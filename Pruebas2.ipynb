{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utOD3qYp_0D3",
        "outputId": "36b3075c-9031-4e18-8c53-7c6f10477dcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando datasets...\n",
            "Filas originales: 732\n",
            "Filas de refuerzo (Statlog): 270\n",
            "Total pacientes para entrenar: 1002\n",
            "Aplicando SMOTE (Generando datos sint칠ticos)...\n",
            "Entrenando XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:27:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "游댠 RESULTADOS FINALES (FUSI칍N + XGBOOST):\n",
            "Accuracy: 0.6119 (61.19%)\n",
            "Micro F1: 0.6119\n",
            "==============================\n",
            "\n",
            "Matriz de Confusi칩n:\n",
            "[[85  5  3  2  1]\n",
            " [ 5 26 14 10  0]\n",
            " [ 3  7  6  4  2]\n",
            " [ 3  9  3  4  2]\n",
            " [ 1  2  0  2  2]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "print(\"Cargando datasets...\")\n",
        "df_train = pd.read_csv('/train_IA_PROJECT.csv')\n",
        "df_statlog = pd.read_csv('/statlog_limpio.csv')\n",
        "\n",
        "print(f\"Filas originales: {len(df_train)}\")\n",
        "print(f\"Filas de refuerzo (Statlog): {len(df_statlog)}\")\n",
        "\n",
        "\n",
        "df_total = pd.concat([df_train, df_statlog], ignore_index=True)\n",
        "print(f\"Total pacientes para entrenar: {len(df_total)}\")\n",
        "\n",
        "\n",
        "\n",
        "# Regla fbs: -9 es 0 (Sano)\n",
        "df_total['fbs'] = df_total['fbs'].replace(['-9.0', '-9', -9, -9.0], 0)\n",
        "\n",
        "# Convertimos basura a NaN\n",
        "df_total.replace(['?', '-9.0', '-9', -9], np.nan, inplace=True)\n",
        "\n",
        "# Asegurar que todo es num칠rico\n",
        "for col in df_total.columns:\n",
        "    if col != 'label':\n",
        "        df_total[col] = pd.to_numeric(df_total[col], errors='coerce')\n",
        "\n",
        "# Borrar filas sin label \n",
        "df_total.dropna(subset=['label'], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "cols_unknown = ['ca', 'thal', 'slope']\n",
        "for col in cols_unknown:\n",
        "    df_total[col] = df_total[col].fillna(-1)\n",
        "\n",
        "# KNN (Para rellenar edad, colesterol, etc.)\n",
        "\n",
        "cols_restantes = [col for col in df_total.columns if col not in cols_unknown + ['label']]\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "df_filled = imputer.fit_transform(df_total[cols_restantes])\n",
        "df_total[cols_restantes] = df_filled\n",
        "\n",
        "\n",
        "df_total.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "X = df_total.drop('label', axis=1)\n",
        "y = df_total['label'].astype(int)\n",
        "\n",
        "# Normalizaci칩n (StandardScaler)\n",
        "scaler = StandardScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "smote = SMOTE(k_neighbors=1, random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Entrenando XGBoost...\")\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=400,      \n",
        "    learning_rate=0.02,     \n",
        "    max_depth=5,            \n",
        "    subsample=0.8,          \n",
        "    colsample_bytree=0.8,  \n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"RESULTADOS FINALES (FUSI칍N + XGBOOST):\")\n",
        "print(f\"Accuracy: {acc:.4f} ({(acc*100):.2f}%)\")\n",
        "print(f\"Micro F1: {f1:.4f}\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "\n",
        "print(\"\\nMatriz de Confusi칩n:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN0UfZoVAibe"
      },
      "source": [
        "# Mejora de analisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "muujtuCyAkt-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UBtcuP9Aqv_",
        "outputId": "2d925477-b917-4cf2-8f19-7402c3958199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas originales (train_IA): 732\n",
            "Filas de refuerzo (Statlog): 270\n",
            "Total pacientes combinados: 1002\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_train = pd.read_csv('/train_IA_PROJECT.csv')\n",
        "df_statlog = pd.read_csv('/statlog_limpio.csv')\n",
        "\n",
        "print(f\"Filas originales (train_IA): {len(df_train)}\")\n",
        "print(f\"Filas de refuerzo (Statlog): {len(df_statlog)}\")\n",
        "\n",
        "# Unimos datasets\n",
        "df_total = pd.concat([df_train, df_statlog], ignore_index=True)\n",
        "print(f\"Total pacientes combinados: {len(df_total)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdOsypRuBVS8",
        "outputId": "8e10a28d-06cc-47fc-9424-fa1bb6e80ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resumen de tipos:\n",
            "age         float64\n",
            "sex         float64\n",
            "cp          float64\n",
            "trestbps     object\n",
            "chol         object\n",
            "fbs          object\n",
            "restecg     float64\n",
            "thalach      object\n",
            "exang        object\n",
            "oldpeak      object\n",
            "slope        object\n",
            "ca           object\n",
            "thal         object\n",
            "label         int64\n",
            "dtype: object\n",
            "\n",
            "Valores especiales por columna:\n",
            "\n",
            "=== Columna: age ===\n",
            "Valores 칰nicos (hasta 10): [51. 54. 63. 52. 55. 44. 35. 62. 68. 50.]\n",
            "N칰mero de '?': 0\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: sex ===\n",
            "Valores 칰nicos (hasta 10): [1. 0.]\n",
            "N칰mero de '?': 0\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: cp ===\n",
            "Valores 칰nicos (hasta 10): [1. 3. 4. 2.]\n",
            "N칰mero de '?': 0\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: trestbps ===\n",
            "Valores 칰nicos (hasta 10): ['125.0' '120.0' '140' '140.0' '122.0' '135' '100' '130.0' '120' '104.0']\n",
            "N칰mero de '?': 47\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: chol ===\n",
            "Valores 칰nicos (hasta 10): ['213.0' '237.0' '0' '-9.0' '217.0' '169.0' '192.0' '297' '231.0' '246.0']\n",
            "N칰mero de '?': 5\n",
            "N칰mero de '-9' (string o num): 16\n",
            "\n",
            "=== Columna: fbs ===\n",
            "Valores 칰nicos (hasta 10): ['0.0' '?' '0' '1.0' '1' '-9.0' 0.0 1.0]\n",
            "N칰mero de '?': 58\n",
            "N칰mero de '-9' (string o num): 8\n",
            "\n",
            "=== Columna: restecg ===\n",
            "Valores 칰nicos (hasta 10): [2. 0. 1.]\n",
            "N칰mero de '?': 0\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: thalach ===\n",
            "Valores 칰nicos (hasta 10): ['125.0' '150.0' '149' '140.0' '111.0' '144.0' '174.0' '130' '120' '179']\n",
            "N칰mero de '?': 44\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: exang ===\n",
            "Valores 칰nicos (hasta 10): ['1.0' '0' '0.0' '1' '?' 0.0 1.0]\n",
            "N칰mero de '?': 44\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: oldpeak ===\n",
            "Valores 칰nicos (hasta 10): ['1.4' '1.5' '2' '0.0' '5.6' '2.8' '1' '0' '5.0' '-1.1']\n",
            "N칰mero de '?': 49\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: slope ===\n",
            "Valores 칰nicos (hasta 10): ['1.0' '-9.0' '1' '3.0' '2' '2.0' '3' '?' 2.0 1.0]\n",
            "N칰mero de '?': 95\n",
            "N칰mero de '-9' (string o num): 152\n",
            "\n",
            "=== Columna: ca ===\n",
            "Valores 칰nicos (hasta 10): ['1.0' '-9.0' '?' '0.0' '2.0' '1' '3.0' '0' '2' 3.0]\n",
            "N칰mero de '?': 249\n",
            "N칰mero de '-9' (string o num): 230\n",
            "\n",
            "=== Columna: thal ===\n",
            "Valores 칰nicos (hasta 10): ['3.0' '7.0' '?' '-9.0' '6.0' '7' '6' '3' 3.0 7.0]\n",
            "N칰mero de '?': 169\n",
            "N칰mero de '-9' (string o num): 210\n",
            "\n",
            "=== Columna: label ===\n",
            "Valores 칰nicos (hasta 10): [0 2 3 4 1]\n",
            "N칰mero de '?': 0\n",
            "N칰mero de '-9' (string o num): 0\n"
          ]
        }
      ],
      "source": [
        "print(\"Resumen de tipos:\")\n",
        "print(df_total.dtypes)\n",
        "\n",
        "print(\"\\nValores especiales por columna:\")\n",
        "for col in df_total.columns:\n",
        "    vals = df_total[col]\n",
        "    print(\"\\n=== Columna:\", col, \"===\")\n",
        "    print(\"Valores 칰nicos (hasta 10):\", vals.unique()[:10])\n",
        "    print(\"N칰mero de '?':\", (vals == '?').sum())\n",
        "    print(\"N칰mero de '-9' (string o num):\",\n",
        "          (vals == '-9').sum() + (vals == '-9.0').sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4ubVrCVBZUg",
        "outputId": "44e7be11-f605-4439-f637-6f726014ab9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci칩n de grados de enfermedad (label):\n",
            "label\n",
            "0    477\n",
            "1    276\n",
            "2    108\n",
            "3    107\n",
            "4     34\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Proporciones:\n",
            "label\n",
            "0    0.476048\n",
            "1    0.275449\n",
            "2    0.107784\n",
            "3    0.106786\n",
            "4    0.033932\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDistribuci칩n de grados de enfermedad (label):\")\n",
        "print(df_total['label'].value_counts().sort_index())\n",
        "print(\"\\nProporciones:\")\n",
        "print(df_total['label'].value_counts(normalize=True).sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6TW4NX0BZxl",
        "outputId": "2eef6624-22db-420c-f6f7-842eb8de71ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci칩n de sexo (tal cual viene):\n",
            "sex\n",
            "1.0    578\n",
            "0.0    154\n",
            "Name: count, dtype: int64\n",
            "sex\n",
            "1.0    183\n",
            "0.0     87\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\nDistribuci칩n de sexo:\")\n",
        "print(df_train['sex'].value_counts(dropna=False))\n",
        "print(df_statlog['sex'].value_counts(dropna=False))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7R070GtBgky",
        "outputId": "7a3cb975-933a-478e-9b54-20034009a185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "age         float64\n",
            "sex         float64\n",
            "cp          float64\n",
            "trestbps    float64\n",
            "chol        float64\n",
            "fbs         float64\n",
            "restecg     float64\n",
            "thalach     float64\n",
            "exang       float64\n",
            "oldpeak     float64\n",
            "slope       float64\n",
            "ca          float64\n",
            "thal        float64\n",
            "label         int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "df = df_total.copy()\n",
        "\n",
        "# 1) fbs: -9 es 0 \n",
        "df['fbs'] = df['fbs'].replace(['-9.0', '-9'], 0)\n",
        "\n",
        "# 2) \"?\" -> NaN\n",
        "df = df.replace('?', np.nan)\n",
        "\n",
        "# 3) Convertir columnas num칠ricas a float \n",
        "num_cols_all = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
        "                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'label']\n",
        "\n",
        "for col in num_cols_all:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# 4) Eliminar filas sin label\n",
        "df = df.dropna(subset=['label'])\n",
        "df['label'] = df['label'].astype(int)\n",
        "\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFEyJ9GeBlx2"
      },
      "outputs": [],
      "source": [
        "# columnas donde -9 significa \"prueba no realizada\"\n",
        "cols_not_done = ['chol', 'slope', 'ca', 'thal']\n",
        "\n",
        "for col in cols_not_done:\n",
        "    # Flag: se intent칩 o se pudo hacer la prueba\n",
        "    df[col + '_not_done'] = (df[col] == -9).astype(int)\n",
        "    # Reemplazamos -9 por NaN, para imputar luego\n",
        "    df.loc[df[col] == -9, col] = np.nan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "i1KEYPehBoeU"
      },
      "outputs": [],
      "source": [
        "df.loc[df['trestbps'] == 0, 'trestbps'] = np.nan\n",
        "df.loc[df['chol'] == 0, 'chol'] = np.nan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "yATmmuytBqsK"
      },
      "outputs": [],
      "source": [
        "# Continuas \"biom칠tricas\"\n",
        "cont_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "\n",
        "# Categ칩ricas cl칤nicas (enteras 0/1/2/3/4)\n",
        "cat_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "# Flags de pruebas no realizadas\n",
        "not_done_cols = [c + '_not_done' for c in cols_not_done]\n",
        "\n",
        "target_col = 'label'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRiPUzjGBuvk",
        "outputId": "ca6ffb2b-be32-48ad-e7be-73608076d9f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Porcentaje de NaN por columna:\n",
            "ca          0.478044\n",
            "thal        0.378244\n",
            "slope       0.246507\n",
            "chol        0.155689\n",
            "fbs         0.057884\n",
            "oldpeak     0.048902\n",
            "trestbps    0.047904\n",
            "exang       0.043912\n",
            "thalach     0.043912\n",
            "age         0.000000\n",
            "restecg     0.000000\n",
            "sex         0.000000\n",
            "cp          0.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"Porcentaje de NaN por columna:\")\n",
        "print(df[cont_cols + cat_cols].isna().mean().sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1bL-BG7ByCi",
        "outputId": "5c28b6db-17f1-4389-c6cb-42ed0b101bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci칩n de sexo (0 mujer, 1 hombre):\n",
            "sex\n",
            "1.0    0.759481\n",
            "0.0    0.240519\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Distribuci칩n de label por sexo:\n",
            "label         0         1         2         3         4\n",
            "sex                                                    \n",
            "0.0    0.755187  0.161826  0.037344  0.033195  0.012448\n",
            "1.0    0.387648  0.311432  0.130092  0.130092  0.040736\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDistribuci칩n de sexo (0 mujer, 1 hombre):\")\n",
        "print(df['sex'].value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nDistribuci칩n de label por sexo:\")\n",
        "print(pd.crosstab(df['sex'], df['label'], normalize='index'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpLJR4_1B1ED",
        "outputId": "740c7c4c-1910-44fe-b06e-c992249c1fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN en continuas tras KNN:\n",
            "age         0\n",
            "trestbps    0\n",
            "chol        0\n",
            "thalach     0\n",
            "oldpeak     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "df_imp = df.copy()\n",
        "\n",
        "knn_imp = KNNImputer(n_neighbors=5)\n",
        "df_imp[cont_cols] = knn_imp.fit_transform(df_imp[cont_cols])\n",
        "\n",
        "print(\"NaN en continuas tras KNN:\")\n",
        "print(df_imp[cont_cols].isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns7a6wcZB36U",
        "outputId": "8934f2ad-f4f5-4cb8-d05e-2a5fc1e89314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN en categ칩ricas tras moda:\n",
            "sex        0\n",
            "cp         0\n",
            "fbs        0\n",
            "restecg    0\n",
            "exang      0\n",
            "slope      0\n",
            "ca         0\n",
            "thal       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2969244517.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_imp[col].fillna(moda, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "for col in cat_cols:\n",
        "    moda = df_imp[col].mode()[0]\n",
        "    df_imp[col].fillna(moda, inplace=True)\n",
        "\n",
        "print(\"NaN en categ칩ricas tras moda:\")\n",
        "print(df_imp[cat_cols].isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rceR6Y_9B7Fp",
        "outputId": "12b2f641-8344-4b19-8fe0-26e7ba0a10c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN totales en X: 0\n"
          ]
        }
      ],
      "source": [
        "features = cont_cols + cat_cols + not_done_cols\n",
        "X = df_imp[features]\n",
        "y = df_imp[target_col].astype(int)\n",
        "\n",
        "print(\"NaN totales en X:\", X.isna().sum().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT9EAFF1B9mX",
        "outputId": "ec8c6fa4-59a3-4dea-c98a-c76346af8e51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas categ칩ricas para SMOTENC: ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'chol_not_done', 'slope_not_done', 'ca_not_done', 'thal_not_done']\n",
            "칈ndices categ칩ricos: [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "# Lista completa de columnas de entrada:\n",
        "feature_cols = features  # = cont_cols + cat_cols + not_done_cols\n",
        "\n",
        "# 칈ndices de las que son categ칩ricas (incluyendo las *_not_done, que son 0/1)\n",
        "cat_for_smote = cat_cols + not_done_cols\n",
        "cat_indices = [feature_cols.index(c) for c in cat_for_smote]\n",
        "\n",
        "print(\"Columnas categ칩ricas para SMOTENC:\", cat_for_smote)\n",
        "print(\"칈ndices categ칩ricos:\", cat_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Omh8dmKCCkj",
        "outputId": "349d6a42-6ded-457c-e350-a6eb2e0f3efb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci칩n y_train:\n",
            "label\n",
            "0    0.475655\n",
            "1    0.275905\n",
            "2    0.107366\n",
            "3    0.107366\n",
            "4    0.033708\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Distribuci칩n y_train:\")\n",
        "print(y_train.value_counts(normalize=True).sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yabPWdrYCFs5",
        "outputId": "bd5cce7c-8e1d-4ccd-a118-ff876fe1a1aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aplicando SMOTENC para equilibrar clases...\n",
            "Distribuci칩n de clases tras SMOTENC:\n",
            "label\n",
            "0    381\n",
            "1    381\n",
            "2    381\n",
            "3    381\n",
            "4    381\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#equilibramos clases\n",
        "\n",
        "smote_nc = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',  \n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train_res, y_train_res = smote_nc.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Distribuci칩n de clases tras SMOTENC:\")\n",
        "print(y_train_res.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLfP9UldCK-T",
        "outputId": "d3705721-6da5-4e16-b69e-5f05bd8e8de9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:27:47] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "RESULTADOS XGBOOST (SMOTENC + imputaci칩n afinada)\n",
            "Accuracy:  0.6219\n",
            "F1 micro:  0.6219\n",
            "F1 macro:  0.4587\n",
            "========================================\n",
            "\n",
            "Matriz de confusi칩n:\n",
            "[[83  6  5  2  0]\n",
            " [ 3 27 13 12  0]\n",
            " [ 5  5  6  5  1]\n",
            " [ 3  8  2  7  1]\n",
            " [ 0  2  2  1  2]]\n",
            "\n",
            "Reporte de clasificaci칩n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87        96\n",
            "           1       0.56      0.49      0.52        55\n",
            "           2       0.21      0.27      0.24        22\n",
            "           3       0.26      0.33      0.29        21\n",
            "           4       0.50      0.29      0.36         7\n",
            "\n",
            "    accuracy                           0.62       201\n",
            "   macro avg       0.48      0.45      0.46       201\n",
            "weighted avg       0.64      0.62      0.63       201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.02,\n",
        "    max_depth=5,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_res, y_train_res)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"RESULTADOS XGBOOST (SMOTENC + imputaci칩n afinada)\")\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"F1 micro:  {f1_micro:.4f}\")\n",
        "print(f\"F1 macro:  {f1_macro:.4f}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "print(\"\\nMatriz de confusi칩n:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nReporte de clasificaci칩n:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22SPBTX1CTXS",
        "outputId": "3f4b59e4-711d-458d-d45c-fe549551a886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Rendimiento en MUJERES:\n",
            "N mujeres en test: 50\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        37\n",
            "           1       0.33      0.29      0.31         7\n",
            "           2       0.33      0.50      0.40         2\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.80        50\n",
            "   macro avg       0.32      0.36      0.33        50\n",
            "weighted avg       0.74      0.80      0.77        50\n",
            "\n",
            "\n",
            "Rendimiento en HOMBRES:\n",
            "N hombres en test: 151\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.81        59\n",
            "           1       0.60      0.52      0.56        48\n",
            "           2       0.20      0.25      0.22        20\n",
            "           3       0.27      0.39      0.32        18\n",
            "           4       0.50      0.33      0.40         6\n",
            "\n",
            "    accuracy                           0.56       151\n",
            "   macro avg       0.48      0.45      0.46       151\n",
            "weighted avg       0.60      0.56      0.58       151\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Recuperamos la columna sex de X_test \n",
        "sex_test = X_test['sex']\n",
        "\n",
        "# M치scaras\n",
        "mask_mujer = (sex_test == 0)\n",
        "mask_hombre = (sex_test == 1)\n",
        "\n",
        "print(\"\\nRendimiento en MUJERES:\")\n",
        "print(\"N mujeres en test:\", mask_mujer.sum())\n",
        "print(classification_report(y_test[mask_mujer], y_pred[mask_mujer], zero_division=0))\n",
        "\n",
        "print(\"\\nRendimiento en HOMBRES:\")\n",
        "print(\"N hombres en test:\", mask_hombre.sum())\n",
        "print(classification_report(y_test[mask_hombre], y_pred[mask_hombre], zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVo27nGlDUkY"
      },
      "source": [
        "# Metemos mas mujeres con 3 y 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "QHWLJ8kbDZCP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISNGhM-KDfk5",
        "outputId": "051e6fa5-5fe1-459d-f616-0565090395a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas originales (train_IA): 732\n",
            "Filas de refuerzo (Statlog): 270\n",
            "Total pacientes combinados: 1002\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_train = pd.read_csv('/train_IA_PROJECT.csv')\n",
        "df_statlog = pd.read_csv('/statlog_limpio.csv')\n",
        "\n",
        "print(f\"Filas originales (train_IA): {len(df_train)}\")\n",
        "print(f\"Filas de refuerzo (Statlog): {len(df_statlog)}\")\n",
        "\n",
        "\n",
        "df_total = pd.concat([df_train, df_statlog], ignore_index=True)\n",
        "print(f\"Total pacientes combinados: {len(df_total)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAcohcobDija",
        "outputId": "301d560e-3f94-4597-8aa7-13f77abf138a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resumen de tipos:\n",
            "age         float64\n",
            "sex         float64\n",
            "cp          float64\n",
            "trestbps     object\n",
            "chol         object\n",
            "fbs          object\n",
            "restecg     float64\n",
            "thalach      object\n",
            "exang        object\n",
            "oldpeak      object\n",
            "slope        object\n",
            "ca           object\n",
            "thal         object\n",
            "label         int64\n",
            "dtype: object\n",
            "\n",
            "Valores especiales por columna:\n",
            "\n",
            "=== Columna: age ===\n",
            "Valores 칰nicos (hasta 10): [51. 54. 63. 52. 55. 44. 35. 62. 68. 50.]\n",
            "N칰mero de '?': 0\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: sex ===\n",
            "Valores 칰nicos (hasta 10): [1. 0.]\n",
            "N칰mero de '?': 0\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: cp ===\n",
            "Valores 칰nicos (hasta 10): [1. 3. 4. 2.]\n",
            "N칰mero de '?': 0\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: trestbps ===\n",
            "Valores 칰nicos (hasta 10): ['125.0' '120.0' '140' '140.0' '122.0' '135' '100' '130.0' '120' '104.0']\n",
            "N칰mero de '?': 47\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: chol ===\n",
            "Valores 칰nicos (hasta 10): ['213.0' '237.0' '0' '-9.0' '217.0' '169.0' '192.0' '297' '231.0' '246.0']\n",
            "N칰mero de '?': 5\n",
            "N칰mero de '-9' (string o num): 16\n",
            "\n",
            "=== Columna: fbs ===\n",
            "Valores 칰nicos (hasta 10): ['0.0' '?' '0' '1.0' '1' '-9.0' 0.0 1.0]\n",
            "N칰mero de '?': 58\n",
            "N칰mero de '-9' (string o num): 8\n",
            "\n",
            "=== Columna: restecg ===\n",
            "Valores 칰nicos (hasta 10): [2. 0. 1.]\n",
            "N칰mero de '?': 0\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: thalach ===\n",
            "Valores 칰nicos (hasta 10): ['125.0' '150.0' '149' '140.0' '111.0' '144.0' '174.0' '130' '120' '179']\n",
            "N칰mero de '?': 44\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: exang ===\n",
            "Valores 칰nicos (hasta 10): ['1.0' '0' '0.0' '1' '?' 0.0 1.0]\n",
            "N칰mero de '?': 44\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: oldpeak ===\n",
            "Valores 칰nicos (hasta 10): ['1.4' '1.5' '2' '0.0' '5.6' '2.8' '1' '0' '5.0' '-1.1']\n",
            "N칰mero de '?': 49\n",
            "N칰mero de '-9' (string o num): 0\n",
            "\n",
            "=== Columna: slope ===\n",
            "Valores 칰nicos (hasta 10): ['1.0' '-9.0' '1' '3.0' '2' '2.0' '3' '?' 2.0 1.0]\n",
            "N칰mero de '?': 95\n",
            "N칰mero de '-9' (string o num): 152\n",
            "\n",
            "=== Columna: ca ===\n",
            "Valores 칰nicos (hasta 10): ['1.0' '-9.0' '?' '0.0' '2.0' '1' '3.0' '0' '2' 3.0]\n",
            "N칰mero de '?': 249\n",
            "N칰mero de '-9' (string o num): 230\n",
            "\n",
            "=== Columna: thal ===\n",
            "Valores 칰nicos (hasta 10): ['3.0' '7.0' '?' '-9.0' '6.0' '7' '6' '3' 3.0 7.0]\n",
            "N칰mero de '?': 169\n",
            "N칰mero de '-9' (string o num): 210\n",
            "\n",
            "=== Columna: label ===\n",
            "Valores 칰nicos (hasta 10): [0 2 3 4 1]\n",
            "N칰mero de '?': 0\n",
            "N칰mero de '-9' (string o num): 0\n"
          ]
        }
      ],
      "source": [
        "print(\"Resumen de tipos:\")\n",
        "print(df_total.dtypes)\n",
        "\n",
        "print(\"\\nValores especiales por columna:\")\n",
        "for col in df_total.columns:\n",
        "    vals = df_total[col]\n",
        "    print(\"\\n=== Columna:\", col, \"===\")\n",
        "    print(\"Valores 칰nicos (hasta 10):\", vals.unique()[:10])\n",
        "    print(\"N칰mero de '?':\", (vals == '?').sum())\n",
        "    print(\"N칰mero de '-9' (string o num):\",\n",
        "          (vals == '-9').sum() + (vals == '-9.0').sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFr3ic5mDm75",
        "outputId": "bcee4af4-96de-4439-db50-12ab15cf38b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci칩n de grados de enfermedad (label):\n",
            "label\n",
            "0    477\n",
            "1    276\n",
            "2    108\n",
            "3    107\n",
            "4     34\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Proporciones:\n",
            "label\n",
            "0    0.476048\n",
            "1    0.275449\n",
            "2    0.107784\n",
            "3    0.106786\n",
            "4    0.033932\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDistribuci칩n de grados de enfermedad (label):\")\n",
        "print(df_total['label'].value_counts().sort_index())\n",
        "print(\"\\nProporciones:\")\n",
        "print(df_total['label'].value_counts(normalize=True).sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC7Qy9KJDp3p",
        "outputId": "c080195c-3a8a-41c0-c51d-7a41af057f6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci칩n de sexo (tal cual viene):\n",
            "sex\n",
            "1.0    578\n",
            "0.0    154\n",
            "Name: count, dtype: int64\n",
            "sex\n",
            "1.0    183\n",
            "0.0     87\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\nDistribuci칩n de sexo (tal cual viene):\")\n",
        "print(df_train['sex'].value_counts(dropna=False))\n",
        "print(df_statlog['sex'].value_counts(dropna=False))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reUfgwQGDtne",
        "outputId": "0b8ead44-ebeb-4c74-bb29-a6c1028bcfb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "age         float64\n",
            "sex         float64\n",
            "cp          float64\n",
            "trestbps    float64\n",
            "chol        float64\n",
            "fbs         float64\n",
            "restecg     float64\n",
            "thalach     float64\n",
            "exang       float64\n",
            "oldpeak     float64\n",
            "slope       float64\n",
            "ca          float64\n",
            "thal        float64\n",
            "label         int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "df = df_total.copy()\n",
        "\n",
        "\n",
        "df['fbs'] = df['fbs'].replace(['-9.0', '-9'], 0)\n",
        "\n",
        "\n",
        "df = df.replace('?', np.nan)\n",
        "\n",
        "# Convertir columnas num칠ricas a float \n",
        "num_cols_all = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
        "                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'label']\n",
        "\n",
        "for col in num_cols_all:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Eliminar filas sin label\n",
        "df = df.dropna(subset=['label'])\n",
        "df['label'] = df['label'].astype(int)\n",
        "\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYexe4RYDwRE"
      },
      "outputs": [],
      "source": [
        "# columnas donde -9 significa \"prueba no realizada\"\n",
        "cols_not_done = ['chol', 'slope', 'ca', 'thal']\n",
        "\n",
        "for col in cols_not_done:\n",
        "    # Flag: se intent칩 o se pudo hacer la prueba\n",
        "    df[col + '_not_done'] = (df[col] == -9).astype(int)\n",
        "    # Reemplazamos -9 por NaN, para imputar un valor plausible luego\n",
        "    df.loc[df[col] == -9, col] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "XE9j-44NDzMf"
      },
      "outputs": [],
      "source": [
        "df.loc[df['trestbps'] == 0, 'trestbps'] = np.nan\n",
        "df.loc[df['chol'] == 0, 'chol'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "hhYpAOsUD3j7"
      },
      "outputs": [],
      "source": [
        "# Continuas \"biom칠tricas\"\n",
        "cont_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "\n",
        "# Categ칩ricas cl칤nicas (enteras 0/1/2/3/4)\n",
        "cat_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "# Flags de pruebas no realizadas\n",
        "not_done_cols = [c + '_not_done' for c in cols_not_done]\n",
        "\n",
        "target_col = 'label'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXxrVLocD7Cj",
        "outputId": "7a6b899a-609e-4298-b03f-5e0bbfbc9977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Porcentaje de NaN por columna:\n",
            "ca          0.478044\n",
            "thal        0.378244\n",
            "slope       0.246507\n",
            "chol        0.155689\n",
            "fbs         0.057884\n",
            "oldpeak     0.048902\n",
            "trestbps    0.047904\n",
            "exang       0.043912\n",
            "thalach     0.043912\n",
            "age         0.000000\n",
            "restecg     0.000000\n",
            "sex         0.000000\n",
            "cp          0.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"Porcentaje de NaN por columna:\")\n",
        "print(df[cont_cols + cat_cols].isna().mean().sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbbwxfsZD_Wn",
        "outputId": "e7bab0d5-ca93-4cb9-e538-03e7d6cb9960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci칩n de sexo (0 mujer, 1 hombre):\n",
            "sex\n",
            "1.0    0.759481\n",
            "0.0    0.240519\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Distribuci칩n de label por sexo:\n",
            "label         0         1         2         3         4\n",
            "sex                                                    \n",
            "0.0    0.755187  0.161826  0.037344  0.033195  0.012448\n",
            "1.0    0.387648  0.311432  0.130092  0.130092  0.040736\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDistribuci칩n de sexo (0 mujer, 1 hombre):\")\n",
        "print(df['sex'].value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nDistribuci칩n de label por sexo:\")\n",
        "print(pd.crosstab(df['sex'], df['label'], normalize='index'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzd21EAQEDHf",
        "outputId": "e890fe6d-3589-4500-f8a4-31f104a203f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN en continuas tras KNN:\n",
            "age         0\n",
            "trestbps    0\n",
            "chol        0\n",
            "thalach     0\n",
            "oldpeak     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "df_imp = df.copy()\n",
        "\n",
        "knn_imp = KNNImputer(n_neighbors=5)\n",
        "df_imp[cont_cols] = knn_imp.fit_transform(df_imp[cont_cols])\n",
        "\n",
        "print(\"NaN en continuas tras KNN:\")\n",
        "print(df_imp[cont_cols].isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZafrKazEGCf",
        "outputId": "9a488c30-cc9b-4fae-de73-779f517c0461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN en categ칩ricas tras moda:\n",
            "sex        0\n",
            "cp         0\n",
            "fbs        0\n",
            "restecg    0\n",
            "exang      0\n",
            "slope      0\n",
            "ca         0\n",
            "thal       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-996988591.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_imp[col].fillna(moda, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "for col in cat_cols:\n",
        "    moda = df_imp[col].mode()[0]\n",
        "    df_imp[col].fillna(moda, inplace=True)\n",
        "\n",
        "print(\"NaN en categ칩ricas tras moda:\")\n",
        "print(df_imp[cat_cols].isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFGb_cdRELQC",
        "outputId": "df144261-8752-4832-d577-2e5ff1ffa4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN totales en X: 0\n"
          ]
        }
      ],
      "source": [
        "features = cont_cols + cat_cols + not_done_cols\n",
        "X = df_imp[features]\n",
        "y = df_imp[target_col].astype(int)\n",
        "\n",
        "print(\"NaN totales en X:\", X.isna().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Iax4p0LEObc",
        "outputId": "c24184b0-1516-47ce-c76a-4ebb1612c53a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas categ칩ricas para SMOTENC: ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'chol_not_done', 'slope_not_done', 'ca_not_done', 'thal_not_done']\n",
            "칈ndices categ칩ricos: [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "# Lista completa de columnas de entrada:\n",
        "feature_cols = features  # = cont_cols + cat_cols + not_done_cols\n",
        "\n",
        "# 칈ndices de las que son categ칩ricas (incluyendo las *_not_done, que son 0/1)\n",
        "cat_for_smote = cat_cols + not_done_cols\n",
        "cat_indices = [feature_cols.index(c) for c in cat_for_smote]\n",
        "\n",
        "print(\"Columnas categ칩ricas para SMOTENC:\", cat_for_smote)\n",
        "print(\"칈ndices categ칩ricos:\", cat_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqDVXQQyEhu8",
        "outputId": "5619317e-16e1-4403-840d-6c2a6edc1fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci칩n y_train:\n",
            "label\n",
            "0    0.475655\n",
            "1    0.275905\n",
            "2    0.107366\n",
            "3    0.107366\n",
            "4    0.033708\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Distribuci칩n y_train:\")\n",
        "print(y_train.value_counts(normalize=True).sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of2SG12JEsNs",
        "outputId": "bc4cb34b-4156-4f86-9687-e89386e3162e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mujeres en train: 191\n",
            "Mujeres con label 3-4 en train: 7\n",
            "\n",
            "Tabla sexo x label en train:\n",
            "label    0    1   2   3   4\n",
            "sex                        \n",
            "0.0    145   32   7   5   2\n",
            "1.0    236  189  79  81  25\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# X_train, X_test, y_train, y_test\n",
        "\n",
        "mask_mujer_train = (X_train['sex'] == 0)\n",
        "mask_grave_train = y_train.isin([3, 4])\n",
        "mask_mujer_grave_train = mask_mujer_train & mask_grave_train\n",
        "\n",
        "print(\"Mujeres en train:\", mask_mujer_train.sum())\n",
        "print(\"Mujeres con label 3-4 en train:\", mask_mujer_grave_train.sum())\n",
        "\n",
        "print(\"\\nTabla sexo x label en train:\")\n",
        "print(pd.crosstab(X_train['sex'], y_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qSf8JwKEvOW",
        "outputId": "6358edf4-b12f-45cb-9f7e-8427b14a9c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci칩n tras SMOTENC:\n",
            "label\n",
            "0    381\n",
            "1    381\n",
            "2    381\n",
            "3    381\n",
            "4    381\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "feature_cols = cont_cols + cat_cols + not_done_cols\n",
        "X = df_imp[feature_cols]\n",
        "y = df_imp['label'].astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cat_for_smote = cat_cols + not_done_cols\n",
        "cat_indices = [feature_cols.index(c) for c in cat_for_smote]\n",
        "\n",
        "smote_nc = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',\n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train_res, y_train_res = smote_nc.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Distribuci칩n tras SMOTENC:\")\n",
        "print(y_train_res.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGAln8M7Ey9K",
        "outputId": "8340bac8-d544-4f40-d825-3cd713d91d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mujeres graves en X_train_res: 7\n",
            "Tama침o final de train: 2003\n",
            "Distribuci칩n sexo x label tras oversampling espec칤fico:\n",
            "label    0    1    2    3    4\n",
            "sex                           \n",
            "0.0    145   49   12   75   30\n",
            "1.0    236  332  369  376  379\n"
          ]
        }
      ],
      "source": [
        "#Localizamos mujeres con enfermedad grave en el conjunto resampleado\n",
        "mask_mujer = (X_train_res['sex'] == 0)\n",
        "mask_grave = y_train_res.isin([3, 4])\n",
        "mask_mujer_grave = mask_mujer & mask_grave\n",
        "\n",
        "print(\"Mujeres graves en X_train_res:\", mask_mujer_grave.sum())\n",
        "\n",
        "X_mujer_grave = X_train_res[mask_mujer_grave]\n",
        "y_mujer_grave = y_train_res[mask_mujer_grave]\n",
        "\n",
        "# Replicamos x numero de veces\n",
        "factor_oversample = 3\n",
        "\n",
        "X_extra = pd.concat([X_mujer_grave] * (factor_oversample - 1), ignore_index=True)\n",
        "y_extra = pd.concat([y_mujer_grave] * (factor_oversample - 1), ignore_index=True)\n",
        "\n",
        "#Creamos nuevo train con estas filas extra\n",
        "X_train_final = pd.concat([X_train_res, X_extra], ignore_index=True)\n",
        "y_train_final = pd.concat([y_train_res, y_extra], ignore_index=True)\n",
        "\n",
        "print(\"Tama침o final de train:\", len(X_train_final))\n",
        "print(\"Distribuci칩n sexo x label tras oversampling espec칤fico:\")\n",
        "print(pd.crosstab(X_train_final['sex'], y_train_final))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEYvnrNQFGrY",
        "outputId": "011fe3ff-a5a7-442e-886d-b7ba9d8c8210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N칰mero de mujeres graves con peso extra: 105\n",
            "Peso medio global: 1.1048427358961557\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sample_weight = np.ones(len(y_train_final), dtype=float)\n",
        "\n",
        "sex_train_final = X_train_final['sex']\n",
        "label_train_final = y_train_final\n",
        "\n",
        "mask_mujer_grave_final = (sex_train_final == 0) & (label_train_final.isin([3, 4]))\n",
        "\n",
        "# Factor extra para mujeres graves\n",
        "factor_peso = 3.0   \n",
        "\n",
        "sample_weight[mask_mujer_grave_final] *= factor_peso\n",
        "\n",
        "print(\"N칰mero de mujeres graves con peso extra:\", mask_mujer_grave_final.sum())\n",
        "print(\"Peso medio global:\", sample_weight.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAwNQkmOFMRu",
        "outputId": "21243c3d-6a71-42f9-890c-37ec6a613e1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:27:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== RESULTADOS GLOBALES ===\n",
            "Accuracy: 0.6218905472636815\n",
            "F1 micro: 0.6218905472636815\n",
            "Matriz de confusi칩n:\n",
            " [[83  5  5  3  0]\n",
            " [ 2 29 11 13  0]\n",
            " [ 5  6  5  4  2]\n",
            " [ 2  8  4  6  1]\n",
            " [ 0  2  2  1  2]]\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "xgb_model_w = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.02,\n",
        "    max_depth=5,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_model_w.fit(X_train_final, y_train_final, sample_weight=sample_weight)\n",
        "\n",
        "y_pred = xgb_model_w.predict(X_test)\n",
        "\n",
        "print(\"\\n=== RESULTADOS GLOBALES ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1 micro:\", f1_score(y_test, y_pred, average='micro'))\n",
        "print(\"Matriz de confusi칩n:\\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5C0TRE5FXDS",
        "outputId": "b330b423-2a7d-48d2-f782-788133f9459d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Rendimiento en MUJERES (modelo ponderado):\n",
            "N mujeres en test: 50\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        37\n",
            "           1       0.40      0.57      0.47         7\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.78        50\n",
            "   macro avg       0.27      0.30      0.28        50\n",
            "weighted avg       0.76      0.78      0.77        50\n",
            "\n",
            "\n",
            "Rendimiento en HOMBRES (modelo ponderado):\n",
            "N hombres en test: 151\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.81      0.84        59\n",
            "           1       0.62      0.52      0.57        48\n",
            "           2       0.19      0.25      0.22        20\n",
            "           3       0.24      0.33      0.28        18\n",
            "           4       0.40      0.33      0.36         6\n",
            "\n",
            "    accuracy                           0.57       151\n",
            "   macro avg       0.47      0.45      0.45       151\n",
            "weighted avg       0.61      0.57      0.59       151\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sex_test = X_test['sex']\n",
        "\n",
        "mask_mujer_test = (sex_test == 0)\n",
        "mask_hombre_test = (sex_test == 1)\n",
        "\n",
        "print(\"\\nRendimiento en MUJERES (modelo ponderado):\")\n",
        "print(\"N mujeres en test:\", mask_mujer_test.sum())\n",
        "print(classification_report(y_test[mask_mujer_test], y_pred[mask_mujer_test], zero_division=0))\n",
        "\n",
        "print(\"\\nRendimiento en HOMBRES (modelo ponderado):\")\n",
        "print(\"N hombres en test:\", mask_hombre_test.sum())\n",
        "print(classification_report(y_test[mask_hombre_test], y_pred[mask_hombre_test], zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd4oKHk6GKgn"
      },
      "source": [
        "# Enfoque concatenado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BVSSfQJGNpA"
      },
      "outputs": [],
      "source": [
        "\n",
        "features = cont_cols + cat_cols + not_done_cols\n",
        "\n",
        "X_full = df_imp[features]\n",
        "y_full = df_imp[\"label\"].astype(int)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "nKzP-Xl8GgCf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(\n",
        "    X_full, y_full,\n",
        "    test_size=0.2,\n",
        "    stratify=y_full,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "7gJtXDs9GhR4"
      },
      "outputs": [],
      "source": [
        "# 0 = sano, 1 = enfermo (cualquier grado 14)\n",
        "y_train_enf = (y_train_all > 0).astype(int)\n",
        "y_test_enf  = (y_test_all  > 0).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zLCocrdGmWm",
        "outputId": "7988c2ab-6935-4baa-eecb-916386c41638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci칩n enfermo vs sano (antes):\n",
            "label\n",
            "1    420\n",
            "0    381\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribuci칩n enfermo vs sano (despu칠s SMOTENC):\n",
            "label\n",
            "0    420\n",
            "1    420\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTENC\n",
        "import numpy as np\n",
        "\n",
        "feature_cols = features\n",
        "\n",
        "cat_for_smote = cat_cols + not_done_cols\n",
        "cat_indices = [feature_cols.index(c) for c in cat_for_smote]\n",
        "\n",
        "smote_nc_1 = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority', \n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X1_train_res, y1_train_res = smote_nc_1.fit_resample(X_train_all, y_train_enf)\n",
        "\n",
        "print(\"Distribuci칩n enfermo vs sano (antes):\")\n",
        "print(y_train_enf.value_counts())\n",
        "print(\"\\nDistribuci칩n enfermo vs sano (despu칠s SMOTENC):\")\n",
        "print(y1_train_res.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGwdzHZfGqvX",
        "outputId": "5758fd62-845a-4570-af5d-15cf94647b1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== MODELO 1: ENFERMO vs SANO ===\n",
            "Accuracy: 0.8805970149253731\n",
            "F1 macro: 0.8797367371360192\n",
            "Matriz de confusi칩n:\n",
            " [[80 16]\n",
            " [ 8 97]]\n",
            "\n",
            "Reporte completo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.83      0.87        96\n",
            "           1       0.86      0.92      0.89       105\n",
            "\n",
            "    accuracy                           0.88       201\n",
            "   macro avg       0.88      0.88      0.88       201\n",
            "weighted avg       0.88      0.88      0.88       201\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:27:52] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "xgb_enf = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective='binary:logistic',\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_enf.fit(X1_train_res, y1_train_res)\n",
        "\n",
        "# Predicciones en el test\n",
        "y1_proba_test = xgb_enf.predict_proba(X_test_all)[:, 1]   # prob de estar enfermo\n",
        "y1_pred_test  = (y1_proba_test >= 0.5).astype(int)\n",
        "\n",
        "print(\"=== MODELO 1: ENFERMO vs SANO ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_enf, y1_pred_test))\n",
        "print(\"F1 macro:\", f1_score(y_test_enf, y1_pred_test, average=\"macro\"))\n",
        "print(\"Matriz de confusi칩n:\\n\", confusion_matrix(y_test_enf, y1_pred_test))\n",
        "print(\"\\nReporte completo:\")\n",
        "print(classification_report(y_test_enf, y1_pred_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QNWicvyGwzY",
        "outputId": "577f6d1c-eb41-451f-c57e-75c09341a1c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MODELO 1  MUJERES ===\n",
            "N mujeres en test: 50\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95        37\n",
            "           1       0.91      0.77      0.83        13\n",
            "\n",
            "    accuracy                           0.92        50\n",
            "   macro avg       0.92      0.87      0.89        50\n",
            "weighted avg       0.92      0.92      0.92        50\n",
            "\n",
            "\n",
            "=== MODELO 1  HOMBRES ===\n",
            "N hombres en test: 151\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.75      0.81        59\n",
            "           1       0.85      0.95      0.90        92\n",
            "\n",
            "    accuracy                           0.87       151\n",
            "   macro avg       0.88      0.85      0.86       151\n",
            "weighted avg       0.87      0.87      0.86       151\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sex_test = X_test_all[\"sex\"]\n",
        "\n",
        "mask_f = (sex_test == 0)  # mujeres\n",
        "mask_m = (sex_test == 1)  # hombres\n",
        "\n",
        "print(\"\\n=== MODELO 1  MUJERES ===\")\n",
        "print(\"N mujeres en test:\", mask_f.sum())\n",
        "print(classification_report(y_test_enf[mask_f], y1_pred_test[mask_f], zero_division=0))\n",
        "\n",
        "print(\"\\n=== MODELO 1  HOMBRES ===\")\n",
        "print(\"N hombres en test:\", mask_m.sum())\n",
        "print(classification_report(y_test_enf[mask_m], y1_pred_test[mask_m], zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r04aBrhsG00i",
        "outputId": "dcf5e907-d518-4976-890a-5dadb8f75de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enfermos en train: 420\n",
            "Enfermos en test: 105\n",
            "Distrib train por grado (14):\n",
            "label\n",
            "1    221\n",
            "2     86\n",
            "3     86\n",
            "4     27\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# TRAIN: quedarnos solo con enfermos (label 14)\n",
        "mask_train_enfermo = (y_train_all > 0)\n",
        "X_train_enf = X_train_all[mask_train_enfermo].copy()\n",
        "y_train_enf_label = y_train_all[mask_train_enfermo].copy()\n",
        "\n",
        "# TEST: lo mismo\n",
        "mask_test_enfermo = (y_test_all > 0)\n",
        "X_test_enf = X_test_all[mask_test_enfermo].copy()\n",
        "y_test_enf_label = y_test_all[mask_test_enfermo].copy()\n",
        "\n",
        "print(\"Enfermos en train:\", len(X_train_enf))\n",
        "print(\"Enfermos en test:\", len(X_test_enf))\n",
        "print(\"Distrib train por grado (14):\")\n",
        "print(y_train_enf_label.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PiRw9KgG30T",
        "outputId": "566b7672-c4ff-45e9-a0a8-76c2b09a6aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distrib train grave vs no grave:\n",
            "label\n",
            "0    307\n",
            "1    113\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 0 = leve/moderado (12), 1 = grave (34)\n",
        "y_train_grave = (y_train_enf_label >= 3).astype(int)\n",
        "y_test_grave  = (y_test_enf_label  >= 3).astype(int)\n",
        "\n",
        "print(\"Distrib train grave vs no grave:\")\n",
        "print(y_train_grave.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o-gr_uaG6cy",
        "outputId": "8a0732e3-f2c1-45c7-a045-aa5b255239ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci칩n grave vs no grave tras SMOTENC:\n",
            "label\n",
            "1    307\n",
            "0    307\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "smote_nc_2 = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',  # sube graves\n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X2_train_res, y2_train_res = smote_nc_2.fit_resample(X_train_enf, y_train_grave)\n",
        "\n",
        "print(\"Distribuci칩n grave vs no grave tras SMOTENC:\")\n",
        "print(y2_train_res.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfwlyR_jG9Lj",
        "outputId": "81342d50-21ba-4e49-8657-de4031d694c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== MODELO 2: GRAVE vs NO GRAVE (solo enfermos) ===\n",
            "Accuracy: 0.638095238095238\n",
            "F1 macro: 0.5474137931034483\n",
            "Matriz de confusi칩n:\n",
            " [[57 20]\n",
            " [18 10]]\n",
            "\n",
            "Reporte completo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.74      0.75        77\n",
            "           1       0.33      0.36      0.34        28\n",
            "\n",
            "    accuracy                           0.64       105\n",
            "   macro avg       0.55      0.55      0.55       105\n",
            "weighted avg       0.65      0.64      0.64       105\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:27:52] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ],
      "source": [
        "xgb_grave = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective='binary:logistic',\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_grave.fit(X2_train_res, y2_train_res)\n",
        "\n",
        "y2_proba_test = xgb_grave.predict_proba(X_test_enf)[:,1]\n",
        "y2_pred_test = (y2_proba_test >= 0.5).astype(int)\n",
        "\n",
        "print(\"=== MODELO 2: GRAVE vs NO GRAVE (solo enfermos) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_grave, y2_pred_test))\n",
        "print(\"F1 macro:\", f1_score(y_test_grave, y2_pred_test, average=\"macro\"))\n",
        "print(\"Matriz de confusi칩n:\\n\", confusion_matrix(y_test_grave, y2_pred_test))\n",
        "print(\"\\nReporte completo:\")\n",
        "print(classification_report(y_test_grave, y2_pred_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaeqsE7_HBtI",
        "outputId": "5e6c4150-667d-4357-fa36-f615d7c4474c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MODELO 2  MUJERES ENFERMAS ===\n",
            "N mujeres enfermas en test: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.67      0.63         9\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.46        13\n",
            "   macro avg       0.30      0.33      0.32        13\n",
            "weighted avg       0.42      0.46      0.44        13\n",
            "\n",
            "\n",
            "=== MODELO 2  HOMBRES ENFERMOS ===\n",
            "N hombres enfermos en test: 92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.75      0.77        68\n",
            "           1       0.37      0.42      0.39        24\n",
            "\n",
            "    accuracy                           0.66        92\n",
            "   macro avg       0.58      0.58      0.58        92\n",
            "weighted avg       0.68      0.66      0.67        92\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sex_test_enf = X_test_enf[\"sex\"]\n",
        "\n",
        "mask_f_enf = (sex_test_enf == 0)\n",
        "mask_m_enf = (sex_test_enf == 1)\n",
        "\n",
        "print(\"\\n=== MODELO 2  MUJERES ENFERMAS ===\")\n",
        "print(\"N mujeres enfermas en test:\", mask_f_enf.sum())\n",
        "print(classification_report(y_test_grave[mask_f_enf], y2_pred_test[mask_f_enf], zero_division=0))\n",
        "\n",
        "print(\"\\n=== MODELO 2  HOMBRES ENFERMOS ===\")\n",
        "print(\"N hombres enfermos en test:\", mask_m_enf.sum())\n",
        "print(classification_report(y_test_grave[mask_m_enf], y2_pred_test[mask_m_enf], zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bXJkTpuH_u0"
      },
      "source": [
        "# Redes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3lqF7zsIBao"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "features = cont_cols + cat_cols + not_done_cols\n",
        "X_full = df_imp[features].copy()\n",
        "y_full = df_imp[\"label\"].astype(int)   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "_uNbEuAZIC-C"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_full_scaled = X_full.copy()\n",
        "X_full_scaled[cont_cols] = scaler.fit_transform(X_full_scaled[cont_cols])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "id": "MHTTD32LIG90"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(\n",
        "    X_full_scaled, y_full,\n",
        "    test_size=0.2,\n",
        "    stratify=y_full,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "m9uKioJeIJsj",
        "outputId": "a13f20fd-6a6f-43eb-ff7e-fcdfeca70a80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較늎n",
              "較<span style=\"font-weight: bold\"> Layer (type)                    </span>較<span style=\"font-weight: bold\"> Output Shape           </span>較<span style=\"font-weight: bold\">       Param # </span>較\n",
              "較뫡대較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較뼆n",
              "較 dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             較         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 batch_normalization_12          較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             較           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> 較\n",
              "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            較                        較               較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             較             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             較         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 batch_normalization_13          較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             較           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> 較\n",
              "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            較                        較               較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             較             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              較           <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> 較\n",
              "較덕較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較\n",
              "</pre>\n"
            ],
            "text/plain": [
              "較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較늎n",
              "較\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m較\n",
              "較뫡대較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較뼆n",
              "較 dense_18 (\u001b[38;5;33mDense\u001b[0m)                較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             較         \u001b[38;5;34m1,152\u001b[0m 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 batch_normalization_12          較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             較           \u001b[38;5;34m256\u001b[0m 較\n",
              "較 (\u001b[38;5;33mBatchNormalization\u001b[0m)            較                        較               較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             較             \u001b[38;5;34m0\u001b[0m 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dense_19 (\u001b[38;5;33mDense\u001b[0m)                較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             較         \u001b[38;5;34m2,080\u001b[0m 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 batch_normalization_13          較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             較           \u001b[38;5;34m128\u001b[0m 較\n",
              "較 (\u001b[38;5;33mBatchNormalization\u001b[0m)            較                        較               較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             較             \u001b[38;5;34m0\u001b[0m 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dense_20 (\u001b[38;5;33mDense\u001b[0m)                較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              較           \u001b[38;5;34m165\u001b[0m 較\n",
              "較덕較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,781</span> (14.77 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,781\u001b[0m (14.77 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,589</span> (14.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,589\u001b[0m (14.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, callbacks\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "n_features = X_train_all.shape[1]\n",
        "n_classes = len(np.unique(y_train_all))\n",
        "\n",
        "def build_mlp_5class(input_dim, n_classes):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(input_dim,)))\n",
        "    model.add(layers.Dense(64, activation=\"relu\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Dense(32, activation=\"relu\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Dense(n_classes, activation=\"softmax\"))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model_5 = build_mlp_5class(n_features, n_classes)\n",
        "model_5.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuVItVEFIRCV",
        "outputId": "641525c8-bcd1-47ff-ddf6-42b6088c001d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{np.int64(0): np.float64(0.4204724409448819),\n",
              " np.int64(1): np.float64(0.7248868778280543),\n",
              " np.int64(2): np.float64(1.8627906976744186),\n",
              " np.int64(3): np.float64(1.8627906976744186),\n",
              " np.int64(4): np.float64(5.933333333333334)}"
            ]
          },
          "execution_count": 300,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = np.unique(y_train_all)\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=classes,\n",
        "    y=y_train_all\n",
        ")\n",
        "class_weight_dict = {cls: w for cls, w in zip(classes, class_weights)}\n",
        "class_weight_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62ZWwrAUIUIQ",
        "outputId": "9415f2e1-99f1-4979-a571-64f6cc0f3dcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2210 - loss: 2.3173 - val_accuracy: 0.1304 - val_loss: 1.8296\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2935 - loss: 2.0141 - val_accuracy: 0.1180 - val_loss: 1.8711\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2955 - loss: 1.9037 - val_accuracy: 0.1180 - val_loss: 1.8883\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3211 - loss: 1.7665 - val_accuracy: 0.1304 - val_loss: 1.8602\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3574 - loss: 1.6664 - val_accuracy: 0.1491 - val_loss: 1.8321\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3281 - loss: 1.8292 - val_accuracy: 0.1988 - val_loss: 1.7704\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3901 - loss: 1.5408 - val_accuracy: 0.2484 - val_loss: 1.6900\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3937 - loss: 1.5608 - val_accuracy: 0.2671 - val_loss: 1.5993\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4074 - loss: 1.5122 - val_accuracy: 0.3106 - val_loss: 1.5406\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4368 - loss: 1.4623 - val_accuracy: 0.3416 - val_loss: 1.4837\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3963 - loss: 1.4612 - val_accuracy: 0.3913 - val_loss: 1.4306\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4002 - loss: 1.5165 - val_accuracy: 0.4161 - val_loss: 1.4073\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4174 - loss: 1.5333 - val_accuracy: 0.4286 - val_loss: 1.3695\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4288 - loss: 1.3578 - val_accuracy: 0.4534 - val_loss: 1.3407\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4403 - loss: 1.4785 - val_accuracy: 0.4658 - val_loss: 1.3189\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4491 - loss: 1.3500 - val_accuracy: 0.4534 - val_loss: 1.3203\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4575 - loss: 1.3677 - val_accuracy: 0.4783 - val_loss: 1.3007\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4580 - loss: 1.3377 - val_accuracy: 0.4907 - val_loss: 1.2862\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4883 - loss: 1.3325 - val_accuracy: 0.4907 - val_loss: 1.2596\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4653 - loss: 1.4258 - val_accuracy: 0.5031 - val_loss: 1.2393\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4872 - loss: 1.4687 - val_accuracy: 0.4969 - val_loss: 1.2419\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4552 - loss: 1.3308 - val_accuracy: 0.4969 - val_loss: 1.2434\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5070 - loss: 1.2991 - val_accuracy: 0.4720 - val_loss: 1.2431\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4988 - loss: 1.2837 - val_accuracy: 0.4596 - val_loss: 1.2365\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5026 - loss: 1.2931 - val_accuracy: 0.4845 - val_loss: 1.2286\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4626 - loss: 1.3786 - val_accuracy: 0.4783 - val_loss: 1.2243\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4702 - loss: 1.3395 - val_accuracy: 0.4720 - val_loss: 1.2260\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4872 - loss: 1.2506 - val_accuracy: 0.4907 - val_loss: 1.2234\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5196 - loss: 1.2642 - val_accuracy: 0.4658 - val_loss: 1.2278\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4842 - loss: 1.2466 - val_accuracy: 0.4783 - val_loss: 1.2267\n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5343 - loss: 1.2353 - val_accuracy: 0.5093 - val_loss: 1.2096\n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5056 - loss: 1.2134 - val_accuracy: 0.5031 - val_loss: 1.2067\n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4920 - loss: 1.2637 - val_accuracy: 0.4969 - val_loss: 1.2096\n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5265 - loss: 1.2029 - val_accuracy: 0.4907 - val_loss: 1.2001\n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5256 - loss: 1.2439 - val_accuracy: 0.4969 - val_loss: 1.1966\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5619 - loss: 1.1980 - val_accuracy: 0.4845 - val_loss: 1.1967\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5318 - loss: 1.1421 - val_accuracy: 0.4658 - val_loss: 1.1885\n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5012 - loss: 1.2909 - val_accuracy: 0.4845 - val_loss: 1.1800\n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5499 - loss: 1.2217 - val_accuracy: 0.4845 - val_loss: 1.1869\n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5002 - loss: 1.2346 - val_accuracy: 0.4845 - val_loss: 1.1827\n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5301 - loss: 1.1863 - val_accuracy: 0.5031 - val_loss: 1.1820\n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5042 - loss: 1.1941 - val_accuracy: 0.5155 - val_loss: 1.1789\n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4917 - loss: 1.2108 - val_accuracy: 0.5155 - val_loss: 1.1686\n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5688 - loss: 1.1606 - val_accuracy: 0.5093 - val_loss: 1.1779\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4988 - loss: 1.1673 - val_accuracy: 0.5280 - val_loss: 1.1725\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5224 - loss: 1.2525 - val_accuracy: 0.5093 - val_loss: 1.1741\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5608 - loss: 1.1426 - val_accuracy: 0.5217 - val_loss: 1.1747\n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5123 - loss: 1.2221 - val_accuracy: 0.5217 - val_loss: 1.1823\n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5172 - loss: 1.2047 - val_accuracy: 0.5031 - val_loss: 1.1874\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5439 - loss: 1.0932 - val_accuracy: 0.5093 - val_loss: 1.1932\n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5004 - loss: 1.2361 - val_accuracy: 0.5342 - val_loss: 1.1844\n",
            "Epoch 52/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5468 - loss: 1.1281 - val_accuracy: 0.5342 - val_loss: 1.1764\n",
            "Epoch 53/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5238 - loss: 1.2309 - val_accuracy: 0.5217 - val_loss: 1.1731\n",
            "Epoch 54/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5472 - loss: 1.1777 - val_accuracy: 0.5093 - val_loss: 1.1885\n",
            "Epoch 55/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5206 - loss: 1.1561 - val_accuracy: 0.5155 - val_loss: 1.1770\n",
            "Epoch 56/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4987 - loss: 1.1872 - val_accuracy: 0.5217 - val_loss: 1.1712\n",
            "Epoch 57/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5158 - loss: 1.1506 - val_accuracy: 0.5155 - val_loss: 1.1824\n",
            "Epoch 58/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5279 - loss: 1.1730 - val_accuracy: 0.5155 - val_loss: 1.1818\n"
          ]
        }
      ],
      "source": [
        "es = callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_5 = model_5.fit(\n",
        "    X_train_all, y_train_all,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[es],\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGKrbDREId5Y",
        "outputId": "d8bd7039-5c8a-4762-8e0f-bbc01a646d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "=== RED 5 CLASES  Global ===\n",
            "Accuracy: 0.5373134328358209\n",
            "F1 macro: 0.3583679413794503\n",
            "Matriz de confusi칩n:\n",
            " [[75  9  4  6  2]\n",
            " [ 8 21  7 11  8]\n",
            " [ 3  6  2  2  9]\n",
            " [ 2  4  0  8  7]\n",
            " [ 0  1  1  3  2]]\n",
            "\n",
            "Reporte:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.82        96\n",
            "           1       0.51      0.38      0.44        55\n",
            "           2       0.14      0.09      0.11        22\n",
            "           3       0.27      0.38      0.31        21\n",
            "           4       0.07      0.29      0.11         7\n",
            "\n",
            "    accuracy                           0.54       201\n",
            "   macro avg       0.37      0.38      0.36       201\n",
            "weighted avg       0.59      0.54      0.56       201\n",
            "\n",
            "\n",
            "=== RED 5 CLASES  MUJERES ===\n",
            "N mujeres: 50\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92        37\n",
            "           1       0.44      0.57      0.50         7\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.27      0.30      0.28        50\n",
            "weighted avg       0.74      0.76      0.75        50\n",
            "\n",
            "\n",
            "=== RED 5 CLASES  HOMBRES ===\n",
            "N hombres: 151\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.69      0.75        59\n",
            "           1       0.53      0.35      0.42        48\n",
            "           2       0.14      0.10      0.12        20\n",
            "           3       0.27      0.44      0.33        18\n",
            "           4       0.08      0.33      0.13         6\n",
            "\n",
            "    accuracy                           0.46       151\n",
            "   macro avg       0.37      0.39      0.35       151\n",
            "weighted avg       0.54      0.46      0.49       151\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "\n",
        "y_pred_5 = np.argmax(model_5.predict(X_test_all), axis=1)\n",
        "\n",
        "print(\"=== RED 5 CLASES  Global ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_all, y_pred_5))\n",
        "print(\"F1 macro:\", f1_score(y_test_all, y_pred_5, average=\"macro\"))\n",
        "print(\"Matriz de confusi칩n:\\n\", confusion_matrix(y_test_all, y_pred_5))\n",
        "print(\"\\nReporte:\")\n",
        "print(classification_report(y_test_all, y_pred_5, zero_division=0))\n",
        "\n",
        "# Por sexo\n",
        "sex_test = X_test_all[\"sex\"]  \n",
        "\n",
        "mask_f = (sex_test == 0)\n",
        "mask_m = (sex_test == 1)\n",
        "\n",
        "print(\"\\n=== RED 5 CLASES  MUJERES ===\")\n",
        "print(\"N mujeres:\", mask_f.sum())\n",
        "print(classification_report(y_test_all[mask_f], y_pred_5[mask_f], zero_division=0))\n",
        "\n",
        "print(\"\\n=== RED 5 CLASES  HOMBRES ===\")\n",
        "print(\"N hombres:\", mask_m.sum())\n",
        "print(classification_report(y_test_all[mask_m], y_pred_5[mask_m], zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "id": "tCBPmdgpIvhk"
      },
      "outputs": [],
      "source": [
        "y_train_enf = (y_train_all > 0).astype(int)\n",
        "y_test_enf  = (y_test_all  > 0).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "1cGnr80SIxtK",
        "outputId": "36a7f843-7931-42e7-d6c5-b75106a0ab31"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較늎n",
              "較<span style=\"font-weight: bold\"> Layer (type)                    </span>較<span style=\"font-weight: bold\"> Output Shape           </span>較<span style=\"font-weight: bold\">       Param # </span>較\n",
              "較뫡대較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較뼆n",
              "較 dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             較           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 batch_normalization_14          較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             較           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> 較\n",
              "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            較                        較               較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             較             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             較           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 batch_normalization_15          較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             較            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> 較\n",
              "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            較                        較               較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             較             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              較            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> 較\n",
              "較덕較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較\n",
              "</pre>\n"
            ],
            "text/plain": [
              "較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較늎n",
              "較\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m較\n",
              "較뫡대較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較뼆n",
              "較 dense_21 (\u001b[38;5;33mDense\u001b[0m)                較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             較           \u001b[38;5;34m576\u001b[0m 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 batch_normalization_14          較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             較           \u001b[38;5;34m128\u001b[0m 較\n",
              "較 (\u001b[38;5;33mBatchNormalization\u001b[0m)            較                        較               較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             較             \u001b[38;5;34m0\u001b[0m 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dense_22 (\u001b[38;5;33mDense\u001b[0m)                較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             較           \u001b[38;5;34m528\u001b[0m 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 batch_normalization_15          較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             較            \u001b[38;5;34m64\u001b[0m 較\n",
              "較 (\u001b[38;5;33mBatchNormalization\u001b[0m)            較                        較               較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             較             \u001b[38;5;34m0\u001b[0m 較\n",
              "較럭較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較\n",
              "較 dense_23 (\u001b[38;5;33mDense\u001b[0m)                較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              較            \u001b[38;5;34m17\u001b[0m 較\n",
              "較덕較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313</span> (5.13 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,313\u001b[0m (5.13 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,217</span> (4.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,217\u001b[0m (4.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def build_mlp_binary(input_dim):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(input_dim,)))\n",
        "    model.add(layers.Dense(32, activation=\"relu\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(16, activation=\"relu\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model_enf = build_mlp_binary(n_features)\n",
        "model_enf.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoS0vM-sI0HV",
        "outputId": "b2921508-b109-4209-d749-32f7ac2b75ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{np.int64(0): np.float64(1.0511811023622046),\n",
              " np.int64(1): np.float64(0.9535714285714286)}"
            ]
          },
          "execution_count": 305,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes_enf = np.unique(y_train_enf)\n",
        "class_weights_enf = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=classes_enf,\n",
        "    y=y_train_enf\n",
        ")\n",
        "cw_enf = {cls: w for cls, w in zip(classes_enf, class_weights_enf)}\n",
        "cw_enf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkW9s9atI2p1",
        "outputId": "678b4b89-9b6a-4b84-f169-9f430505545b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5702 - loss: 0.8867 - val_accuracy: 0.7329 - val_loss: 0.6219\n",
            "Epoch 2/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5887 - loss: 0.7721 - val_accuracy: 0.7019 - val_loss: 0.5916\n",
            "Epoch 3/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6837 - loss: 0.6129 - val_accuracy: 0.7267 - val_loss: 0.5688\n",
            "Epoch 4/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6672 - loss: 0.6064 - val_accuracy: 0.7329 - val_loss: 0.5485\n",
            "Epoch 5/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7057 - loss: 0.5793 - val_accuracy: 0.7267 - val_loss: 0.5327\n",
            "Epoch 6/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7402 - loss: 0.5250 - val_accuracy: 0.7391 - val_loss: 0.5191\n",
            "Epoch 7/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7892 - loss: 0.4752 - val_accuracy: 0.7516 - val_loss: 0.5057\n",
            "Epoch 8/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7567 - loss: 0.5171 - val_accuracy: 0.7764 - val_loss: 0.4868\n",
            "Epoch 9/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7338 - loss: 0.5210 - val_accuracy: 0.7826 - val_loss: 0.4792\n",
            "Epoch 10/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7773 - loss: 0.4828 - val_accuracy: 0.7950 - val_loss: 0.4664\n",
            "Epoch 11/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7516 - loss: 0.5195 - val_accuracy: 0.8012 - val_loss: 0.4585\n",
            "Epoch 12/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7963 - loss: 0.4436 - val_accuracy: 0.7950 - val_loss: 0.4483\n",
            "Epoch 13/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8092 - loss: 0.4516 - val_accuracy: 0.8012 - val_loss: 0.4379\n",
            "Epoch 14/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8010 - loss: 0.4402 - val_accuracy: 0.8012 - val_loss: 0.4336\n",
            "Epoch 15/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7699 - loss: 0.4681 - val_accuracy: 0.8012 - val_loss: 0.4293\n",
            "Epoch 16/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7733 - loss: 0.4739 - val_accuracy: 0.8137 - val_loss: 0.4260\n",
            "Epoch 17/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8098 - loss: 0.4282 - val_accuracy: 0.8199 - val_loss: 0.4236\n",
            "Epoch 18/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8156 - loss: 0.4351 - val_accuracy: 0.8199 - val_loss: 0.4223\n",
            "Epoch 19/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8348 - loss: 0.3879 - val_accuracy: 0.8199 - val_loss: 0.4214\n",
            "Epoch 20/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7958 - loss: 0.4123 - val_accuracy: 0.8261 - val_loss: 0.4190\n",
            "Epoch 21/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8090 - loss: 0.4083 - val_accuracy: 0.8261 - val_loss: 0.4191\n",
            "Epoch 22/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7863 - loss: 0.4586 - val_accuracy: 0.8323 - val_loss: 0.4204\n",
            "Epoch 23/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8064 - loss: 0.4250 - val_accuracy: 0.8323 - val_loss: 0.4208\n",
            "Epoch 24/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7878 - loss: 0.4694 - val_accuracy: 0.8323 - val_loss: 0.4210\n",
            "Epoch 25/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8031 - loss: 0.4420 - val_accuracy: 0.8199 - val_loss: 0.4227\n",
            "Epoch 26/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7930 - loss: 0.4665 - val_accuracy: 0.8199 - val_loss: 0.4232\n",
            "Epoch 27/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8224 - loss: 0.4196 - val_accuracy: 0.8199 - val_loss: 0.4239\n",
            "Epoch 28/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7876 - loss: 0.4665 - val_accuracy: 0.8137 - val_loss: 0.4245\n",
            "Epoch 29/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7713 - loss: 0.4631 - val_accuracy: 0.8199 - val_loss: 0.4268\n",
            "Epoch 30/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8082 - loss: 0.3986 - val_accuracy: 0.8137 - val_loss: 0.4274\n",
            "Epoch 31/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 0.3646 - val_accuracy: 0.8261 - val_loss: 0.4232\n",
            "Epoch 32/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7826 - loss: 0.4302 - val_accuracy: 0.8261 - val_loss: 0.4215\n",
            "Epoch 33/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8027 - loss: 0.4355 - val_accuracy: 0.8199 - val_loss: 0.4179\n",
            "Epoch 34/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8428 - loss: 0.3688 - val_accuracy: 0.8199 - val_loss: 0.4190\n",
            "Epoch 35/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8334 - loss: 0.3801 - val_accuracy: 0.8261 - val_loss: 0.4229\n",
            "Epoch 36/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7753 - loss: 0.4495 - val_accuracy: 0.8199 - val_loss: 0.4264\n",
            "Epoch 37/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8213 - loss: 0.3898 - val_accuracy: 0.8199 - val_loss: 0.4284\n",
            "Epoch 38/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8284 - loss: 0.3676 - val_accuracy: 0.8137 - val_loss: 0.4282\n",
            "Epoch 39/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8250 - loss: 0.4047 - val_accuracy: 0.8199 - val_loss: 0.4299\n",
            "Epoch 40/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8261 - loss: 0.4023 - val_accuracy: 0.8137 - val_loss: 0.4315\n",
            "Epoch 41/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8153 - loss: 0.3757 - val_accuracy: 0.8075 - val_loss: 0.4340\n",
            "Epoch 42/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8053 - loss: 0.4360 - val_accuracy: 0.8137 - val_loss: 0.4338\n",
            "Epoch 43/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8021 - loss: 0.4462 - val_accuracy: 0.8199 - val_loss: 0.4356\n",
            "Epoch 44/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8282 - loss: 0.3880 - val_accuracy: 0.8261 - val_loss: 0.4379\n",
            "Epoch 45/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8026 - loss: 0.4151 - val_accuracy: 0.8199 - val_loss: 0.4391\n",
            "Epoch 46/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7934 - loss: 0.4259 - val_accuracy: 0.8199 - val_loss: 0.4413\n",
            "Epoch 47/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8309 - loss: 0.4230 - val_accuracy: 0.8199 - val_loss: 0.4359\n",
            "Epoch 48/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8214 - loss: 0.4083 - val_accuracy: 0.8261 - val_loss: 0.4374\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "=== NN Modelo 1: ENFERMO vs SANO ===\n",
            "Accuracy: 0.8507462686567164\n",
            "F1 macro: 0.8501193080135216\n",
            "[[79 17]\n",
            " [13 92]]\n",
            "\n",
            "Reporte:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84        96\n",
            "           1       0.84      0.88      0.86       105\n",
            "\n",
            "    accuracy                           0.85       201\n",
            "   macro avg       0.85      0.85      0.85       201\n",
            "weighted avg       0.85      0.85      0.85       201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "es = callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_enf = model_enf.fit(\n",
        "    X_train_all, y_train_enf,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    class_weight=cw_enf,\n",
        "    callbacks=[es],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "proba_enf_test = model_enf.predict(X_test_all).ravel()\n",
        "y_pred_enf = (proba_enf_test >= 0.5).astype(int)\n",
        "\n",
        "print(\"=== NN Modelo 1: ENFERMO vs SANO ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_enf, y_pred_enf))\n",
        "print(\"F1 macro:\", f1_score(y_test_enf, y_pred_enf, average=\"macro\"))\n",
        "print(confusion_matrix(y_test_enf, y_pred_enf))\n",
        "print(\"\\nReporte:\")\n",
        "print(classification_report(y_test_enf, y_pred_enf, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRxwoImkI9lS",
        "outputId": "b2e23e7f-3c1a-412b-ef46-804193c16b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== NN Modelo 1  MUJERES ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95        37\n",
            "           1       0.91      0.77      0.83        13\n",
            "\n",
            "    accuracy                           0.92        50\n",
            "   macro avg       0.92      0.87      0.89        50\n",
            "weighted avg       0.92      0.92      0.92        50\n",
            "\n",
            "\n",
            "=== NN Modelo 1  HOMBRES ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.73      0.77        59\n",
            "           1       0.84      0.89      0.86        92\n",
            "\n",
            "    accuracy                           0.83       151\n",
            "   macro avg       0.82      0.81      0.82       151\n",
            "weighted avg       0.83      0.83      0.83       151\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== NN Modelo 1  MUJERES ===\")\n",
        "print(classification_report(y_test_enf[mask_f], y_pred_enf[mask_f], zero_division=0))\n",
        "\n",
        "print(\"\\n=== NN Modelo 1  HOMBRES ===\")\n",
        "print(classification_report(y_test_enf[mask_m], y_pred_enf[mask_m], zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJpJW1FkJBfT",
        "outputId": "20d5fcda-bc24-41f0-db8d-80ee05bc0221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pacientes enfermos: train = 420 test = 105\n",
            "Distribuci칩n grados (train):\n",
            "label\n",
            "1    221\n",
            "2     86\n",
            "3     86\n",
            "4     27\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "mask_train_enf = (y_train_all > 0)\n",
        "mask_test_enf  = (y_test_all  > 0)\n",
        "\n",
        "X_train_enf2 = X_train_all[mask_train_enf].copy()\n",
        "y_train_label_enf = y_train_all[mask_train_enf].copy()\n",
        "\n",
        "X_test_enf2 = X_test_all[mask_test_enf].copy()\n",
        "y_test_label_enf = y_test_all[mask_test_enf].copy()\n",
        "\n",
        "print(\"Pacientes enfermos: train =\", len(X_train_enf2), \"test =\", len(X_test_enf2))\n",
        "print(\"Distribuci칩n grados (train):\")\n",
        "print(y_train_label_enf.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5BudOvKJEBY",
        "outputId": "a8e73354-9d60-4df0-adce-59fc2bfe32e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distrib train grave vs no grave:\n",
            "label\n",
            "0    307\n",
            "1    113\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "y_train_grave = (y_train_label_enf >= 3).astype(int)\n",
        "y_test_grave  = (y_test_label_enf  >= 3).astype(int)\n",
        "\n",
        "print(\"Distrib train grave vs no grave:\")\n",
        "print(y_train_grave.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2Grb7nFJHXV",
        "outputId": "4d1fda08-b426-4cb4-b248-d89a9b88ff34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{np.int64(0): np.float64(0.6840390879478827),\n",
              " np.int64(1): np.float64(1.8584070796460177)}"
            ]
          },
          "execution_count": 310,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes_grave = np.unique(y_train_grave)\n",
        "class_weights_grave = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=classes_grave,\n",
        "    y=y_train_grave\n",
        ")\n",
        "cw_grave = {cls: w for cls, w in zip(classes_grave, class_weights_grave)}\n",
        "cw_grave\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xE9kZkfJJz6",
        "outputId": "d2fa5af2-79ae-4ef8-f00e-e142a779169f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.4961 - loss: 0.9197 - val_accuracy: 0.3571 - val_loss: 0.7799\n",
            "Epoch 2/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5462 - loss: 0.7869 - val_accuracy: 0.4167 - val_loss: 0.7525\n",
            "Epoch 3/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5341 - loss: 0.7586 - val_accuracy: 0.4405 - val_loss: 0.7304\n",
            "Epoch 4/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5590 - loss: 0.7337 - val_accuracy: 0.4643 - val_loss: 0.7157\n",
            "Epoch 5/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5630 - loss: 0.7026 - val_accuracy: 0.5476 - val_loss: 0.7047\n",
            "Epoch 6/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5212 - loss: 0.7714 - val_accuracy: 0.5476 - val_loss: 0.7018\n",
            "Epoch 7/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5495 - loss: 0.7357 - val_accuracy: 0.5714 - val_loss: 0.6977\n",
            "Epoch 8/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5545 - loss: 0.7190 - val_accuracy: 0.5595 - val_loss: 0.6889\n",
            "Epoch 9/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5427 - loss: 0.7383 - val_accuracy: 0.6071 - val_loss: 0.6821\n",
            "Epoch 10/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5289 - loss: 0.7104 - val_accuracy: 0.5952 - val_loss: 0.6780\n",
            "Epoch 11/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6125 - loss: 0.6960 - val_accuracy: 0.6071 - val_loss: 0.6737\n",
            "Epoch 12/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6247 - loss: 0.6199 - val_accuracy: 0.6190 - val_loss: 0.6740\n",
            "Epoch 13/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5774 - loss: 0.6744 - val_accuracy: 0.5714 - val_loss: 0.6760\n",
            "Epoch 14/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5844 - loss: 0.6927 - val_accuracy: 0.5595 - val_loss: 0.6742\n",
            "Epoch 15/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6475 - loss: 0.6229 - val_accuracy: 0.5595 - val_loss: 0.6743\n",
            "Epoch 16/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6415 - loss: 0.6053 - val_accuracy: 0.5595 - val_loss: 0.6724\n",
            "Epoch 17/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6485 - loss: 0.5999 - val_accuracy: 0.5476 - val_loss: 0.6726\n",
            "Epoch 18/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5993 - loss: 0.6589 - val_accuracy: 0.5595 - val_loss: 0.6708\n",
            "Epoch 19/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6319 - loss: 0.6710 - val_accuracy: 0.5833 - val_loss: 0.6661\n",
            "Epoch 20/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6289 - loss: 0.6216 - val_accuracy: 0.5833 - val_loss: 0.6610\n",
            "Epoch 21/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5929 - loss: 0.6805 - val_accuracy: 0.5833 - val_loss: 0.6539\n",
            "Epoch 22/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5857 - loss: 0.6696 - val_accuracy: 0.5714 - val_loss: 0.6500\n",
            "Epoch 23/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6314 - loss: 0.6125 - val_accuracy: 0.5714 - val_loss: 0.6467\n",
            "Epoch 24/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6189 - loss: 0.6366 - val_accuracy: 0.5595 - val_loss: 0.6447\n",
            "Epoch 25/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6204 - loss: 0.5914 - val_accuracy: 0.5595 - val_loss: 0.6433\n",
            "Epoch 26/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6045 - loss: 0.6821 - val_accuracy: 0.5714 - val_loss: 0.6476\n",
            "Epoch 27/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6614 - loss: 0.6575 - val_accuracy: 0.5714 - val_loss: 0.6490\n",
            "Epoch 28/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7139 - loss: 0.6015 - val_accuracy: 0.5833 - val_loss: 0.6478\n",
            "Epoch 29/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6554 - loss: 0.5993 - val_accuracy: 0.5833 - val_loss: 0.6466\n",
            "Epoch 30/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6421 - loss: 0.6531 - val_accuracy: 0.6071 - val_loss: 0.6428\n",
            "Epoch 31/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6237 - loss: 0.6374 - val_accuracy: 0.6071 - val_loss: 0.6424\n",
            "Epoch 32/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6504 - loss: 0.6307 - val_accuracy: 0.6190 - val_loss: 0.6419\n",
            "Epoch 33/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6451 - loss: 0.6592 - val_accuracy: 0.6190 - val_loss: 0.6389\n",
            "Epoch 34/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5915 - loss: 0.6628 - val_accuracy: 0.6429 - val_loss: 0.6365\n",
            "Epoch 35/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5655 - loss: 0.6409 - val_accuracy: 0.6429 - val_loss: 0.6356\n",
            "Epoch 36/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6390 - loss: 0.6691 - val_accuracy: 0.6429 - val_loss: 0.6355\n",
            "Epoch 37/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6225 - loss: 0.6233 - val_accuracy: 0.6429 - val_loss: 0.6337\n",
            "Epoch 38/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6782 - loss: 0.6187 - val_accuracy: 0.6429 - val_loss: 0.6341\n",
            "Epoch 39/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5988 - loss: 0.6476 - val_accuracy: 0.6310 - val_loss: 0.6316\n",
            "Epoch 40/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6379 - loss: 0.6118 - val_accuracy: 0.6310 - val_loss: 0.6312\n",
            "Epoch 41/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6560 - loss: 0.6177 - val_accuracy: 0.6310 - val_loss: 0.6342\n",
            "Epoch 42/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6478 - loss: 0.6184 - val_accuracy: 0.6310 - val_loss: 0.6344\n",
            "Epoch 43/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6647 - loss: 0.6220 - val_accuracy: 0.6190 - val_loss: 0.6371\n",
            "Epoch 44/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6192 - loss: 0.6178 - val_accuracy: 0.6310 - val_loss: 0.6378\n",
            "Epoch 45/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6905 - loss: 0.5979 - val_accuracy: 0.6190 - val_loss: 0.6408\n",
            "Epoch 46/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6692 - loss: 0.6572 - val_accuracy: 0.6310 - val_loss: 0.6380\n",
            "Epoch 47/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.6931 - loss: 0.5808 - val_accuracy: 0.6310 - val_loss: 0.6358\n",
            "Epoch 48/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6805 - loss: 0.6100 - val_accuracy: 0.6071 - val_loss: 0.6363\n",
            "Epoch 49/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6374 - loss: 0.6095 - val_accuracy: 0.5952 - val_loss: 0.6393\n",
            "Epoch 50/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6496 - loss: 0.6064 - val_accuracy: 0.5952 - val_loss: 0.6396\n",
            "Epoch 51/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6993 - loss: 0.5714 - val_accuracy: 0.5952 - val_loss: 0.6395\n",
            "Epoch 52/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6854 - loss: 0.5977 - val_accuracy: 0.5952 - val_loss: 0.6411\n",
            "Epoch 53/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6700 - loss: 0.6199 - val_accuracy: 0.6190 - val_loss: 0.6402\n",
            "Epoch 54/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6629 - loss: 0.6012 - val_accuracy: 0.6310 - val_loss: 0.6421\n",
            "Epoch 55/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6535 - loss: 0.6027 - val_accuracy: 0.5952 - val_loss: 0.6443\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "=== NN Modelo 2: GRAVE vs NO GRAVE (solo enfermos) ===\n",
            "Accuracy: 0.638095238095238\n",
            "F1 macro: 0.6035373608903021\n",
            "[[49 28]\n",
            " [10 18]]\n",
            "\n",
            "Reporte:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.64      0.72        77\n",
            "           1       0.39      0.64      0.49        28\n",
            "\n",
            "    accuracy                           0.64       105\n",
            "   macro avg       0.61      0.64      0.60       105\n",
            "weighted avg       0.71      0.64      0.66       105\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_grave = build_mlp_binary(n_features)\n",
        "\n",
        "es2 = callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_grave = model_grave.fit(\n",
        "    X_train_enf2, y_train_grave,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    class_weight=cw_grave,\n",
        "    callbacks=[es2],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "proba_grave_test = model_grave.predict(X_test_enf2).ravel()\n",
        "y_pred_grave = (proba_grave_test >= 0.5).astype(int)\n",
        "\n",
        "print(\"=== NN Modelo 2: GRAVE vs NO GRAVE (solo enfermos) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_grave, y_pred_grave))\n",
        "print(\"F1 macro:\", f1_score(y_test_grave, y_pred_grave, average=\"macro\"))\n",
        "print(confusion_matrix(y_test_grave, y_pred_grave))\n",
        "print(\"\\nReporte:\")\n",
        "print(classification_report(y_test_grave, y_pred_grave, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL4LXi30LIyr"
      },
      "source": [
        "# A침adimos cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs-0gTZWLLVS",
        "outputId": "ad5ae985-2289-4ee9-c47f-84eb6dbb9624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas originales: 732\n",
            "Filas de refuerzo (Statlog): 270\n",
            "Total pacientes: 1002\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "df_train = pd.read_csv('/train_IA_PROJECT.csv')\n",
        "df_statlog = pd.read_csv('/statlog_limpio.csv')\n",
        "\n",
        "print(f\"Filas originales: {len(df_train)}\")\n",
        "print(f\"Filas de refuerzo (Statlog): {len(df_statlog)}\")\n",
        "\n",
        "df_total = pd.concat([df_train, df_statlog], ignore_index=True)\n",
        "print(f\"Total pacientes: {len(df_total)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "id": "3jcQhSl6LP48"
      },
      "outputs": [],
      "source": [
        "df = df_total.copy()\n",
        "\n",
        "# Columnas donde sabemos que -9 significa \"prueba no realizada\"\n",
        "cols_not_done_num = ['chol']               # num칠ricas\n",
        "cols_not_done_cat = ['slope', 'ca', 'thal']  # categ칩ricas 13/03/37\n",
        "\n",
        "for col in cols_not_done_num + cols_not_done_cat:\n",
        "    mask_nd = df[col].astype(str).isin(['-9', '-9.0'])\n",
        "    df[col + '_not_done'] = mask_nd.astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAgMqCtvLScu"
      },
      "outputs": [],
      "source": [
        "df['fbs_not_done'] = df['fbs'].astype(str).isin(['-9', '-9.0']).astype(int)\n",
        "df['fbs'] = df['fbs'].replace(['-9', '-9.0'], 0)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "id": "IfGcCaKALUY7"
      },
      "outputs": [],
      "source": [
        "df.replace('?', np.nan, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "D7VIQGHKLWcM"
      },
      "outputs": [],
      "source": [
        "num_cols_all = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
        "                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'label']\n",
        "\n",
        "for col in num_cols_all:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "id": "g8K7ReaALYeZ"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset=['label'])\n",
        "df['label'] = df['label'].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "id": "uubZ5odXLaS0"
      },
      "outputs": [],
      "source": [
        "cont_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']  # continuas 락iom칠tricas렢n",
        "cat_cols  = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']  # cl칤nicas codificadas\n",
        "\n",
        "not_done_cols = [c + '_not_done' for c in cols_not_done_num + cols_not_done_cat] + ['fbs_not_done']\n",
        "target_col = 'label'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "id": "QpVKJYRwLcNt"
      },
      "outputs": [],
      "source": [
        "df.loc[df['trestbps'] == 0, 'trestbps'] = np.nan\n",
        "df.loc[df['chol'] == 0,      'chol']     = np.nan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkTX0f6cLfWg"
      },
      "outputs": [],
      "source": [
        "for col in ['slope', 'ca', 'thal']:\n",
        "    \n",
        "    df[col] = df[col].fillna(-1)  # -1 = categor칤a \"no disponible / no realizada\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "id": "JBMphpt-LhVV"
      },
      "outputs": [],
      "source": [
        "# N칰mero de pruebas cr칤ticas NO realizadas\n",
        "df['n_advanced_not_done'] = df[['chol_not_done', 'slope_not_done', 'ca_not_done', 'thal_not_done']].sum(axis=1)\n",
        "\n",
        "# Proporci칩n respecto al m치ximo posible (4 en este caso)\n",
        "df['prop_advanced_not_done'] = df['n_advanced_not_done'] / 4.0\n",
        "\n",
        "# N칰mero total de pruebas con -9 en todo el registro (incluyendo fbs)\n",
        "df['n_total_not_done'] = df[not_done_cols].sum(axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {
        "id": "c8k8BppDLj8P"
      },
      "outputs": [],
      "source": [
        "extra_cols = ['n_advanced_not_done', 'prop_advanced_not_done', 'n_total_not_done']\n",
        "features = cont_cols + cat_cols + not_done_cols + extra_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtS72wJrLlqX",
        "outputId": "15fb201e-5d9b-49de-b5f9-7146077304ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN en continuas tras KNN:\n",
            "age         0\n",
            "trestbps    0\n",
            "chol        0\n",
            "thalach     0\n",
            "oldpeak     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "df_imp = df.copy()\n",
        "\n",
        "knn_imp = KNNImputer(n_neighbors=5)\n",
        "df_imp[cont_cols] = knn_imp.fit_transform(df_imp[cont_cols])\n",
        "\n",
        "print(\"NaN en continuas tras KNN:\")\n",
        "print(df_imp[cont_cols].isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGbeGTGCLnbM",
        "outputId": "8e00dbf6-53b3-4576-a21a-7ed1d2eeff20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN en cat tras moda:\n",
            "sex        0\n",
            "cp         0\n",
            "fbs        0\n",
            "restecg    0\n",
            "exang      0\n",
            "slope      0\n",
            "ca         0\n",
            "thal       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3958482152.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_imp[col].fillna(moda, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "for col in ['sex', 'cp', 'fbs', 'restecg', 'exang']:\n",
        "    moda = df_imp[col].mode()[0]\n",
        "    df_imp[col].fillna(moda, inplace=True)\n",
        "\n",
        "print(\"NaN en cat tras moda:\")\n",
        "print(df_imp[cat_cols].isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFGuYBVlLpax",
        "outputId": "389cc47d-c39e-4581-a2ee-07ce490b1e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci칩n original clases y_train:\n",
            "label\n",
            "0    381\n",
            "1    221\n",
            "2     86\n",
            "3     86\n",
            "4     27\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribuci칩n clases tras SMOTENC:\n",
            "label\n",
            "0    381\n",
            "1    381\n",
            "2    381\n",
            "3    381\n",
            "4    381\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "X = df_imp[features]\n",
        "y = df_imp[target_col].astype(int)\n",
        "\n",
        "feature_cols = features\n",
        "\n",
        "\n",
        "cat_for_smote = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'] + not_done_cols\n",
        "cat_indices = [feature_cols.index(c) for c in cat_for_smote]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Distribuci칩n original clases y_train:\")\n",
        "print(y_train.value_counts().sort_index())\n",
        "\n",
        "smote_nc = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',\n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train_res, y_train_res = smote_nc.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nDistribuci칩n clases tras SMOTENC:\")\n",
        "print(y_train_res.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y1_P3fdLuU1",
        "outputId": "96d9a1fa-9644-4195-ad5b-0b1b05667515"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:28:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "RESULTADOS XGBOOST con features de PRUEBAS NO HECHAS\n",
            "Accuracy:  0.6070\n",
            "F1 micro:  0.6070\n",
            "F1 macro:  0.4152\n",
            "========================================\n",
            "\n",
            "Matriz de confusi칩n:\n",
            "[[85  4  6  1  0]\n",
            " [ 3 26 13 13  0]\n",
            " [ 3  6  6  5  2]\n",
            " [ 3 11  2  3  2]\n",
            " [ 1  2  0  2  2]]\n",
            "\n",
            "Reporte global:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89        96\n",
            "           1       0.53      0.47      0.50        55\n",
            "           2       0.22      0.27      0.24        22\n",
            "           3       0.12      0.14      0.13        21\n",
            "           4       0.33      0.29      0.31         7\n",
            "\n",
            "    accuracy                           0.61       201\n",
            "   macro avg       0.42      0.41      0.42       201\n",
            "weighted avg       0.62      0.61      0.61       201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=5,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"RESULTADOS XGBOOST con features de PRUEBAS NO HECHAS\")\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"F1 micro:  {f1_micro:.4f}\")\n",
        "print(f\"F1 macro:  {f1_macro:.4f}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "print(\"\\nMatriz de confusi칩n:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nReporte global:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA1eEzyyMHOM"
      },
      "source": [
        "# Comparacion de modelos a침adiendo columnas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "id": "r-FBH2xsMKQY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "def evaluar_modelo(nombre, modelo, X_train, y_train, X_test, y_test):\n",
        "    print(f\"\\n{'='*20} {nombre} {'='*20}\")\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
        "    f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
        "\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"F1 micro: {f1_micro:.4f}\")\n",
        "    print(f\"F1 macro: {f1_macro:.4f}\")\n",
        "    print(\"\\nMatriz de confusi칩n:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\nReporte de clasificaci칩n:\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "    return acc, f1_macro\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DR4PAvtMN35",
        "outputId": "214fe081-49f9-4460-860f-5ecce147eebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== Logistic Regression multinomial ====================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 0.5522\n",
            "F1 micro: 0.5522\n",
            "F1 macro: 0.3698\n",
            "\n",
            "Matriz de confusi칩n:\n",
            "[[75 10  4  6  1]\n",
            " [11 25  9  9  1]\n",
            " [ 2  8  2  6  4]\n",
            " [ 1  4  2  7  7]\n",
            " [ 0  3  1  1  2]]\n",
            "\n",
            "Reporte de clasificaci칩n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.78      0.81        96\n",
            "           1       0.50      0.45      0.48        55\n",
            "           2       0.11      0.09      0.10        22\n",
            "           3       0.24      0.33      0.28        21\n",
            "           4       0.13      0.29      0.18         7\n",
            "\n",
            "    accuracy                           0.55       201\n",
            "   macro avg       0.37      0.39      0.37       201\n",
            "weighted avg       0.58      0.55      0.56       201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(\n",
        "    multi_class=\"multinomial\",\n",
        "    class_weight=\"balanced\",  # importante por el desbalanceo\n",
        "    max_iter=30000,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "acc_lr, f1_lr = evaluar_modelo(\n",
        "    \"Logistic Regression multinomial\",\n",
        "    log_reg,\n",
        "    X_train_res, y_train_res,\n",
        "    X_test, y_test\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxLr4BCZMRbd",
        "outputId": "008ac9b6-65d9-4238-c759-a5a38b4b9fda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== Random Forest ====================\n",
            "Accuracy : 0.6169\n",
            "F1 micro: 0.6169\n",
            "F1 macro: 0.4400\n",
            "\n",
            "Matriz de confusi칩n:\n",
            "[[84  6  2  3  1]\n",
            " [ 4 24 14 13  0]\n",
            " [ 3  7  5  4  3]\n",
            " [ 2  8  0  9  2]\n",
            " [ 1  2  0  2  2]]\n",
            "\n",
            "Reporte de clasificaci칩n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.88        96\n",
            "           1       0.51      0.44      0.47        55\n",
            "           2       0.24      0.23      0.23        22\n",
            "           3       0.29      0.43      0.35        21\n",
            "           4       0.25      0.29      0.27         7\n",
            "\n",
            "    accuracy                           0.62       201\n",
            "   macro avg       0.44      0.45      0.44       201\n",
            "weighted avg       0.63      0.62      0.62       201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=10000,\n",
        "    max_depth=None,          \n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=3,\n",
        "    class_weight=\"balanced_subsample\",  \n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "acc_rf, f1_rf = evaluar_modelo(\n",
        "    \"Random Forest\",\n",
        "    rf,\n",
        "    X_train_res, y_train_res,\n",
        "    X_test, y_test\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e6h27FNMw7q",
        "outputId": "9dce02ae-3bd4-4792-e897-c25e3e0ff216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== Gradient Boosting (sklearn) ====================\n",
            "Accuracy : 0.5970\n",
            "F1 micro: 0.5970\n",
            "F1 macro: 0.4207\n",
            "\n",
            "Matriz de confusi칩n:\n",
            "[[80  9  4  3  0]\n",
            " [ 4 29 10 12  0]\n",
            " [ 3  7  5  5  2]\n",
            " [ 3  9  4  4  1]\n",
            " [ 0  2  1  2  2]]\n",
            "\n",
            "Reporte de clasificaci칩n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.83      0.86        96\n",
            "           1       0.52      0.53      0.52        55\n",
            "           2       0.21      0.23      0.22        22\n",
            "           3       0.15      0.19      0.17        21\n",
            "           4       0.40      0.29      0.33         7\n",
            "\n",
            "    accuracy                           0.60       201\n",
            "   macro avg       0.43      0.41      0.42       201\n",
            "weighted avg       0.62      0.60      0.61       201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "acc_gb, f1_gb = evaluar_modelo(\n",
        "    \"Gradient Boosting (sklearn)\",\n",
        "    gb,\n",
        "    X_train_res, y_train_res,\n",
        "    X_test, y_test\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gd1uoPQPesj"
      },
      "source": [
        "# ML para mujeres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxSn81rWPg8i"
      },
      "outputs": [],
      "source": [
        "df = df_imp.copy()  \n",
        "features_base = cont_cols + cat_cols + not_done_cols  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "tTOebMR6PkGU"
      },
      "outputs": [],
      "source": [
        "# Flags de pruebas an칩malas\n",
        "df[\"hi_bp\"]       = (df[\"trestbps\"] >= 140).astype(int)   # hipertensi칩n\n",
        "df[\"hi_chol\"]     = (df[\"chol\"]     >= 240).astype(int)   # colesterol alto\n",
        "df[\"hi_oldpeak\"]  = (df[\"oldpeak\"]  >= 2.0).astype(int)   # ST muy deprimido\n",
        "df[\"low_thalach\"] = (df[\"thalach\"]  <= 120).astype(int)   # FC m치xima baja (mala tolerancia)\n",
        "df[\"age_gt_60\"]   = (df[\"age\"]      >= 60).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIw6nUm8Pswp"
      },
      "outputs": [],
      "source": [
        "risk_flags = [\"hi_bp\", \"hi_chol\", \"hi_oldpeak\", \"low_thalach\", \"age_gt_60\"]\n",
        "df[\"n_risk_factors\"] = df[risk_flags].sum(axis=1)\n",
        "\n",
        "\n",
        "advanced_not_done = [c for c in df.columns if c.endswith(\"_not_done\") and c.split(\"_\")[0] in [\"chol\",\"slope\",\"ca\",\"thal\"]]\n",
        "\n",
        "df[\"n_advanced_not_done\"]   = df[advanced_not_done].sum(axis=1)\n",
        "df[\"prop_advanced_not_done\"] = df[\"n_advanced_not_done\"] / len(advanced_not_done)\n",
        "\n",
        "# N칰mero total de pruebas con -9 / no realizadas\n",
        "not_done_cols = [c for c in df.columns if c.endswith(\"_not_done\")]\n",
        "df[\"n_total_not_done\"] = df[not_done_cols].sum(axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "AD9NpGABPwPE"
      },
      "outputs": [],
      "source": [
        "df[\"age_x_chol\"]     = df[\"age\"] * df[\"chol\"]\n",
        "df[\"age_x_trestbps\"] = df[\"age\"] * df[\"trestbps\"]\n",
        "df[\"bp_x_oldpeak\"]   = df[\"trestbps\"] * df[\"oldpeak\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "XQisVAIJPyVK"
      },
      "outputs": [],
      "source": [
        "extra_feats = risk_flags + [\n",
        "    \"n_risk_factors\",\n",
        "    \"n_advanced_not_done\",\n",
        "    \"prop_advanced_not_done\",\n",
        "    \"n_total_not_done\",\n",
        "    \"age_x_chol\",\n",
        "    \"age_x_trestbps\",\n",
        "    \"bp_x_oldpeak\"\n",
        "]\n",
        "\n",
        "features_fe = features_base + extra_feats\n",
        "\n",
        "X = df[features_fe]\n",
        "y = df[\"label\"].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmPc2Tu6P0gx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cat_for_smote = cat_cols + not_done_cols  \n",
        "cat_indices = [features_fe.index(c) for c in cat_for_smote]\n",
        "\n",
        "smote_nc = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',\n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train_res, y_train_res = smote_nc.fit_resample(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0upOYbKP2_W",
        "outputId": "487d78f4-9a3f-429d-e7f1-355d1b1b35dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:30:21] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6169154228855721\n",
            "F1 macro: 0.41732719457913336\n",
            "[[84  6  5  1  0]\n",
            " [ 2 26 14 13  0]\n",
            " [ 3  8  5  2  4]\n",
            " [ 2  9  1  8  1]\n",
            " [ 1  3  0  2  1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89        96\n",
            "           1       0.50      0.47      0.49        55\n",
            "           2       0.20      0.23      0.21        22\n",
            "           3       0.31      0.38      0.34        21\n",
            "           4       0.17      0.14      0.15         7\n",
            "\n",
            "    accuracy                           0.62       201\n",
            "   macro avg       0.42      0.42      0.42       201\n",
            "weighted avg       0.63      0.62      0.62       201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "xgb_fe = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=5,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_fe.fit(X_train_res, y_train_res)\n",
        "\n",
        "y_pred = xgb_fe.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1 macro:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh-kLdSDP9AT",
        "outputId": "5396c854-1d9e-408e-9ac6-e13dcd1d9e8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp                        0.099878\n",
            "prop_advanced_not_done    0.071607\n",
            "sex                       0.054745\n",
            "slope_not_done            0.048331\n",
            "thal_not_done             0.043965\n",
            "ca                        0.042906\n",
            "oldpeak                   0.039355\n",
            "n_advanced_not_done       0.038428\n",
            "fbs                       0.036980\n",
            "slope                     0.035172\n",
            "bp_x_oldpeak              0.033740\n",
            "restecg                   0.033369\n",
            "hi_oldpeak                0.033334\n",
            "exang                     0.030704\n",
            "hi_bp                     0.028844\n",
            "n_total_not_done          0.028373\n",
            "thalach                   0.028218\n",
            "age_x_trestbps            0.028104\n",
            "n_risk_factors            0.027152\n",
            "age_x_chol                0.026610\n",
            "dtype: float32\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "importancias = pd.Series(xgb_fe.feature_importances_, index=features_fe)\n",
        "print(importancias.sort_values(ascending=False).head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgWJ9wGKQIpB",
        "outputId": "636af896-4096-4dd9-e68d-1bd5ca09cd96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci칩n de clases en mujeres:\n",
            "label\n",
            "0    182\n",
            "1     39\n",
            "2      9\n",
            "3      8\n",
            "4      3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "X = df[features_fe]\n",
        "y = df[\"label\"].astype(int)\n",
        "\n",
        "mask_female = (df[\"sex\"] == 0)\n",
        "X_female = X[mask_female].copy()\n",
        "y_female = y[mask_female].copy()\n",
        "\n",
        "print(\"Distribuci칩n de clases en mujeres:\")\n",
        "print(y_female.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3kFVwYtQL1-",
        "outputId": "e2211626-78b6-43c4-8adf-fa7385c3ec3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci칩n de clases en mujeres tras SMOTENC:\n",
            "label\n",
            "0    182\n",
            "1    182\n",
            "2    182\n",
            "3    182\n",
            "4    182\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "cat_for_smote_f = cat_cols + not_done_cols\n",
        "cat_indices_f = [list(X_female.columns).index(c) for c in cat_for_smote_f]\n",
        "\n",
        "smote_f = SMOTENC(\n",
        "    categorical_features=cat_indices_f,\n",
        "    sampling_strategy='not majority',  \n",
        "    k_neighbors=2,                     \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_female_res, y_female_res = smote_f.fit_resample(X_female, y_female)\n",
        "\n",
        "print(\"Distribuci칩n de clases en mujeres tras SMOTENC:\")\n",
        "print(y_female_res.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDRDmwojQPlW",
        "outputId": "360e8a22-ab37-4c0f-f8cf-2d2bee546ea7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:30:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MODELO ESPEC칈FICO MUJERES ===\n",
            "Accuracy: 0.9010989010989011\n",
            "F1 macro: 0.9000588342317146\n",
            "[[32  2  0  0  3]\n",
            " [ 0 28  1  6  1]\n",
            " [ 1  1 33  1  0]\n",
            " [ 0  0  0 37  0]\n",
            " [ 1  1  0  0 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.86      0.90        37\n",
            "           1       0.88      0.78      0.82        36\n",
            "           2       0.97      0.92      0.94        36\n",
            "           3       0.84      1.00      0.91        37\n",
            "           4       0.89      0.94      0.92        36\n",
            "\n",
            "    accuracy                           0.90       182\n",
            "   macro avg       0.90      0.90      0.90       182\n",
            "weighted avg       0.90      0.90      0.90       182\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xf_train, Xf_test, yf_train, yf_test = train_test_split(\n",
        "    X_female_res, y_female_res,\n",
        "    test_size=0.2,\n",
        "    stratify=y_female_res,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_female = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=4,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_female.fit(Xf_train, yf_train)\n",
        "\n",
        "yf_pred = xgb_female.predict(Xf_test)\n",
        "\n",
        "print(\"\\n=== MODELO ESPEC칈FICO MUJERES ===\")\n",
        "print(\"Accuracy:\", accuracy_score(yf_test, yf_pred))\n",
        "print(\"F1 macro:\", f1_score(yf_test, yf_pred, average=\"macro\"))\n",
        "print(confusion_matrix(yf_test, yf_pred))\n",
        "print(classification_report(yf_test, yf_pred, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aDXAULuQXPH",
        "outputId": "8a273ed7-2e2d-4c5e-a4d2-d09c76ed3380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MODELO COMBINADO (global + mujeres-espec칤fico) ===\n",
            "Accuracy: 0.6417910447761194\n",
            "F1 macro: 0.4527550951766126\n",
            "[[83  6  5  1  1]\n",
            " [ 1 28 13 13  0]\n",
            " [ 3  7  6  2  4]\n",
            " [ 1  7  1 11  1]\n",
            " [ 1  3  0  2  1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.86      0.90        96\n",
            "           1       0.55      0.51      0.53        55\n",
            "           2       0.24      0.27      0.26        22\n",
            "           3       0.38      0.52      0.44        21\n",
            "           4       0.14      0.14      0.14         7\n",
            "\n",
            "    accuracy                           0.64       201\n",
            "   macro avg       0.45      0.46      0.45       201\n",
            "weighted avg       0.67      0.64      0.65       201\n",
            "\n",
            "\n",
            "=== SOLO MUJERES con modelo combinado ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97        37\n",
            "           1       0.71      0.71      0.71         7\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       0.75      1.00      0.86         3\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.90        50\n",
            "   macro avg       0.63      0.73      0.67        50\n",
            "weighted avg       0.91      0.90      0.90        50\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test global (X_test, y_test) del modelo general\n",
        "X_test_global = X_test.copy()\n",
        "sex_test = X_test_global[\"sex\"]\n",
        "\n",
        "# Predicciones del modelo global\n",
        "y_pred_global = xgb_fe.predict(X_test_global)\n",
        "\n",
        "# Predicciones del modelo espec칤fico mujeres (solo para las filas de mujeres)\n",
        "mask_f_test = (sex_test == 0)\n",
        "\n",
        "X_test_fem_global = X_test_global[mask_f_test]\n",
        "y_pred_fem_model = xgb_female.predict(X_test_fem_global)\n",
        "\n",
        "# Sustituimos en las posiciones de mujeres\n",
        "y_pred_combined = y_pred_global.copy()\n",
        "y_pred_combined[mask_f_test] = y_pred_fem_model\n",
        "\n",
        "print(\"\\n=== MODELO COMBINADO (global + mujeres-espec칤fico) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_combined))\n",
        "print(\"F1 macro:\", f1_score(y_test, y_pred_combined, average=\"macro\"))\n",
        "print(confusion_matrix(y_test, y_pred_combined))\n",
        "print(classification_report(y_test, y_pred_combined, zero_division=0))\n",
        "\n",
        "print(\"\\n=== SOLO MUJERES con modelo combinado ===\")\n",
        "print(classification_report(y_test[mask_f_test], y_pred_combined[mask_f_test], zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA7feYOnSA0H",
        "outputId": "145c2b15-5e6e-4ea4-b666-f6780d756d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape X: (1002, 21)\n",
            "Distribuci칩n de clases global:\n",
            "label\n",
            "0    477\n",
            "1    276\n",
            "2    108\n",
            "3    107\n",
            "4     34\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "df = df_imp.copy()  \n",
        "# Features solo con columnas originales + flags _not_done\n",
        "features_base = cont_cols + cat_cols + not_done_cols\n",
        "\n",
        "X = df[features_base].copy()\n",
        "y = df[\"label\"].astype(int)\n",
        "\n",
        "print(\"Shape X:\", X.shape)\n",
        "print(\"Distribuci칩n de clases global:\")\n",
        "print(y.value_counts().sort_index())\n",
        "\n",
        "# Split global\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60WS4Q09SFJO",
        "outputId": "779c6a83-0037-486c-d197-b7c72cc7a1a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci칩n de clases tras SMOTENC (global):\n",
            "label\n",
            "0    381\n",
            "1    381\n",
            "2    381\n",
            "3    381\n",
            "4    381\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:30:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MODELO GLOBAL (solo columnas originales + _not_done) ===\n",
            "Accuracy: 0.6268656716417911\n",
            "F1 macro: 0.44386524739556704\n",
            "Matriz de confusi칩n:\n",
            " [[86  4  5  1  0]\n",
            " [ 4 26 13 12  0]\n",
            " [ 3  6  5  5  3]\n",
            " [ 3  8  2  7  1]\n",
            " [ 1  3  0  1  2]]\n",
            "\n",
            "Reporte global:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.89        96\n",
            "           1       0.55      0.47      0.51        55\n",
            "           2       0.20      0.23      0.21        22\n",
            "           3       0.27      0.33      0.30        21\n",
            "           4       0.33      0.29      0.31         7\n",
            "\n",
            "    accuracy                           0.63       201\n",
            "   macro avg       0.45      0.44      0.44       201\n",
            "weighted avg       0.64      0.63      0.63       201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cat_for_smote = cat_cols + not_done_cols\n",
        "cat_indices = [features_base.index(c) for c in cat_for_smote]\n",
        "\n",
        "smote_nc = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',\n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train_res, y_train_res = smote_nc.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Distribuci칩n de clases tras SMOTENC (global):\")\n",
        "print(y_train_res.value_counts().sort_index())\n",
        "\n",
        "\n",
        "xgb_fe = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=5,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_fe.fit(X_train_res, y_train_res)\n",
        "\n",
        "y_pred_global = xgb_fe.predict(X_test)\n",
        "\n",
        "print(\"\\n=== MODELO GLOBAL (solo columnas originales + _not_done) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_global))\n",
        "print(\"F1 macro:\", f1_score(y_test, y_pred_global, average=\"macro\"))\n",
        "print(\"Matriz de confusi칩n:\\n\", confusion_matrix(y_test, y_pred_global))\n",
        "print(\"\\nReporte global:\")\n",
        "print(classification_report(y_test, y_pred_global, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUpQ4YOeSIgF",
        "outputId": "f1f09e2d-4091-421c-dad3-35104f5b1e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci칩n de clases en mujeres (antes de SMOTE):\n",
            "label\n",
            "0    182\n",
            "1     39\n",
            "2      9\n",
            "3      8\n",
            "4      3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Subconjunto mujeres\n",
        "mask_female = (df[\"sex\"] == 0)\n",
        "X_female = X[mask_female].copy()\n",
        "y_female = y[mask_female].copy()\n",
        "\n",
        "print(\"\\nDistribuci칩n de clases en mujeres (antes de SMOTE):\")\n",
        "print(y_female.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KGXAzTrSK6-",
        "outputId": "aa450728-9da5-4889-c744-31f154d1f928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci칩n de clases en mujeres tras SMOTENC:\n",
            "label\n",
            "0    182\n",
            "1    182\n",
            "2    182\n",
            "3    182\n",
            "4    182\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "cat_for_smote_f = cat_cols + not_done_cols\n",
        "cat_indices_f = [list(X_female.columns).index(c) for c in cat_for_smote_f]\n",
        "\n",
        "smote_f = SMOTENC(\n",
        "    categorical_features=cat_indices_f,\n",
        "    sampling_strategy='not majority',  # sube clases minoritarias\n",
        "    k_neighbors=2,                     # pocas muestras, bajamos k\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_female_res, y_female_res = smote_f.fit_resample(X_female, y_female)\n",
        "\n",
        "print(\"\\nDistribuci칩n de clases en mujeres tras SMOTENC:\")\n",
        "print(y_female_res.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvv4Y5ncSNDS",
        "outputId": "f954e06d-80d8-478f-b681-dbad8a321bee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:30:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MODELO ESPEC칈FICO MUJERES (04) ===\n",
            "Accuracy: 0.9395604395604396\n",
            "F1 macro: 0.9388266223882662\n",
            "Matriz de confusi칩n:\n",
            " [[35  1  0  0  1]\n",
            " [ 0 30  3  3  0]\n",
            " [ 0  2 34  0  0]\n",
            " [ 0  0  0 37  0]\n",
            " [ 0  1  0  0 35]]\n",
            "\n",
            "Reporte mujeres (test mujeres-resampleadas):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97        37\n",
            "           1       0.88      0.83      0.86        36\n",
            "           2       0.92      0.94      0.93        36\n",
            "           3       0.93      1.00      0.96        37\n",
            "           4       0.97      0.97      0.97        36\n",
            "\n",
            "    accuracy                           0.94       182\n",
            "   macro avg       0.94      0.94      0.94       182\n",
            "weighted avg       0.94      0.94      0.94       182\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xf_train, Xf_test, yf_train, yf_test = train_test_split(\n",
        "    X_female_res, y_female_res,\n",
        "    test_size=0.2,\n",
        "    stratify=y_female_res,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_female = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=4,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_female.fit(Xf_train, yf_train)\n",
        "\n",
        "yf_pred = xgb_female.predict(Xf_test)\n",
        "\n",
        "print(\"\\n=== MODELO ESPEC칈FICO MUJERES (04) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(yf_test, yf_pred))\n",
        "print(\"F1 macro:\", f1_score(yf_test, yf_pred, average=\"macro\"))\n",
        "print(\"Matriz de confusi칩n:\\n\", confusion_matrix(yf_test, yf_pred))\n",
        "print(\"\\nReporte mujeres (test mujeres-resampleadas):\")\n",
        "print(classification_report(yf_test, yf_pred, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5cvDsuVSQ1L",
        "outputId": "c01fa595-b066-49db-80aa-41c61dc23c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MODELO COMBINADO (GLOBAL + MUJERES-ESPEC칈FICO) ===\n",
            "Accuracy: 0.6616915422885572\n",
            "F1 macro: 0.6616915422885572\n",
            "Matriz de confusi칩n:\n",
            " [[87  4  4  1  0]\n",
            " [ 3 28 12 12  0]\n",
            " [ 3  5  6  5  3]\n",
            " [ 2  6  2 10  1]\n",
            " [ 1  3  0  1  2]]\n",
            "\n",
            "Reporte global combinado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91        96\n",
            "           1       0.61      0.51      0.55        55\n",
            "           2       0.25      0.27      0.26        22\n",
            "           3       0.34      0.48      0.40        21\n",
            "           4       0.33      0.29      0.31         7\n",
            "\n",
            "    accuracy                           0.66       201\n",
            "   macro avg       0.49      0.49      0.49       201\n",
            "weighted avg       0.67      0.66      0.67       201\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Copia del test global\n",
        "X_test_global = X_test.copy()\n",
        "sex_test = X_test_global[\"sex\"]\n",
        "\n",
        "# Predicciones del modelo global (ya las tenemos: y_pred_global)\n",
        "# y_pred_global = xgb_fe.predict(X_test_global)\n",
        "\n",
        "# Predicciones del modelo espec칤fico de mujeres (solo en filas de mujeres)\n",
        "mask_f_test = (sex_test == 0)\n",
        "\n",
        "X_test_fem_global = X_test_global[mask_f_test]\n",
        "y_pred_fem_model = xgb_female.predict(X_test_fem_global)\n",
        "\n",
        "# Sustituimos en las posiciones de mujeres\n",
        "y_pred_combined = y_pred_global.copy()\n",
        "y_pred_combined[mask_f_test] = y_pred_fem_model\n",
        "\n",
        "print(\"\\n=== MODELO COMBINADO (GLOBAL + MUJERES-ESPEC칈FICO) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_combined))\n",
        "print(\"F1 macro:\", f1_score(y_test, y_pred_combined, average=\"micro\"))\n",
        "print(\"Matriz de confusi칩n:\\n\", confusion_matrix(y_test, y_pred_combined))\n",
        "print(\"\\nReporte global combinado:\")\n",
        "print(classification_report(y_test, y_pred_combined, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RVAH1kOT0nf"
      },
      "source": [
        "# Prueba Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1B-X99fT35l",
        "outputId": "fe31b8a0-2a71-4ee8-9ffb-2de5789db63a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2438021352.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train_raw[col].fillna(moda, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "\n",
        "cont_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "cat_cols  = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "not_done_cols = ['chol_not_done', 'slope_not_done', 'ca_not_done', 'thal_not_done', 'fbs_not_done']\n",
        "\n",
        "features_base = cont_cols + cat_cols + not_done_cols\n",
        "\n",
        "\n",
        "df_train_raw = df_imp.copy()  \n",
        "\n",
        "def add_not_done_flags(df):\n",
        "    # flags -9 para pruebas num칠ricas/categ칩ricas\n",
        "    for col in ['chol', 'slope', 'ca', 'thal']:\n",
        "        mask_nd = df[col].astype(str).isin(['-9', '-9.0'])\n",
        "        df[col + '_not_done'] = mask_nd.astype(int)\n",
        "    # fbs\n",
        "    df['fbs_not_done'] = df['fbs'].astype(str).isin(['-9', '-9.0']).astype(int)\n",
        "    return df\n",
        "\n",
        "df_train_raw = add_not_done_flags(df_train_raw)\n",
        "\n",
        "# convertir '?' a NaN\n",
        "df_train_raw.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# convertir a num\n",
        "for col in cont_cols + cat_cols + ['label']:\n",
        "    df_train_raw[col] = pd.to_numeric(df_train_raw[col], errors='coerce')\n",
        "\n",
        "# tratar 0 \n",
        "df_train_raw.loc[df_train_raw['trestbps'] == 0, 'trestbps'] = np.nan\n",
        "df_train_raw.loc[df_train_raw['chol'] == 0, 'chol'] = np.nan\n",
        "\n",
        "# slope/ca/thal: -1 como \"no realizada\", fbs ya corregido\n",
        "for col in ['slope', 'ca', 'thal']:\n",
        "    df_train_raw[col] = df_train_raw[col].fillna(-1)\n",
        "\n",
        "# imputador continuo sobre TRAIN \n",
        "knn_imp = KNNImputer(n_neighbors=5)\n",
        "df_train_raw[cont_cols] = knn_imp.fit_transform(df_train_raw[cont_cols])\n",
        "\n",
        "# NaN categ칩ricas -> moda (train)\n",
        "for col in ['sex', 'cp', 'fbs', 'restecg', 'exang']:\n",
        "    moda = df_train_raw[col].mode()[0]\n",
        "    df_train_raw[col].fillna(moda, inplace=True)\n",
        "\n",
        "\n",
        "df_imp = df_train_raw.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "E8YzCtuhUDTA",
        "outputId": "3cf39c61-944c-4ea1-b66a-2d5b7ecb73e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:18:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:18:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"郊\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"郊쬪";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None, num_class=5, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None, num_class=5, ...)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='mlogloss',\n",
              "              feature_types=None, feature_weights=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None, num_class=5, ...)"
            ]
          },
          "execution_count": 228,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTENC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_imp[features_base]\n",
        "y = df_imp[\"label\"].astype(int)\n",
        "\n",
        "# split global\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "#SMOTENC \n",
        "cat_for_smote = cat_cols + not_done_cols\n",
        "cat_indices = [features_base.index(c) for c in cat_for_smote]\n",
        "\n",
        "smote_nc = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',\n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train_res, y_train_res = smote_nc.fit_resample(X_train, y_train)\n",
        "\n",
        "#XGBoost GLOBAL \n",
        "xgb_fe = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=5,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "xgb_fe.fit(X_train_res, y_train_res)\n",
        "\n",
        "# --- MODELO MUJERES ---\n",
        "mask_female = (df_imp[\"sex\"] == 0)\n",
        "X_female = X[mask_female].copy()\n",
        "y_female = y[mask_female].copy()\n",
        "\n",
        "cat_for_smote_f = cat_cols + not_done_cols\n",
        "cat_indices_f = [list(X_female.columns).index(c) for c in cat_for_smote_f]\n",
        "\n",
        "smote_f = SMOTENC(\n",
        "    categorical_features=cat_indices_f,\n",
        "    sampling_strategy='not majority',\n",
        "    k_neighbors=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_female_res, y_female_res = smote_f.fit_resample(X_female, y_female)\n",
        "\n",
        "Xf_train, Xf_test, yf_train, yf_test = train_test_split(\n",
        "    X_female_res, y_female_res,\n",
        "    test_size=0.2,\n",
        "    stratify=y_female_res,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_female = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=4,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='multi:softmax',\n",
        "    num_class=5,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "xgb_female.fit(Xf_train, yf_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGAZR9lXUXLu",
        "outputId": "4c06a43c-e8de-4de8-8233-642acbb2f18c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1275344275.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[col].fillna(train_mode, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Cargar test de Kaggle \n",
        "df_test_raw = pd.read_csv(\"/test.csv\") \n",
        "\n",
        "df_test = df_test_raw.copy()\n",
        "\n",
        "# 1) Flags de pruebas no hechas\n",
        "df_test = add_not_done_flags(df_test)\n",
        "\n",
        "# 2) Convertir '?' a NaN\n",
        "df_test.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# 3) Convertir a num칠rico continuas + categ칩ricas\n",
        "for col in cont_cols + cat_cols:\n",
        "    df_test[col] = pd.to_numeric(df_test[col], errors='coerce')\n",
        "\n",
        "# 4) de 0 a NaN en continuas\n",
        "df_test.loc[df_test['trestbps'] == 0, 'trestbps'] = np.nan\n",
        "df_test.loc[df_test['chol'] == 0,      'chol']     = np.nan\n",
        "\n",
        "# 5) slope/ca/thal: -1 como categor칤a \"no realizada\" (igual que en train)\n",
        "for col in ['slope', 'ca', 'thal']:\n",
        "    df_test[col] = df_test[col].fillna(-1)\n",
        "\n",
        "# 6) Imputamos continuas con knn_imp entrenado en el train\n",
        "df_test[cont_cols] = knn_imp.transform(df_test[cont_cols])\n",
        "\n",
        "# 7) Rellenamos NaN en categ칩ricas con la moda del TRAIN (df_imp)\n",
        "for col in ['sex', 'cp', 'fbs', 'restecg', 'exang']:\n",
        "    train_mode = df_imp[col].mode()[0]\n",
        "    df_test[col].fillna(train_mode, inplace=True)\n",
        "\n",
        "# 8) Matriz final de features para el modelo\n",
        "X_test_kaggle = df_test[features_base]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYs-_2qtUznf"
      },
      "outputs": [],
      "source": [
        "# Predicciones del modelo global\n",
        "y_pred_global_test = xgb_fe.predict(X_test_kaggle)\n",
        "\n",
        "# Predicciones del modelo espec칤fico de mujeres\n",
        "sex_test_kaggle = X_test_kaggle[\"sex\"]\n",
        "mask_f_test = (sex_test_kaggle == 0)\n",
        "\n",
        "X_test_fem = X_test_kaggle[mask_f_test]\n",
        "y_pred_fem_test = xgb_female.predict(X_test_fem)\n",
        "\n",
        "# Combinamos para mujeres usamos el modelo espec칤fico\n",
        "y_pred_combined_test = y_pred_global_test.copy()\n",
        "y_pred_combined_test[mask_f_test] = y_pred_fem_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo9GdvBfU4_e",
        "outputId": "2d94ce7e-bb0b-4479-e0de-1f89000f8c3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas test: 184\n",
            "Filas sample_submission: 184\n",
            "九 submission.csv generado\n"
          ]
        }
      ],
      "source": [
        "# Cargamos sample_submission\n",
        "sub = pd.read_csv(\"/sample_submission.csv\")\n",
        "\n",
        "print(\"Filas test:\", len(X_test_kaggle))\n",
        "print(\"Filas sample_submission:\", len(sub))\n",
        "\n",
        "sub[\"label\"] = y_pred_combined_test.astype(int)\n",
        "\n",
        "\n",
        "sub.to_csv(\"submission.csv\", index=False)\n",
        "print(\"九 submission.csv generado\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfHpxfL6Llze"
      },
      "source": [
        "# 2춹 Prueba Kaggle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcARbS-ePvSo",
        "outputId": "38238896-f59c-4244-edb8-08324f866fab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando datasets de TRAIN...\n",
            "Filas train_IA_PROJECT: 732\n",
            "Filas statlog_limpio   : 270\n",
            "Total pacientes combinados (train+statlog): 1002\n",
            "\n",
            "Resumen df_imp (TRAIN limpio+imputado):\n",
            "age               0\n",
            "trestbps          0\n",
            "chol              0\n",
            "thalach           0\n",
            "oldpeak           0\n",
            "sex               0\n",
            "cp                0\n",
            "fbs               0\n",
            "restecg           0\n",
            "exang             0\n",
            "slope             0\n",
            "ca                0\n",
            "thal              0\n",
            "chol_not_done     0\n",
            "slope_not_done    0\n",
            "ca_not_done       0\n",
            "thal_not_done     0\n",
            "fbs_not_done      0\n",
            "label             0\n",
            "dtype: int64\n",
            "\n",
            "Cargando TEST de Kaggle...\n",
            "\n",
            "NaNs en TEST despu칠s de limpieza:\n",
            "age               0\n",
            "trestbps          0\n",
            "chol              0\n",
            "thalach           0\n",
            "oldpeak           0\n",
            "sex               0\n",
            "cp                0\n",
            "fbs               0\n",
            "restecg           0\n",
            "exang             0\n",
            "slope             0\n",
            "ca                0\n",
            "thal              0\n",
            "chol_not_done     0\n",
            "slope_not_done    0\n",
            "ca_not_done       0\n",
            "thal_not_done     0\n",
            "fbs_not_done      0\n",
            "dtype: int64\n",
            "\n",
            "Shape X_full (TRAIN): (1002, 18)\n",
            "Distrib clases TRAIN:\n",
            "label\n",
            "0    477\n",
            "1    276\n",
            "2    108\n",
            "3    107\n",
            "4     34\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distrib clases en MUJERES (TRAIN):\n",
            "label\n",
            "0    182\n",
            "1     39\n",
            "2      9\n",
            "3      8\n",
            "4      3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "================ GLOBAL: PSEUDO-LABELING ================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2482918172.py:274: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train_clean[col].fillna(moda, inplace=True)\n",
            "/tmp/ipython-input-2482918172.py:300: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[col].fillna(cat_modes[col], inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:15:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== PROFESOR (antes de pseudo-labeling) ===\n",
            "Accuracy val: 0.6119402985074627\n",
            "F1 macro val: 0.44346540695683323\n",
            "Matriz conf val:\n",
            " [[82  6  5  3  0]\n",
            " [ 3 28 12 12  0]\n",
            " [ 5  6  5  5  1]\n",
            " [ 3  9  2  6  1]\n",
            " [ 0  2  1  2  2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.87        96\n",
            "           1       0.55      0.51      0.53        55\n",
            "           2       0.20      0.23      0.21        22\n",
            "           3       0.21      0.29      0.24        21\n",
            "           4       0.50      0.29      0.36         7\n",
            "\n",
            "    accuracy                           0.61       201\n",
            "   macro avg       0.47      0.43      0.44       201\n",
            "weighted avg       0.63      0.61      0.62       201\n",
            "\n",
            "\n",
            "Pseudo-labeling con threshold=0.8\n",
            "Muestras test totales: 184\n",
            "Muestras test con confianza >= threshold: 79\n",
            "Train original: 1002\n",
            "Train aumentado: 1081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:15:21] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== ALUMNO (despu칠s de pseudo-labeling) ===\n",
            "Accuracy val: 0.6359447004608295\n",
            "F1 macro val: 0.39060069695944416\n",
            "Matriz conf val:\n",
            " [[98  3  2  4  0]\n",
            " [ 9 30 10  8  2]\n",
            " [ 2 11  2  6  1]\n",
            " [ 1 11  0  7  3]\n",
            " [ 1  2  1  2  1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.92      0.90       107\n",
            "           1       0.53      0.51      0.52        59\n",
            "           2       0.13      0.09      0.11        22\n",
            "           3       0.26      0.32      0.29        22\n",
            "           4       0.14      0.14      0.14         7\n",
            "\n",
            "    accuracy                           0.64       217\n",
            "   macro avg       0.39      0.40      0.39       217\n",
            "weighted avg       0.62      0.64      0.63       217\n",
            "\n",
            "\n",
            "\n",
            "================ MUJERES: PSEUDO-LABELING ================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:15:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== PROFESOR (antes de pseudo-labeling) ===\n",
            "Accuracy val: 0.7959183673469388\n",
            "F1 macro val: 0.2974124809741248\n",
            "Matriz conf val:\n",
            " [[34  2  0  0  1]\n",
            " [ 1  5  0  1  1]\n",
            " [ 1  1  0  0  0]\n",
            " [ 0  2  0  0  0]\n",
            " [ 0  0  0  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93        37\n",
            "           1       0.50      0.62      0.56         8\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.80        49\n",
            "   macro avg       0.29      0.31      0.30        49\n",
            "weighted avg       0.79      0.80      0.79        49\n",
            "\n",
            "\n",
            "Pseudo-labeling con threshold=0.8\n",
            "Muestras test totales: 40\n",
            "Muestras test con confianza >= threshold: 36\n",
            "Train original: 241\n",
            "Train aumentado: 277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:15:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== ALUMNO (despu칠s de pseudo-labeling) ===\n",
            "Accuracy val: 0.8214285714285714\n",
            "F1 macro val: 0.5054112554112554\n",
            "Matriz conf val:\n",
            " [[41  1  0  0  1]\n",
            " [ 3  3  1  2  0]\n",
            " [ 1  0  1  0  0]\n",
            " [ 0  1  0  0  0]\n",
            " [ 0  0  0  0  1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93        43\n",
            "           1       0.60      0.33      0.43         9\n",
            "           2       0.50      0.50      0.50         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.82        56\n",
            "   macro avg       0.50      0.56      0.51        56\n",
            "weighted avg       0.82      0.82      0.81        56\n",
            "\n",
            "\n",
            "Distribuci칩n predicciones COMBINADAS en test:\n",
            "{np.int64(0): np.int64(84), np.int64(1): np.int64(44), np.int64(2): np.int64(21), np.int64(3): np.int64(24), np.int64(4): np.int64(11)}\n",
            "\n",
            "Filas test Kaggle: 184\n",
            "Filas sample_submission: 184\n",
            "\n",
            "九 submission.csv generado en el directorio actual\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "cont_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "\n",
        "cat_cols  = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "\n",
        "not_done_cols = ['chol_not_done', 'slope_not_done', 'ca_not_done', 'thal_not_done', 'fbs_not_done']\n",
        "\n",
        "features_base = cont_cols + cat_cols + not_done_cols\n",
        "target_col = 'label'\n",
        "\n",
        "\n",
        "\n",
        "def add_not_done_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    \n",
        "    for col in ['chol', 'slope', 'ca', 'thal', 'fbs']:\n",
        "        \n",
        "        if col in df.columns:\n",
        "            mask_nd = df[col].astype(str).isin(['-9', '-9.0'])\n",
        "            df[col + '_not_done'] = mask_nd.astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def basic_numeric_clean(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1) \"?\" -> NaN\n",
        "    df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "    # 2) -9 para chol/slope/ca/thal -> NaN (prueba no realizada)\n",
        "    for col in ['chol', 'slope', 'ca', 'thal']:\n",
        "        if col in df.columns:\n",
        "            mask_nd = df[col].astype(str).isin(['-9', '-9.0'])\n",
        "            df.loc[mask_nd, col] = np.nan\n",
        "\n",
        "    # 3) fbs: -9 / -9.0 -> 0 \n",
        "    if 'fbs' in df.columns:\n",
        "        df['fbs'] = df['fbs'].replace(['-9', '-9.0'], 0)\n",
        "\n",
        "    # 4) Convertimos columnas num칠ricas a float/int\n",
        "    num_cols_all = cont_cols + cat_cols\n",
        "    if is_train and target_col in df.columns:\n",
        "        num_cols_all = num_cols_all + [target_col]\n",
        "\n",
        "    for col in num_cols_all:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # 5) 0 raros -> NaN\n",
        "    if 'trestbps' in df.columns:\n",
        "        df.loc[df['trestbps'] == 0, 'trestbps'] = np.nan\n",
        "    if 'chol' in df.columns:\n",
        "        df.loc[df['chol'] == 0, 'chol'] = np.nan\n",
        "\n",
        "    # 6) En TRAIN: eliminar filas sin label y pasarla a int\n",
        "    if is_train and target_col in df.columns:\n",
        "        df = df.dropna(subset=[target_col])\n",
        "        df[target_col] = df[target_col].astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_xgb_with_pseudo_labeling(\n",
        "    X_labeled: pd.DataFrame,\n",
        "    y_labeled: pd.Series,\n",
        "    X_unlabeled: pd.DataFrame,\n",
        "    cat_cols: list,\n",
        "    not_done_cols: list,\n",
        "    threshold: float = 0.80,\n",
        "    k_neighbors_smote: int = 3,\n",
        "    random_state: int = 42,\n",
        "):\n",
        "    \"\"\"\n",
        "    Entrena un XGBoost con pseudo-labeling:\n",
        "\n",
        "    1) Split interno train/valid sobre los datos etiquetados.\n",
        "    2) SMOTENC en train.\n",
        "    3) Entrena modelo \"profesor\" (softprob).\n",
        "    4) Pseudo-labels sobre X_unlabeled con proba_max >= threshold.\n",
        "    5) Une train original + pseudo-labels -> nuevo train.\n",
        "    6) Nuevo split + SMOTENC + XGBoost \"alumno\".\n",
        "    7) Devuelve modelo alumno + predicciones de test (X_unlabeled).\n",
        "    \"\"\"\n",
        "\n",
        "    features = list(X_labeled.columns)\n",
        "    cat_for_smote = cat_cols + not_done_cols\n",
        "    cat_indices = [features.index(c) for c in cat_for_smote if c in features]\n",
        "\n",
        "    # 1) Split interno\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X_labeled, y_labeled,\n",
        "        test_size=0.2,\n",
        "        stratify=y_labeled,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # 2) SMOTENC en train\n",
        "    smote_nc = SMOTENC(\n",
        "        categorical_features=cat_indices,\n",
        "        sampling_strategy='not majority',\n",
        "        k_neighbors=k_neighbors_smote,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    X_tr_res, y_tr_res = smote_nc.fit_resample(X_tr, y_tr)\n",
        "\n",
        "    # 3) MODELO PROFESOR\n",
        "    xgb_teacher = XGBClassifier(\n",
        "        n_estimators=400,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=5,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        objective='multi:softprob',   # para tener probabilidades\n",
        "        num_class=5,\n",
        "        random_state=random_state,\n",
        "        eval_metric='mlogloss',\n",
        "        use_label_encoder=False\n",
        "    )\n",
        "\n",
        "    xgb_teacher.fit(X_tr_res, y_tr_res)\n",
        "\n",
        "    # Eval en valid\n",
        "    proba_val = xgb_teacher.predict_proba(X_val)\n",
        "    y_val_pred = proba_val.argmax(axis=1)\n",
        "\n",
        "    print(\"\\n=== PROFESOR (antes de pseudo-labeling) ===\")\n",
        "    print(\"Accuracy val:\", accuracy_score(y_val, y_val_pred))\n",
        "    print(\"F1 macro val:\", f1_score(y_val, y_val_pred, average=\"macro\"))\n",
        "    print(\"Matriz conf val:\\n\", confusion_matrix(y_val, y_val_pred))\n",
        "    print(classification_report(y_val, y_val_pred, zero_division=0))\n",
        "\n",
        "    # 4) Pseudo-labels sobre TEST (X_unlabeled)\n",
        "    proba_test = xgb_teacher.predict_proba(X_unlabeled)\n",
        "    max_conf = proba_test.max(axis=1)\n",
        "    high_conf_mask = max_conf >= threshold\n",
        "\n",
        "    print(f\"\\nPseudo-labeling con threshold={threshold}\")\n",
        "    print(f\"Muestras test totales: {X_unlabeled.shape[0]}\")\n",
        "    print(f\"Muestras test con confianza >= threshold: {high_conf_mask.sum()}\")\n",
        "\n",
        "    X_pseudo = X_unlabeled[high_conf_mask]\n",
        "    y_pseudo = proba_test[high_conf_mask].argmax(axis=1)\n",
        "\n",
        "    # 5) Train aumentado\n",
        "    X_aug = pd.concat([X_labeled, X_pseudo], axis=0)\n",
        "    y_aug = pd.concat([\n",
        "        y_labeled,\n",
        "        pd.Series(y_pseudo, index=X_pseudo.index)\n",
        "    ])\n",
        "\n",
        "    print(f\"Train original: {X_labeled.shape[0]}\")\n",
        "    print(f\"Train aumentado: {X_aug.shape[0]}\")\n",
        "\n",
        "    # 6) Nuevo split + SMOTENC + XGB alumno\n",
        "    X_tr2, X_val2, y_tr2, y_val2 = train_test_split(\n",
        "        X_aug, y_aug,\n",
        "        test_size=0.2,\n",
        "        stratify=y_aug,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    smote_nc2 = SMOTENC(\n",
        "        categorical_features=cat_indices,\n",
        "        sampling_strategy='not majority',\n",
        "        k_neighbors=k_neighbors_smote,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    X_tr2_res, y_tr2_res = smote_nc2.fit_resample(X_tr2, y_tr2)\n",
        "\n",
        "    xgb_student = XGBClassifier(\n",
        "        n_estimators=400,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=5,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        objective='multi:softprob',\n",
        "        num_class=5,\n",
        "        random_state=random_state,\n",
        "        eval_metric='mlogloss',\n",
        "        use_label_encoder=False\n",
        "    )\n",
        "\n",
        "    xgb_student.fit(X_tr2_res, y_tr2_res)\n",
        "\n",
        "    # Eval en valid (despu칠s de pseudo-labeling)\n",
        "    proba_val2 = xgb_student.predict_proba(X_val2)\n",
        "    y_val2_pred = proba_val2.argmax(axis=1)\n",
        "\n",
        "    print(\"\\n=== ALUMNO (despu칠s de pseudo-labeling) ===\")\n",
        "    print(\"Accuracy val:\", accuracy_score(y_val2, y_val2_pred))\n",
        "    print(\"F1 macro val:\", f1_score(y_val2, y_val2_pred, average=\"macro\"))\n",
        "    print(\"Matriz conf val:\\n\", confusion_matrix(y_val2, y_val2_pred))\n",
        "    print(classification_report(y_val2, y_val2_pred, zero_division=0))\n",
        "\n",
        "    # 7) Predicciones finales sobre TODO el test (X_unlabeled)\n",
        "    proba_test_final = xgb_student.predict_proba(X_unlabeled)\n",
        "    y_unlabeled_pred = proba_test_final.argmax(axis=1)\n",
        "\n",
        "    return xgb_student, y_unlabeled_pred\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. Cargar y limpiar TRAIN (train_IA + statlog)\n",
        "# ============================================================\n",
        "\n",
        "print(\"Cargando datasets de TRAIN...\")\n",
        "df_train = pd.read_csv(\"/train_IA_PROJECT.csv\")\n",
        "df_statlog = pd.read_csv(\"/statlog_limpio.csv\")\n",
        "\n",
        "print(f\"Filas train_IA_PROJECT: {len(df_train)}\")\n",
        "print(f\"Filas statlog_limpio   : {len(df_statlog)}\")\n",
        "\n",
        "# Fusionamos ambos (como en tu notebook)\n",
        "df_total = pd.concat([df_train, df_statlog], ignore_index=True)\n",
        "print(f\"Total pacientes combinados (train+statlog): {len(df_total)}\")\n",
        "\n",
        "# 1) Flags not_done en TRAIN\n",
        "df_total = add_not_done_flags(df_total)\n",
        "\n",
        "# 2) Limpieza b치sica num칠rica + label\n",
        "df_train_clean = basic_numeric_clean(df_total, is_train=True)\n",
        "\n",
        "# 3) Imputaci칩n KNN en continuas (solo con TRAIN)\n",
        "knn_imp = KNNImputer(n_neighbors=5)\n",
        "df_train_clean[cont_cols] = knn_imp.fit_transform(df_train_clean[cont_cols])\n",
        "\n",
        "# 4) NaN en categ칩ricas -> moda (solo TRAIN)\n",
        "cat_modes = {}\n",
        "for col in cat_cols:\n",
        "    moda = df_train_clean[col].mode()[0]\n",
        "    cat_modes[col] = moda\n",
        "    df_train_clean[col].fillna(moda, inplace=True)\n",
        "\n",
        "# Este ser치 tu df_imp definitivo de TRAIN\n",
        "df_imp = df_train_clean.copy()\n",
        "\n",
        "print(\"\\nResumen df_imp (TRAIN limpio+imputado):\")\n",
        "print(df_imp[features_base + [target_col]].isna().sum())\n",
        "\n",
        "# ============================================================\n",
        "# 5. Cargar y limpiar TEST de Kaggle\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nCargando TEST de Kaggle...\")\n",
        "df_test_raw = pd.read_csv(\"/test.csv\")   # ajusta ruta si hace falta\n",
        "\n",
        "# 1) Flags not_done en TEST\n",
        "df_test = add_not_done_flags(df_test_raw)\n",
        "\n",
        "# 2) Limpieza b치sica num칠rica (sin label)\n",
        "df_test = basic_numeric_clean(df_test, is_train=False)\n",
        "\n",
        "# 3) Imputaci칩n KNN en continuas usando MISMO imputador que TRAIN\n",
        "df_test[cont_cols] = knn_imp.transform(df_test[cont_cols])\n",
        "\n",
        "# 4) NaN en categ칩ricas -> usar las modas del TRAIN\n",
        "for col in cat_cols:\n",
        "    df_test[col].fillna(cat_modes[col], inplace=True)\n",
        "\n",
        "print(\"\\nNaNs en TEST despu칠s de limpieza:\")\n",
        "print(df_test[features_base].isna().sum())\n",
        "\n",
        "# ============================================================\n",
        "# 6. Preparar matrices X e y (global y mujeres)\n",
        "# ============================================================\n",
        "\n",
        "X_full = df_imp[features_base].copy()\n",
        "y_full = df_imp[target_col].astype(int)\n",
        "\n",
        "X_test_kaggle = df_test[features_base].copy()\n",
        "\n",
        "print(\"\\nShape X_full (TRAIN):\", X_full.shape)\n",
        "print(\"Distrib clases TRAIN:\")\n",
        "print(y_full.value_counts().sort_index())\n",
        "\n",
        "# Subconjunto mujeres en TRAIN y TEST\n",
        "mask_female_train = (df_imp[\"sex\"] == 0)\n",
        "mask_female_test  = (df_test[\"sex\"] == 0)\n",
        "\n",
        "X_female_train = X_full[mask_female_train].copy()\n",
        "y_female_train = y_full[mask_female_train].copy()\n",
        "\n",
        "X_female_test = X_test_kaggle[mask_female_test].copy()\n",
        "\n",
        "print(\"\\nDistrib clases en MUJERES (TRAIN):\")\n",
        "print(y_female_train.value_counts().sort_index())\n",
        "\n",
        "# ============================================================\n",
        "# 7. Pseudo-labeling GLOBAL\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\\n================ GLOBAL: PSEUDO-LABELING ================\")\n",
        "\n",
        "model_global, y_pred_test_global = train_xgb_with_pseudo_labeling(\n",
        "    X_labeled=X_full,\n",
        "    y_labeled=y_full,\n",
        "    X_unlabeled=X_test_kaggle,\n",
        "    cat_cols=cat_cols,\n",
        "    not_done_cols=not_done_cols,\n",
        "    threshold=0.80,          # puedes probar 0.85 / 0.90\n",
        "    k_neighbors_smote=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 8. Pseudo-labeling ESPEC칈FICO MUJERES\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\\n================ MUJERES: PSEUDO-LABELING ================\")\n",
        "\n",
        "model_female, y_pred_test_female = train_xgb_with_pseudo_labeling(\n",
        "    X_labeled=X_female_train,\n",
        "    y_labeled=y_female_train,\n",
        "    X_unlabeled=X_female_test,\n",
        "    cat_cols=cat_cols,\n",
        "    not_done_cols=not_done_cols,\n",
        "    threshold=0.80,\n",
        "    k_neighbors_smote=2,   # como hac칤as t칰 para mujeres\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 9. Combinar predicciones GLOBAL + MUJERES y crear submission\n",
        "# ============================================================\n",
        "\n",
        "# Empezamos del modelo global\n",
        "y_pred_combined_test = y_pred_test_global.copy()\n",
        "\n",
        "# Sustituimos en las filas de mujeres por el modelo espec칤fico\n",
        "y_pred_combined_test[mask_female_test.values] = y_pred_test_female\n",
        "\n",
        "print(\"\\nDistribuci칩n predicciones COMBINADAS en test:\")\n",
        "unique, counts = np.unique(y_pred_combined_test, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "# Cargar sample_submission\n",
        "sub = pd.read_csv(\"/sample_submission.csv\")  # ajusta ruta si hace falta\n",
        "\n",
        "print(\"\\nFilas test Kaggle:\", len(X_test_kaggle))\n",
        "print(\"Filas sample_submission:\", len(sub))\n",
        "\n",
        "# Asignar las predicciones combinadas\n",
        "sub[\"label\"] = y_pred_combined_test.astype(int)\n",
        "\n",
        "# Guardar submission\n",
        "sub.to_csv(\"submission.csv\", index=False)\n",
        "print(\"\\n九 submission.csv generado en el directorio actual\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXAtBmrXeoLh"
      },
      "source": [
        "# 3춹 PRUEBA KAGGLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-aYEjnfeqV8",
        "outputId": "e8aaf84a-f524-42cb-abeb-5f7c99e6ac98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando datasets de TRAIN...\n",
            "Filas train_IA_PROJECT: 732\n",
            "Filas statlog_limpio   : 270\n",
            "Total pacientes combinados (train+statlog): 1002\n",
            "\n",
            "Resumen df_imp (TRAIN limpio+imputado, sin chol en features):\n",
            "age               0\n",
            "trestbps          0\n",
            "thalach           0\n",
            "oldpeak           0\n",
            "sex               0\n",
            "cp                0\n",
            "fbs               0\n",
            "restecg           0\n",
            "exang             0\n",
            "slope             0\n",
            "ca                0\n",
            "thal              0\n",
            "chol_not_done     0\n",
            "slope_not_done    0\n",
            "ca_not_done       0\n",
            "thal_not_done     0\n",
            "fbs_not_done      0\n",
            "label             0\n",
            "dtype: int64\n",
            "\n",
            "Cargando TEST de Kaggle...\n",
            "\n",
            "NaNs en TEST despu칠s de limpieza (features_base):\n",
            "age               0\n",
            "trestbps          0\n",
            "thalach           0\n",
            "oldpeak           0\n",
            "sex               0\n",
            "cp                0\n",
            "fbs               0\n",
            "restecg           0\n",
            "exang             0\n",
            "slope             0\n",
            "ca                0\n",
            "thal              0\n",
            "chol_not_done     0\n",
            "slope_not_done    0\n",
            "ca_not_done       0\n",
            "thal_not_done     0\n",
            "fbs_not_done      0\n",
            "dtype: int64\n",
            "\n",
            "Shape X_full (TRAIN): (1002, 17)\n",
            "Distrib clases TRAIN:\n",
            "label\n",
            "0    477\n",
            "1    276\n",
            "2    108\n",
            "3    107\n",
            "4     34\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distrib clases en MUJERES (TRAIN):\n",
            "label\n",
            "0    182\n",
            "1     39\n",
            "2      9\n",
            "3      8\n",
            "4      3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "================ GLOBAL: PSEUDO-LABELING (sin chol) ================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-481354112.py:268: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train_clean[col].fillna(moda, inplace=True)\n",
            "/tmp/ipython-input-481354112.py:298: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[col].fillna(cat_modes[col], inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:16:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== PROFESOR (antes de pseudo-labeling) ===\n",
            "Accuracy val: 0.5671641791044776\n",
            "F1 macro val: 0.3689081897334331\n",
            "Matriz conf val:\n",
            " [[82  7  4  2  1]\n",
            " [ 7 23 11 12  2]\n",
            " [ 3  7  5  5  2]\n",
            " [ 3 10  3  2  3]\n",
            " [ 0  2  1  2  2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.86        96\n",
            "           1       0.47      0.42      0.44        55\n",
            "           2       0.21      0.23      0.22        22\n",
            "           3       0.09      0.10      0.09        21\n",
            "           4       0.20      0.29      0.24         7\n",
            "\n",
            "    accuracy                           0.57       201\n",
            "   macro avg       0.37      0.38      0.37       201\n",
            "weighted avg       0.58      0.57      0.57       201\n",
            "\n",
            "\n",
            "Pseudo-labeling con threshold=0.8\n",
            "Muestras test totales: 184\n",
            "Muestras test con confianza >= threshold: 72\n",
            "Train original: 1002\n",
            "Train aumentado: 1074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:16:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== ALUMNO (despu칠s de pseudo-labeling) ===\n",
            "Accuracy val: 0.6046511627906976\n",
            "F1 macro val: 0.3651580087814335\n",
            "Matriz conf val:\n",
            " [[93  6  2  4  1]\n",
            " [ 9 26  8 13  2]\n",
            " [ 1  9  5  5  2]\n",
            " [ 2 11  1  6  2]\n",
            " [ 2  4  1  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87       106\n",
            "           1       0.46      0.45      0.46        58\n",
            "           2       0.29      0.23      0.26        22\n",
            "           3       0.21      0.27      0.24        22\n",
            "           4       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.60       215\n",
            "   macro avg       0.37      0.37      0.37       215\n",
            "weighted avg       0.61      0.60      0.60       215\n",
            "\n",
            "\n",
            "\n",
            "================ MUJERES: PSEUDO-LABELING (sin chol) ================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:17:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== PROFESOR (antes de pseudo-labeling) ===\n",
            "Accuracy val: 0.7346938775510204\n",
            "F1 macro val: 0.28825396825396826\n",
            "Matriz conf val:\n",
            " [[31  2  0  3  1]\n",
            " [ 1  5  0  1  1]\n",
            " [ 1  1  0  0  0]\n",
            " [ 0  2  0  0  0]\n",
            " [ 0  0  0  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.84      0.89        37\n",
            "           1       0.50      0.62      0.56         8\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.73        49\n",
            "   macro avg       0.29      0.29      0.29        49\n",
            "weighted avg       0.79      0.73      0.76        49\n",
            "\n",
            "\n",
            "Pseudo-labeling con threshold=0.8\n",
            "Muestras test totales: 40\n",
            "Muestras test con confianza >= threshold: 31\n",
            "Train original: 241\n",
            "Train aumentado: 272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:17:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== ALUMNO (despu칠s de pseudo-labeling) ===\n",
            "Accuracy val: 0.7818181818181819\n",
            "F1 macro val: 0.2746031746031746\n",
            "Matriz conf val:\n",
            " [[39  2  0  0  1]\n",
            " [ 2  4  0  2  0]\n",
            " [ 0  2  0  0  0]\n",
            " [ 1  1  0  0  0]\n",
            " [ 0  1  0  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        42\n",
            "           1       0.40      0.50      0.44         8\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.78        55\n",
            "   macro avg       0.27      0.29      0.27        55\n",
            "weighted avg       0.77      0.78      0.77        55\n",
            "\n",
            "\n",
            "Distribuci칩n predicciones COMBINADAS en test (sin chol):\n",
            "{np.int64(0): np.int64(79), np.int64(1): np.int64(50), np.int64(2): np.int64(23), np.int64(3): np.int64(22), np.int64(4): np.int64(10)}\n",
            "\n",
            "Filas test Kaggle: 184\n",
            "Filas sample_submission: 184\n",
            "\n",
            "九 submission_sin_chol.csv generado en el directorio actual\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ============================================================\n",
        "# 1. Definici칩n de columnas (SIN chol)\n",
        "# ============================================================\n",
        "\n",
        "# Continuas biom칠tricas (quitamos chol)  # <<< CAMBIO\n",
        "cont_cols = ['age', 'trestbps', 'thalach', 'oldpeak']\n",
        "\n",
        "# Categ칩ricas cl칤nicas\n",
        "cat_cols  = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "# Flags de pruebas NO realizadas (mantenemos chol_not_done)  # <<< chol_not_done sigue siendo feature\n",
        "not_done_cols = ['chol_not_done', 'slope_not_done', 'ca_not_done', 'thal_not_done', 'fbs_not_done']\n",
        "\n",
        "features_base = cont_cols + cat_cols + not_done_cols\n",
        "target_col = 'label'\n",
        "\n",
        "# ============================================================\n",
        "# 2. Funciones de limpieza compartidas (TRAIN + TEST)\n",
        "# ============================================================\n",
        "\n",
        "def add_not_done_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "\n",
        "    # chol, slope, ca, thal, fbs\n",
        "    for col in ['chol', 'slope', 'ca', 'thal', 'fbs']:\n",
        "        if col in df.columns:\n",
        "            mask_nd = df[col].astype(str).isin(['-9', '-9.0'])\n",
        "            df[col + '_not_done'] = mask_nd.astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def basic_numeric_clean(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1) \"?\" -> NaN\n",
        "    df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "    # 2) -9 para chol/slope/ca/thal -> NaN (prueba no realizada)\n",
        "    for col in ['chol', 'slope', 'ca', 'thal']:\n",
        "        if col in df.columns:\n",
        "            mask_nd = df[col].astype(str).isin(['-9', '-9.0'])\n",
        "            df.loc[mask_nd, col] = np.nan\n",
        "\n",
        "    # 3) fbs: -9 / -9.0 -> 0\n",
        "    if 'fbs' in df.columns:\n",
        "        df['fbs'] = df['fbs'].replace(['-9', '-9.0'], 0)\n",
        "\n",
        "    # 4) Convertir columnas num칠ricas a float/int\n",
        "    num_cols_all = cont_cols + cat_cols\n",
        "    if 'chol' in df.columns and 'chol' not in num_cols_all:\n",
        "        # por si quieres seguir usando chol en la limpieza\n",
        "        num_cols_all = num_cols_all + ['chol']\n",
        "    if is_train and target_col in df.columns:\n",
        "        num_cols_all = num_cols_all + [target_col]\n",
        "\n",
        "    for col in num_cols_all:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # 5) Zeros imposibles -> NaN\n",
        "    if 'trestbps' in df.columns:\n",
        "        df.loc[df['trestbps'] == 0, 'trestbps'] = np.nan\n",
        "    if 'chol' in df.columns:\n",
        "        df.loc[df['chol'] == 0, 'chol'] = np.nan\n",
        "\n",
        "    # 6) En TRAIN: eliminar filas sin label y pasarla a int\n",
        "    if is_train and target_col in df.columns:\n",
        "        df = df.dropna(subset=[target_col])\n",
        "        df[target_col] = df[target_col].astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. Pseudo-labeling gen칠rico para XGBoost + SMOTENC\n",
        "# ============================================================\n",
        "\n",
        "def train_xgb_with_pseudo_labeling(\n",
        "    X_labeled: pd.DataFrame,\n",
        "    y_labeled: pd.Series,\n",
        "    X_unlabeled: pd.DataFrame,\n",
        "    cat_cols: list,\n",
        "    not_done_cols: list,\n",
        "    threshold: float = 0.80,\n",
        "    k_neighbors_smote: int = 3,\n",
        "    random_state: int = 42,\n",
        "):\n",
        "    \"\"\"\n",
        "    Entrena un XGBoost con pseudo-labeling (profesor + alumno).\n",
        "    \"\"\"\n",
        "\n",
        "    features = list(X_labeled.columns)\n",
        "    cat_for_smote = cat_cols + not_done_cols\n",
        "    cat_indices = [features.index(c) for c in cat_for_smote if c in features]\n",
        "\n",
        "    # 1) Split interno\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X_labeled, y_labeled,\n",
        "        test_size=0.2,\n",
        "        stratify=y_labeled,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # 2) SMOTENC en train\n",
        "    smote_nc = SMOTENC(\n",
        "        categorical_features=cat_indices,\n",
        "        sampling_strategy='not majority',\n",
        "        k_neighbors=k_neighbors_smote,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    X_tr_res, y_tr_res = smote_nc.fit_resample(X_tr, y_tr)\n",
        "\n",
        "    # 3) MODELO PROFESOR\n",
        "    xgb_teacher = XGBClassifier(\n",
        "        n_estimators=400,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=5,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        objective='multi:softprob',\n",
        "        num_class=5,\n",
        "        random_state=random_state,\n",
        "        eval_metric='mlogloss',\n",
        "        use_label_encoder=False\n",
        "    )\n",
        "\n",
        "    xgb_teacher.fit(X_tr_res, y_tr_res)\n",
        "\n",
        "    # Eval en valid\n",
        "    proba_val = xgb_teacher.predict_proba(X_val)\n",
        "    y_val_pred = proba_val.argmax(axis=1)\n",
        "\n",
        "    print(\"\\n=== PROFESOR (antes de pseudo-labeling) ===\")\n",
        "    print(\"Accuracy val:\", accuracy_score(y_val, y_val_pred))\n",
        "    print(\"F1 macro val:\", f1_score(y_val, y_val_pred, average=\"macro\"))\n",
        "    print(\"Matriz conf val:\\n\", confusion_matrix(y_val, y_val_pred))\n",
        "    print(classification_report(y_val, y_val_pred, zero_division=0))\n",
        "\n",
        "    # 4) Pseudo-labels sobre TEST (X_unlabeled)\n",
        "    proba_test = xgb_teacher.predict_proba(X_unlabeled)\n",
        "    max_conf = proba_test.max(axis=1)\n",
        "    high_conf_mask = max_conf >= threshold\n",
        "\n",
        "    print(f\"\\nPseudo-labeling con threshold={threshold}\")\n",
        "    print(f\"Muestras test totales: {X_unlabeled.shape[0]}\")\n",
        "    print(f\"Muestras test con confianza >= threshold: {high_conf_mask.sum()}\")\n",
        "\n",
        "    X_pseudo = X_unlabeled[high_conf_mask]\n",
        "    y_pseudo = proba_test[high_conf_mask].argmax(axis=1)\n",
        "\n",
        "    # 5) Train aumentado\n",
        "    X_aug = pd.concat([X_labeled, X_pseudo], axis=0)\n",
        "    y_aug = pd.concat([\n",
        "        y_labeled,\n",
        "        pd.Series(y_pseudo, index=X_pseudo.index)\n",
        "    ])\n",
        "\n",
        "    print(f\"Train original: {X_labeled.shape[0]}\")\n",
        "    print(f\"Train aumentado: {X_aug.shape[0]}\")\n",
        "\n",
        "    # 6) Nuevo split + SMOTENC + XGB alumno\n",
        "    X_tr2, X_val2, y_tr2, y_val2 = train_test_split(\n",
        "        X_aug, y_aug,\n",
        "        test_size=0.2,\n",
        "        stratify=y_aug,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    smote_nc2 = SMOTENC(\n",
        "        categorical_features=cat_indices,\n",
        "        sampling_strategy='not majority',\n",
        "        k_neighbors=k_neighbors_smote,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    X_tr2_res, y_tr2_res = smote_nc2.fit_resample(X_tr2, y_tr2)\n",
        "\n",
        "    xgb_student = XGBClassifier(\n",
        "        n_estimators=400,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=5,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        objective='multi:softprob',\n",
        "        num_class=5,\n",
        "        random_state=random_state,\n",
        "        eval_metric='mlogloss',\n",
        "        use_label_encoder=False\n",
        "    )\n",
        "\n",
        "    xgb_student.fit(X_tr2_res, y_tr2_res)\n",
        "\n",
        "    # Eval en valid (despu칠s de pseudo-labeling)\n",
        "    proba_val2 = xgb_student.predict_proba(X_val2)\n",
        "    y_val2_pred = proba_val2.argmax(axis=1)\n",
        "\n",
        "    print(\"\\n=== ALUMNO (despu칠s de pseudo-labeling) ===\")\n",
        "    print(\"Accuracy val:\", accuracy_score(y_val2, y_val2_pred))\n",
        "    print(\"F1 macro val:\", f1_score(y_val2, y_val2_pred, average=\"macro\"))\n",
        "    print(\"Matriz conf val:\\n\", confusion_matrix(y_val2, y_val2_pred))\n",
        "    print(classification_report(y_val2, y_val2_pred, zero_division=0))\n",
        "\n",
        "    # 7) Predicciones finales sobre TODO el test (X_unlabeled)\n",
        "    proba_test_final = xgb_student.predict_proba(X_unlabeled)\n",
        "    y_unlabeled_pred = proba_test_final.argmax(axis=1)\n",
        "\n",
        "    return xgb_student, y_unlabeled_pred\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. Cargar y limpiar TRAIN (train_IA + statlog)\n",
        "# ============================================================\n",
        "\n",
        "print(\"Cargando datasets de TRAIN...\")\n",
        "df_train = pd.read_csv(\"/train_IA_PROJECT.csv\")       # ajusta ruta\n",
        "df_statlog = pd.read_csv(\"/statlog_limpio.csv\")       # ajusta ruta\n",
        "\n",
        "print(f\"Filas train_IA_PROJECT: {len(df_train)}\")\n",
        "print(f\"Filas statlog_limpio   : {len(df_statlog)}\")\n",
        "\n",
        "# Fusionamos ambos\n",
        "df_total = pd.concat([df_train, df_statlog], ignore_index=True)\n",
        "print(f\"Total pacientes combinados (train+statlog): {len(df_total)}\")\n",
        "\n",
        "# 1) Flags not_done en TRAIN\n",
        "df_total = add_not_done_flags(df_total)\n",
        "\n",
        "# 2) Limpieza b치sica num칠rica + label\n",
        "df_train_clean = basic_numeric_clean(df_total, is_train=True)\n",
        "\n",
        "# 3) Imputaci칩n KNN en continuas (solo con TRAIN)\n",
        "#    OJO: usamos solo cont_cols (sin chol)  # <<< CAMBIO\n",
        "knn_imp = KNNImputer(n_neighbors=5)\n",
        "df_train_clean[cont_cols] = knn_imp.fit_transform(df_train_clean[cont_cols])\n",
        "\n",
        "# 4) NaN en categ칩ricas -> moda (solo TRAIN)\n",
        "cat_modes = {}\n",
        "for col in cat_cols:\n",
        "    moda = df_train_clean[col].mode()[0]\n",
        "    cat_modes[col] = moda\n",
        "    df_train_clean[col].fillna(moda, inplace=True)\n",
        "\n",
        "# 5) Eliminamos chol de TRAIN para que no entre al modelo  # <<< CAMBIO\n",
        "if 'chol' in df_train_clean.columns:\n",
        "    df_train_clean = df_train_clean.drop(columns=['chol'])\n",
        "\n",
        "# df_imp definitivo de TRAIN\n",
        "df_imp = df_train_clean.copy()\n",
        "\n",
        "print(\"\\nResumen df_imp (TRAIN limpio+imputado, sin chol en features):\")\n",
        "print(df_imp[features_base + [target_col]].isna().sum())\n",
        "\n",
        "# ============================================================\n",
        "# 5. Cargar y limpiar TEST de Kaggle\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nCargando TEST de Kaggle...\")\n",
        "df_test_raw = pd.read_csv(\"/test.csv\")   # ajusta ruta\n",
        "\n",
        "# 1) Flags not_done en TEST\n",
        "df_test = add_not_done_flags(df_test_raw)\n",
        "\n",
        "# 2) Limpieza b치sica num칠rica (sin label)\n",
        "df_test = basic_numeric_clean(df_test, is_train=False)\n",
        "\n",
        "# 3) Imputaci칩n KNN en continuas usando MISMO imputador que TRAIN\n",
        "df_test[cont_cols] = knn_imp.transform(df_test[cont_cols])\n",
        "\n",
        "# 4) NaN en categ칩ricas -> usar las modas del TRAIN\n",
        "for col in cat_cols:\n",
        "    df_test[col].fillna(cat_modes[col], inplace=True)\n",
        "\n",
        "# 5) Eliminamos chol tambi칠n en TEST (por coherencia)  # <<< CAMBIO\n",
        "if 'chol' in df_test.columns:\n",
        "    df_test = df_test.drop(columns=['chol'])\n",
        "\n",
        "print(\"\\nNaNs en TEST despu칠s de limpieza (features_base):\")\n",
        "print(df_test[features_base].isna().sum())\n",
        "\n",
        "# ============================================================\n",
        "# 6. Preparar matrices X e y (global y mujeres)\n",
        "# ============================================================\n",
        "\n",
        "X_full = df_imp[features_base].copy()\n",
        "y_full = df_imp[target_col].astype(int)\n",
        "\n",
        "X_test_kaggle = df_test[features_base].copy()\n",
        "\n",
        "print(\"\\nShape X_full (TRAIN):\", X_full.shape)\n",
        "print(\"Distrib clases TRAIN:\")\n",
        "print(y_full.value_counts().sort_index())\n",
        "\n",
        "# Subconjunto mujeres en TRAIN y TEST\n",
        "mask_female_train = (df_imp[\"sex\"] == 0)\n",
        "mask_female_test  = (df_test[\"sex\"] == 0)\n",
        "\n",
        "X_female_train = X_full[mask_female_train].copy()\n",
        "y_female_train = y_full[mask_female_train].copy()\n",
        "\n",
        "X_female_test = X_test_kaggle[mask_female_test].copy()\n",
        "\n",
        "print(\"\\nDistrib clases en MUJERES (TRAIN):\")\n",
        "print(y_female_train.value_counts().sort_index())\n",
        "\n",
        "# ============================================================\n",
        "# 7. Pseudo-labeling GLOBAL\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\\n================ GLOBAL: PSEUDO-LABELING (sin chol) ================\")\n",
        "\n",
        "model_global, y_pred_test_global = train_xgb_with_pseudo_labeling(\n",
        "    X_labeled=X_full,\n",
        "    y_labeled=y_full,\n",
        "    X_unlabeled=X_test_kaggle,\n",
        "    cat_cols=cat_cols,\n",
        "    not_done_cols=not_done_cols,\n",
        "    threshold=0.80,\n",
        "    k_neighbors_smote=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 8. Pseudo-labeling ESPEC칈FICO MUJERES\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\\n================ MUJERES: PSEUDO-LABELING (sin chol) ================\")\n",
        "\n",
        "model_female, y_pred_test_female = train_xgb_with_pseudo_labeling(\n",
        "    X_labeled=X_female_train,\n",
        "    y_labeled=y_female_train,\n",
        "    X_unlabeled=X_female_test,\n",
        "    cat_cols=cat_cols,\n",
        "    not_done_cols=not_done_cols,\n",
        "    threshold=0.80,\n",
        "    k_neighbors_smote=2,   # como antes para mujeres\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 9. Combinar predicciones GLOBAL + MUJERES y crear submission\n",
        "# ============================================================\n",
        "\n",
        "# Empezamos del modelo global\n",
        "y_pred_combined_test = y_pred_test_global.copy()\n",
        "\n",
        "# Sustituimos en las filas de mujeres por el modelo espec칤fico\n",
        "y_pred_combined_test[mask_female_test.values] = y_pred_test_female\n",
        "\n",
        "print(\"\\nDistribuci칩n predicciones COMBINADAS en test (sin chol):\")\n",
        "unique, counts = np.unique(y_pred_combined_test, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "# Cargar sample_submission\n",
        "sub = pd.read_csv(\"/sample_submission.csv\")  # ajusta ruta\n",
        "\n",
        "print(\"\\nFilas test Kaggle:\", len(X_test_kaggle))\n",
        "print(\"Filas sample_submission:\", len(sub))\n",
        "\n",
        "# Asignar las predicciones combinadas\n",
        "sub[\"label\"] = y_pred_combined_test.astype(int)\n",
        "\n",
        "# Guardar submission\n",
        "sub.to_csv(\"submission_sin_chol.csv\", index=False)\n",
        "print(\"\\n九 submission_sin_chol.csv generado en el directorio actual\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMQuJcb3hmZ0"
      },
      "source": [
        "# 4춹 PRUEBA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZge7A7OhoPY",
        "outputId": "c9b1b827-bc83-4d9d-92c0-54a2be977c89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando datasets de TRAIN...\n",
            "Filas train_IA_PROJECT: 732\n",
            "Filas statlog_limpio   : 270\n",
            "Total pacientes combinados (train+statlog): 1002\n",
            "\n",
            "Resumen df_imp (TRAIN limpio+imputado, sin chol en features):\n",
            "age               0\n",
            "trestbps          0\n",
            "thalach           0\n",
            "oldpeak           0\n",
            "sex               0\n",
            "cp                0\n",
            "fbs               0\n",
            "restecg           0\n",
            "exang             0\n",
            "slope             0\n",
            "ca                0\n",
            "thal              0\n",
            "chol_not_done     0\n",
            "slope_not_done    0\n",
            "ca_not_done       0\n",
            "thal_not_done     0\n",
            "fbs_not_done      0\n",
            "label             0\n",
            "dtype: int64\n",
            "\n",
            "Cargando TEST de Kaggle...\n",
            "\n",
            "NaNs en TEST despu칠s de limpieza (features_base):\n",
            "age               0\n",
            "trestbps          0\n",
            "thalach           0\n",
            "oldpeak           0\n",
            "sex               0\n",
            "cp                0\n",
            "fbs               0\n",
            "restecg           0\n",
            "exang             0\n",
            "slope             0\n",
            "ca                0\n",
            "thal              0\n",
            "chol_not_done     0\n",
            "slope_not_done    0\n",
            "ca_not_done       0\n",
            "thal_not_done     0\n",
            "fbs_not_done      0\n",
            "dtype: int64\n",
            "\n",
            "Shape X_full (TRAIN): (1002, 17)\n",
            "Distrib clases TRAIN (04):\n",
            "label\n",
            "0    477\n",
            "1    276\n",
            "2    108\n",
            "3    107\n",
            "4     34\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3527276797.py:133: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train_clean[col].fillna(moda, inplace=True)\n",
            "/tmp/ipython-input-3527276797.py:164: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[col].fillna(cat_modes[col], inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========== MODELO GENERAL: LOGISTIC REGRESSION (0 vs 14) ==========\n",
            "Accuracy binario (val): 0.8407960199004975\n",
            "F1 macro binario (val): 0.8401272618810897\n",
            "Matriz conf binaria (val):\n",
            " [[78 18]\n",
            " [14 91]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83        96\n",
            "           1       0.83      0.87      0.85       105\n",
            "\n",
            "    accuracy                           0.84       201\n",
            "   macro avg       0.84      0.84      0.84       201\n",
            "weighted avg       0.84      0.84      0.84       201\n",
            "\n",
            "\n",
            "========== MODELO ESPEC칈FICO: RANDOM FOREST (severidad 14) ==========\n",
            "Accuracy severidad (val): 0.41904761904761906\n",
            "F1 macro severidad (val): 0.35309716599190283\n",
            "Matriz conf severidad (val):\n",
            " [[29 16  8  2]\n",
            " [ 7  7  3  5]\n",
            " [ 7  6  5  3]\n",
            " [ 2  1  1  3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.64      0.53      0.58        55\n",
            "           2       0.23      0.32      0.27        22\n",
            "           3       0.29      0.24      0.26        21\n",
            "           4       0.23      0.43      0.30         7\n",
            "\n",
            "    accuracy                           0.42       105\n",
            "   macro avg       0.35      0.38      0.35       105\n",
            "weighted avg       0.46      0.42      0.43       105\n",
            "\n",
            "\n",
            "En test, n칰mero de enfermos predichos (p_sick>=0.5): 100\n",
            "N칰mero de sanos predichos: 84\n",
            "\n",
            "Distribuci칩n de predicciones finales (04) en test:\n",
            "{np.int64(0): np.int64(84), np.int64(1): np.int64(40), np.int64(2): np.int64(30), np.int64(3): np.int64(23), np.int64(4): np.int64(7)}\n",
            "\n",
            "Filas test Kaggle: 184\n",
            "Filas sample_submission: 184\n",
            "\n",
            "九 submission_logreg_rf.csv generado en el directorio actual\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ============================================================\n",
        "# 1. Definici칩n de columnas (SIN chol)\n",
        "# ============================================================\n",
        "\n",
        "# Continuas biom칠tricas (quitamos chol)\n",
        "cont_cols = ['age', 'trestbps', 'thalach', 'oldpeak']\n",
        "\n",
        "# Categ칩ricas cl칤nicas\n",
        "cat_cols  = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "# Flags de pruebas NO realizadas (mantenemos chol_not_done)\n",
        "not_done_cols = ['chol_not_done', 'slope_not_done', 'ca_not_done', 'thal_not_done', 'fbs_not_done']\n",
        "\n",
        "features_base = cont_cols + cat_cols + not_done_cols\n",
        "target_col = 'label'\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. Funciones de limpieza compartidas (TRAIN + TEST)\n",
        "# ============================================================\n",
        "\n",
        "def add_not_done_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Crea columnas *_not_done a partir de -9/-9.0 en ciertas variables.\n",
        "    No modifica todav칤a los valores (eso se hace en otra funci칩n).\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # chol, slope, ca, thal, fbs\n",
        "    for col in ['chol', 'slope', 'ca', 'thal', 'fbs']:\n",
        "        if col in df.columns:\n",
        "            mask_nd = df[col].astype(str).isin(['-9', '-9.0'])\n",
        "            df[col + '_not_done'] = mask_nd.astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def basic_numeric_clean(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    - \"?\" -> NaN\n",
        "    - -9 en chol/slope/ca/thal -> NaN\n",
        "    - fbs -9 -> 0\n",
        "    - Convierte columnas a num칠ricas\n",
        "    - Marca 0 imposibles como NaN\n",
        "    - En TRAIN, limpia label\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1) \"?\" -> NaN\n",
        "    df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "    # 2) -9 para chol/slope/ca/thal -> NaN (prueba no realizada)\n",
        "    for col in ['chol', 'slope', 'ca', 'thal']:\n",
        "        if col in df.columns:\n",
        "            mask_nd = df[col].astype(str).isin(['-9', '-9.0'])\n",
        "            df.loc[mask_nd, col] = np.nan\n",
        "\n",
        "    # 3) fbs: -9 / -9.0 -> 0 (pero con flag fbs_not_done)\n",
        "    if 'fbs' in df.columns:\n",
        "        df['fbs'] = df['fbs'].replace(['-9', '-9.0'], 0)\n",
        "\n",
        "    # 4) Convertir columnas num칠ricas a float/int\n",
        "    num_cols_all = cont_cols + cat_cols\n",
        "    if 'chol' in df.columns and 'chol' not in num_cols_all:\n",
        "        num_cols_all = num_cols_all + ['chol']\n",
        "    if is_train and target_col in df.columns:\n",
        "        num_cols_all = num_cols_all + [target_col]\n",
        "\n",
        "    for col in num_cols_all:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # 5) Zeros imposibles -> NaN\n",
        "    if 'trestbps' in df.columns:\n",
        "        df.loc[df['trestbps'] == 0, 'trestbps'] = np.nan\n",
        "    if 'chol' in df.columns:\n",
        "        df.loc[df['chol'] == 0, 'chol'] = np.nan\n",
        "\n",
        "    # 6) En TRAIN: eliminar filas sin label y pasarla a int\n",
        "    if is_train and target_col in df.columns:\n",
        "        df = df.dropna(subset=[target_col])\n",
        "        df[target_col] = df[target_col].astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. Cargar y limpiar TRAIN (train_IA + statlog)\n",
        "# ============================================================\n",
        "\n",
        "print(\"Cargando datasets de TRAIN...\")\n",
        "df_train = pd.read_csv(\"/train_IA_PROJECT.csv\")       # 游대 ajusta ruta si hace falta\n",
        "df_statlog = pd.read_csv(\"/statlog_limpio.csv\")       # 游대 ajusta ruta si hace falta\n",
        "\n",
        "print(f\"Filas train_IA_PROJECT: {len(df_train)}\")\n",
        "print(f\"Filas statlog_limpio   : {len(df_statlog)}\")\n",
        "\n",
        "# Fusionamos ambos\n",
        "df_total = pd.concat([df_train, df_statlog], ignore_index=True)\n",
        "print(f\"Total pacientes combinados (train+statlog): {len(df_total)}\")\n",
        "\n",
        "# 1) Flags not_done en TRAIN\n",
        "df_total = add_not_done_flags(df_total)\n",
        "\n",
        "# 2) Limpieza b치sica num칠rica + label\n",
        "df_train_clean = basic_numeric_clean(df_total, is_train=True)\n",
        "\n",
        "# 3) Imputaci칩n KNN en continuas (solo con TRAIN)\n",
        "knn_imp = KNNImputer(n_neighbors=5)\n",
        "df_train_clean[cont_cols] = knn_imp.fit_transform(df_train_clean[cont_cols])\n",
        "\n",
        "# 4) NaN en categ칩ricas -> moda (solo TRAIN)\n",
        "cat_modes = {}\n",
        "for col in cat_cols:\n",
        "    moda = df_train_clean[col].mode()[0]\n",
        "    cat_modes[col] = moda\n",
        "    df_train_clean[col].fillna(moda, inplace=True)\n",
        "\n",
        "# 5) Eliminamos chol de TRAIN para que no entre al modelo\n",
        "if 'chol' in df_train_clean.columns:\n",
        "    df_train_clean = df_train_clean.drop(columns=['chol'])\n",
        "\n",
        "# df_imp definitivo de TRAIN\n",
        "df_imp = df_train_clean.copy()\n",
        "\n",
        "print(\"\\nResumen df_imp (TRAIN limpio+imputado, sin chol en features):\")\n",
        "print(df_imp[features_base + [target_col]].isna().sum())\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. Cargar y limpiar TEST de Kaggle\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nCargando TEST de Kaggle...\")\n",
        "df_test_raw = pd.read_csv(\"/test.csv\")   # 游대 ajusta ruta si hace falta\n",
        "\n",
        "# 1) Flags not_done en TEST\n",
        "df_test = add_not_done_flags(df_test_raw)\n",
        "\n",
        "# 2) Limpieza b치sica num칠rica (sin label)\n",
        "df_test = basic_numeric_clean(df_test, is_train=False)\n",
        "\n",
        "# 3) Imputaci칩n KNN en continuas usando MISMO imputador que TRAIN\n",
        "df_test[cont_cols] = knn_imp.transform(df_test[cont_cols])\n",
        "\n",
        "# 4) NaN en categ칩ricas -> usar las modas del TRAIN\n",
        "for col in cat_cols:\n",
        "    df_test[col].fillna(cat_modes[col], inplace=True)\n",
        "\n",
        "# 5) Eliminamos chol tambi칠n en TEST (por coherencia)\n",
        "if 'chol' in df_test.columns:\n",
        "    df_test = df_test.drop(columns=['chol'])\n",
        "\n",
        "print(\"\\nNaNs en TEST despu칠s de limpieza (features_base):\")\n",
        "print(df_test[features_base].isna().sum())\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. Preparar matrices X e y\n",
        "# ============================================================\n",
        "\n",
        "X_full = df_imp[features_base].copy()\n",
        "y_full = df_imp[target_col].astype(int)\n",
        "\n",
        "X_test_kaggle = df_test[features_base].copy()\n",
        "\n",
        "print(\"\\nShape X_full (TRAIN):\", X_full.shape)\n",
        "print(\"Distrib clases TRAIN (04):\")\n",
        "print(y_full.value_counts().sort_index())\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. Modelo general: Regresi칩n Log칤stica BINARIA (0 vs 14)\n",
        "# ============================================================\n",
        "\n",
        "# Etiqueta binaria: 0 = sano, 1 = enfermo\n",
        "y_bin = (y_full > 0).astype(int)\n",
        "\n",
        "# Split train/valid\n",
        "Xb_train, Xb_val, yb_train, yb_val = train_test_split(\n",
        "    X_full, y_bin,\n",
        "    test_size=0.2,\n",
        "    stratify=y_bin,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# SMOTENC para balancear el binario\n",
        "features = list(X_full.columns)\n",
        "cat_for_smote = cat_cols + not_done_cols\n",
        "cat_indices = [features.index(c) for c in cat_for_smote if c in features]\n",
        "\n",
        "smote_bin = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',\n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "Xb_train_res, yb_train_res = smote_bin.fit_resample(Xb_train, yb_train)\n",
        "\n",
        "# Regresi칩n log칤stica binaria\n",
        "log_reg = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced',\n",
        "    solver='lbfgs'\n",
        ")\n",
        "\n",
        "log_reg.fit(Xb_train_res, yb_train_res)\n",
        "\n",
        "# M칠tricas en valid binario\n",
        "yb_val_pred = log_reg.predict(Xb_val)\n",
        "\n",
        "print(\"\\n========== MODELO GENERAL: LOGISTIC REGRESSION (0 vs 14) ==========\")\n",
        "print(\"Accuracy binario (val):\", accuracy_score(yb_val, yb_val_pred))\n",
        "print(\"F1 macro binario (val):\", f1_score(yb_val, yb_val_pred, average=\"macro\"))\n",
        "print(\"Matriz conf binaria (val):\\n\", confusion_matrix(yb_val, yb_val_pred))\n",
        "print(classification_report(yb_val, yb_val_pred, zero_division=0))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. Modelo espec칤fico: Random Forest para severidad 14\n",
        "# ============================================================\n",
        "\n",
        "# Nos quedamos SOLO con enfermos para el modelo de severidad\n",
        "mask_sick = (y_full > 0)\n",
        "X_sick = X_full[mask_sick].copy()\n",
        "y_sick = y_full[mask_sick].copy()   # valores 14\n",
        "\n",
        "# Split train/valid en enfermos\n",
        "Xs_train, Xs_val, ys_train, ys_val = train_test_split(\n",
        "    X_sick, y_sick,\n",
        "    test_size=0.2,\n",
        "    stratify=y_sick,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# SMOTENC para balancear clases 14\n",
        "smote_sev = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',\n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "Xs_train_res, ys_train_res = smote_sev.fit_resample(Xs_train, ys_train)\n",
        "\n",
        "# Random Forest multiclase\n",
        "rf_severity = RandomForestClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=None,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_severity.fit(Xs_train_res, ys_train_res)\n",
        "\n",
        "# M칠tricas en valid severidad\n",
        "ys_val_pred = rf_severity.predict(Xs_val)\n",
        "\n",
        "print(\"\\n========== MODELO ESPEC칈FICO: RANDOM FOREST (severidad 14) ==========\")\n",
        "print(\"Accuracy severidad (val):\", accuracy_score(ys_val, ys_val_pred))\n",
        "print(\"F1 macro severidad (val):\", f1_score(ys_val, ys_val_pred, average=\"macro\"))\n",
        "print(\"Matriz conf severidad (val):\\n\", confusion_matrix(ys_val, ys_val_pred))\n",
        "print(classification_report(ys_val, ys_val_pred, zero_division=0))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. Predicci칩n en TEST: combinaci칩n LogReg (0/1) + RF (14)\n",
        "# ============================================================\n",
        "\n",
        "# 1) Predicciones binarios en test (probabilidad de estar enfermo)\n",
        "proba_test_bin = log_reg.predict_proba(X_test_kaggle)\n",
        "p_sick = proba_test_bin[:, 1]\n",
        "\n",
        "# Puedes tunear este umbral; por defecto 0.5\n",
        "threshold = 0.5\n",
        "mask_sick_test = (p_sick >= threshold)\n",
        "\n",
        "print(f\"\\nEn test, n칰mero de enfermos predichos (p_sick>={threshold}):\", mask_sick_test.sum())\n",
        "print(\"N칰mero de sanos predichos:\", (~mask_sick_test).sum())\n",
        "\n",
        "# 2) Inicializamos todas las predicciones de test como 0 (sano)\n",
        "y_test_pred_final = np.zeros(len(X_test_kaggle), dtype=int)\n",
        "\n",
        "# 3) Para los que el modelo binario dice \"enfermo\", usamos el RF 14\n",
        "X_test_sick = X_test_kaggle[mask_sick_test]\n",
        "y_test_sick_pred = rf_severity.predict(X_test_sick)\n",
        "\n",
        "# Insertamos esas predicciones 14 en las posiciones correspondientes\n",
        "y_test_pred_final[mask_sick_test] = y_test_sick_pred\n",
        "\n",
        "print(\"\\nDistribuci칩n de predicciones finales (04) en test:\")\n",
        "unique, counts = np.unique(y_test_pred_final, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9. Crear submission\n",
        "# ============================================================\n",
        "\n",
        "sub = pd.read_csv(\"/sample_submission.csv\")  # 游대 ajusta ruta si hace falta\n",
        "\n",
        "print(\"\\nFilas test Kaggle:\", len(X_test_kaggle))\n",
        "print(\"Filas sample_submission:\", len(sub))\n",
        "\n",
        "sub[\"label\"] = y_test_pred_final.astype(int)\n",
        "\n",
        "sub.to_csv(\"submission_logreg_rf.csv\", index=False)\n",
        "print(\"\\n九 submission_logreg_rf.csv generado en el directorio actual\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV635n94layJ"
      },
      "source": [
        "# PRUEBA 5춹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YChSy-CPlkVx",
        "outputId": "ae5c04f0-5e07-4bf7-9ee7-513429393e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Cargando datos ===\n",
            "Train shape   : (732, 14)\n",
            "Statlog shape : (270, 14)\n",
            "Test shape    : (184, 13)\n",
            "\n",
            "=== Despu칠s de limpiar y a침adir features ===\n",
            "Train columns: ['age', 'sex', 'cp', 'trestbps', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'label', 'hi_bp', 'hi_oldpeak', 'low_thalach']\n",
            "Test  columns: ['age', 'sex', 'cp', 'trestbps', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'hi_bp', 'hi_oldpeak', 'low_thalach']\n",
            "\n",
            "Train_full shape: (1002, 16)\n",
            "Columnas que NO se usar치n como features: ['label']\n",
            "\n",
            "Features finales: ['age', 'sex', 'cp', 'trestbps', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'hi_bp', 'hi_oldpeak', 'low_thalach']\n",
            "X shape     : (1002, 15)\n",
            "X_test shape: (184, 15)\n",
            "\n",
            "=== Imputaci칩n y escalado ===\n",
            "X_scaled shape     : (1002, 15)\n",
            "X_test_scaled shape: (184, 15)\n",
            "\n",
            "=== Definiendo modelo base (VotingClassifier: LR + RF) ===\n",
            "\n",
            "=== FASE 1: Entrenamiento inicial con datos reales ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo entrenado.\n",
            "\n",
            "=== FASE 2: Pseudo-labeling ===\n",
            "Inicialmente hay 36 pseudo-candidatos con prob >= 0.863 (top 20%).\n",
            "De ellos, 36 pertenecen a clases 0,1,2 (las que m치s nos importan).\n",
            "\n",
            "Usaremos 36 pseudo-ejemplos para reforzar las clases 0,1,2.\n",
            "Dataset real : 1002\n",
            "Dataset pseudo: 36\n",
            "Total        : 1038\n",
            "\n",
            "=== FASE 3: Re-entrenamiento final con pseudo-labels (pesan menos) ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo final entrenado.\n",
            "\n",
            "=== FASE 4: Predicci칩n final sobre test ===\n",
            "\n",
            "Columnas de sample_submission:\n",
            "Index(['ID', 'label'], dtype='object')\n",
            "\n",
            "Filas test Kaggle: 184\n",
            "Filas sample_submission: 184\n",
            "\n",
            "九 submission_logreg_rf.csv generado con la misma estructura que sample_submission.csv\n"
          ]
        }
      ],
      "source": [
        "# modelo_pseudo_labeling_v2.py\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# ============================================================\n",
        "# 1. Carga de datos\n",
        "# ============================================================\n",
        "TRAIN_PATH   = \"/train_IA_PROJECT.csv\"\n",
        "EXTRA_PATH   = \"/statlog_limpio.csv\"   # datos adicionales que ya usabas\n",
        "TEST_PATH    = \"/test.csv\"\n",
        "TARGET_COL   = \"label\"                # ajusta si se llama distinto\n",
        "\n",
        "print(\"=== Cargando datos ===\")\n",
        "df_train   = pd.read_csv(TRAIN_PATH)\n",
        "df_statlog = pd.read_csv(EXTRA_PATH)\n",
        "df_test    = pd.read_csv(TEST_PATH)\n",
        "\n",
        "print(\"Train shape   :\", df_train.shape)\n",
        "print(\"Statlog shape :\", df_statlog.shape)\n",
        "print(\"Test shape    :\", df_test.shape)\n",
        "\n",
        "# ============================================================\n",
        "# 2. Eliminar 'chol' y a침adir features sencillas\n",
        "# ============================================================\n",
        "def add_simple_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "\n",
        "    # Convertir a num칠rico por si vienen como strings\n",
        "    for col in [\"trestbps\", \"oldpeak\", \"thalach\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    # Hipertensi칩n\n",
        "    if \"trestbps\" in df.columns:\n",
        "        df[\"hi_bp\"] = (df[\"trestbps\"] >= 140).astype(int)\n",
        "\n",
        "    # ST muy deprimido\n",
        "    if \"oldpeak\" in df.columns:\n",
        "        df[\"hi_oldpeak\"] = (df[\"oldpeak\"] >= 2.0).astype(int)\n",
        "\n",
        "    # Frecuencia cardiaca m치xima baja\n",
        "    if \"thalach\" in df.columns:\n",
        "        df[\"low_thalach\"] = (df[\"thalach\"] <= 120).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "for df_name, df in [(\"train\", df_train), (\"statlog\", df_statlog), (\"test\", df_test)]:\n",
        "    df_local = df\n",
        "\n",
        "    # Quitar 'chol' si existe\n",
        "    if \"chol\" in df_local.columns:\n",
        "        df_local = df_local.drop(columns=[\"chol\"])\n",
        "\n",
        "    # A침adir features derivadas\n",
        "    df_local = add_simple_features(df_local)\n",
        "\n",
        "    # Reasignar\n",
        "    if df_name == \"train\":\n",
        "        df_train = df_local\n",
        "    elif df_name == \"statlog\":\n",
        "        df_statlog = df_local\n",
        "    else:\n",
        "        df_test = df_local\n",
        "\n",
        "print(\"\\n=== Despu칠s de limpiar y a침adir features ===\")\n",
        "print(\"Train columns:\", df_train.columns.tolist())\n",
        "print(\"Test  columns:\", df_test.columns.tolist())\n",
        "\n",
        "# ============================================================\n",
        "# 3. Construir df_train_full (train + statlog) y preparar X, y\n",
        "# ============================================================\n",
        "# Nos aseguramos de que df_statlog tenga la columna TARGET_COL\n",
        "if TARGET_COL not in df_statlog.columns:\n",
        "    raise ValueError(f\"En {EXTRA_PATH} debe existir la columna '{TARGET_COL}' con las etiquetas.\")\n",
        "\n",
        "df_train_full = pd.concat([df_train, df_statlog], axis=0, ignore_index=True)\n",
        "print(\"\\nTrain_full shape:\", df_train_full.shape)\n",
        "\n",
        "# Columnas a excluir como features\n",
        "cols_to_drop = [TARGET_COL]\n",
        "for extra_col in [\"id\", \"ID\", \"patient\", \"index\", \"Unnamed: 0\"]:\n",
        "    if extra_col in df_train_full.columns:\n",
        "        cols_to_drop.append(extra_col)\n",
        "\n",
        "cols_to_drop = list(dict.fromkeys(cols_to_drop))  # quitar duplicados\n",
        "\n",
        "print(\"Columnas que NO se usar치n como features:\", cols_to_drop)\n",
        "\n",
        "# X, y para entrenamiento\n",
        "y = df_train_full[TARGET_COL].astype(int)\n",
        "X = df_train_full.drop(columns=cols_to_drop)\n",
        "\n",
        "# X_test: mismas columnas que X (orden consistente)\n",
        "X_test = df_test.copy()\n",
        "# Quitar tambi칠n posibles columnas tipo id en test\n",
        "for col in cols_to_drop:\n",
        "    if col in X_test.columns and col != TARGET_COL:\n",
        "        X_test = X_test.drop(columns=[col])\n",
        "\n",
        "# Asegurarnos de tener mismas columnas en train/test (por si acaso)\n",
        "X_test = X_test[X.columns]\n",
        "\n",
        "print(\"\\nFeatures finales:\", X.columns.tolist())\n",
        "print(\"X shape     :\", X.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "\n",
        "# Convertir todo a num칠rico (por seguridad)\n",
        "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "X_test = X_test.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. Imputaci칩n + escalado\n",
        "# ============================================================\n",
        "print(\"\\n=== Imputaci칩n y escalado ===\")\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "X_imp      = imputer.fit_transform(X)\n",
        "X_test_imp = imputer.transform(X_test)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled      = scaler.fit_transform(X_imp)\n",
        "X_test_scaled = scaler.transform(X_test_imp)\n",
        "\n",
        "print(\"X_scaled shape     :\", X_scaled.shape)\n",
        "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
        "\n",
        "# ============================================================\n",
        "# 5. Definici칩n del modelo base (Voting: LR + RF)\n",
        "# ============================================================\n",
        "print(\"\\n=== Definiendo modelo base (VotingClassifier: LR + RF) ===\")\n",
        "\n",
        "clf_lr = LogisticRegression(\n",
        "    solver=\"lbfgs\",\n",
        "    multi_class=\"multinomial\",\n",
        "    max_iter=5000,\n",
        "    C=2.0,               # un pel칤n menos regularizaci칩n que el default\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "clf_rf = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=None,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    class_weight=None,   # prueba tambi칠n \"balanced_subsample\" si quieres\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model = VotingClassifier(\n",
        "    estimators=[(\"lr\", clf_lr), (\"rf\", clf_rf)],\n",
        "    voting=\"soft\",\n",
        "    weights=[2, 1]  # dar algo m치s de peso a LR (suele generalizar mejor)\n",
        ")\n",
        "\n",
        "print(\"\\n=== FASE 1: Entrenamiento inicial con datos reales ===\")\n",
        "model.fit(X_scaled, y)\n",
        "print(\"Modelo entrenado.\")\n",
        "\n",
        "# ============================================================\n",
        "# 6. Pseudo-labeling: seleccionar muestras muy seguras (solo clases 02)\n",
        "# ============================================================\n",
        "print(\"\\n=== FASE 2: Pseudo-labeling ===\")\n",
        "probs = model.predict_proba(X_test_scaled)   # (n_test, n_clases)\n",
        "preds = model.predict(X_test_scaled)\n",
        "\n",
        "max_probs = np.max(probs, axis=1)\n",
        "\n",
        "# Estrategia: top 20% m치s seguro como candidatos\n",
        "fraction = 0.2\n",
        "k = int(len(max_probs) * fraction)\n",
        "\n",
        "if k > 0:\n",
        "    sorted_probs = np.sort(max_probs)\n",
        "    threshold = sorted_probs[-k]  # prob m칤nima del top 20%\n",
        "else:\n",
        "    threshold = 0.95\n",
        "\n",
        "candidate_indices = np.where(max_probs >= threshold)[0]\n",
        "print(f\"Inicialmente hay {len(candidate_indices)} pseudo-candidatos con prob >= {threshold:.3f} (top {fraction*100:.0f}%).\")\n",
        "\n",
        "# Filtrar SOLO las pseudo-etiquetas que son clases 0, 1 o 2\n",
        "candidate_preds = preds[candidate_indices]\n",
        "mask_012 = candidate_preds <= 2\n",
        "high_conf_indices = candidate_indices[mask_012]\n",
        "\n",
        "print(f\"De ellos, {len(high_conf_indices)} pertenecen a clases 0,1,2 (las que m치s nos importan).\")\n",
        "\n",
        "if len(high_conf_indices) == 0:\n",
        "    print(\"丘멆잺 No se han encontrado pseudo-labels suficientemente seguros en 0,1,2.\")\n",
        "    print(\"   Contin칰o sin pseudo-labeling (modelo inicial).\")\n",
        "    X_augmented = X_scaled\n",
        "    y_augmented = y.values\n",
        "    weights = np.ones(len(y_augmented))\n",
        "else:\n",
        "    X_pseudo_scaled = X_test_scaled[high_conf_indices]\n",
        "    y_pseudo = preds[high_conf_indices]\n",
        "\n",
        "    n_train  = X_scaled.shape[0]\n",
        "    n_pseudo = X_pseudo_scaled.shape[0]\n",
        "\n",
        "    print(f\"\\nUsaremos {n_pseudo} pseudo-ejemplos para reforzar las clases 0,1,2.\")\n",
        "\n",
        "    # Aumentar dataset\n",
        "    X_augmented = np.vstack([X_scaled, X_pseudo_scaled])\n",
        "    y_augmented = np.concatenate([y.values, y_pseudo])\n",
        "\n",
        "    # Pesos: 1.0 para datos reales, 0.3 para pseudo-labels\n",
        "    weights = np.ones(n_train + n_pseudo)\n",
        "    weights[n_train:] = 0.3\n",
        "\n",
        "    print(f\"Dataset real : {n_train}\")\n",
        "    print(f\"Dataset pseudo: {n_pseudo}\")\n",
        "    print(f\"Total        : {n_train + n_pseudo}\")\n",
        "\n",
        "# ============================================================\n",
        "# 7. Re-entrenamiento final con pesos (datos reales + pseudo)\n",
        "# ============================================================\n",
        "print(\"\\n=== FASE 3: Re-entrenamiento final con pseudo-labels (pesan menos) ===\")\n",
        "\n",
        "# Reinstanciamos el modelo para entrenarlo desde cero con el dataset aumentado\n",
        "model_final = VotingClassifier(\n",
        "    estimators=[(\"lr\", clf_lr), (\"rf\", clf_rf)],\n",
        "    voting=\"soft\",\n",
        "    weights=[2, 1]\n",
        ")\n",
        "\n",
        "model_final.fit(X_augmented, y_augmented, sample_weight=weights)\n",
        "print(\"Modelo final entrenado.\")\n",
        "\n",
        "# ============================================================\n",
        "# 8. Predicci칩n sobre el test y generaci칩n de submission\n",
        "# ============================================================\n",
        "print(\"\\n=== FASE 4: Predicci칩n final sobre test ===\")\n",
        "y_test_pred = model_final.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9. Crear submission con la MISMA ESTRUCTURA que sample_submission\n",
        "# ============================================================\n",
        "\n",
        "# Leemos la plantilla exacta\n",
        "sub = pd.read_csv(\"/sample_submission.csv\")  # usa la ruta real de tu plantilla\n",
        "\n",
        "print(\"\\nColumnas de sample_submission:\")\n",
        "print(sub.columns)\n",
        "\n",
        "print(\"\\nFilas test Kaggle:\", len(X_test_kaggle))\n",
        "print(\"Filas sample_submission:\", len(sub))\n",
        "\n",
        "if len(sub) != len(X_test_kaggle):\n",
        "    raise ValueError(\n",
        "        f\"仇 El n칰mero de filas del test ({len(X_test_kaggle)}) \"\n",
        "        f\"no coincide con sample_submission ({len(sub)})\"\n",
        "    )\n",
        "\n",
        "# Detectamos la(s) columna(s) de predicci칩n.\n",
        "# Caso t칤pico: hay una columna 'label', pero si no, usamos la 칰ltima columna.\n",
        "if \"label\" in sub.columns:\n",
        "    label_col = \"label\"\n",
        "else:\n",
        "    # Tomamos la 칰ltima columna como columna de predicci칩n\n",
        "    label_col = sub.columns[-1]\n",
        "    print(f\"丘멆잺 No se encontr칩 columna 'label'. \"\n",
        "          f\"Usando '{label_col}' como columna de predicci칩n.\")\n",
        "\n",
        "# Asignamos nuestras predicciones finales (04) a esa columna\n",
        "sub[label_col] = y_test_pred_final.astype(int)\n",
        "\n",
        "# Guardamos el CSV con el mismo formato de la plantilla\n",
        "sub.to_csv(\"submission_logreg_rf.csv\", index=False)\n",
        "print(\"\\n九 submission_logreg_rf.csv generado con la misma estructura que sample_submission.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUW33rMcp68b",
        "outputId": "1a08f78a-e8b2-46a4-be92-d243e26dbc9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando datasets de TRAIN...\n",
            "Filas train_IA_PROJECT: 732\n",
            "Filas statlog_limpio   : 270\n",
            "Total pacientes combinados (train+statlog): 1002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2935985748.py:128: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train_clean[col].fillna(moda, inplace=True)\n",
            "/tmp/ipython-input-2935985748.py:155: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[col].fillna(cat_modes[col], inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resumen df_imp (TRAIN limpio+imputado):\n",
            "age               0\n",
            "trestbps          0\n",
            "chol              0\n",
            "thalach           0\n",
            "oldpeak           0\n",
            "sex               0\n",
            "cp                0\n",
            "fbs               0\n",
            "restecg           0\n",
            "exang             0\n",
            "slope             0\n",
            "ca                0\n",
            "thal              0\n",
            "chol_not_done     0\n",
            "slope_not_done    0\n",
            "ca_not_done       0\n",
            "thal_not_done     0\n",
            "fbs_not_done      0\n",
            "label             0\n",
            "dtype: int64\n",
            "\n",
            "Cargando TEST de Kaggle...\n",
            "\n",
            "NaNs en TEST despu칠s de limpieza (features_base):\n",
            "age               0\n",
            "trestbps          0\n",
            "chol              0\n",
            "thalach           0\n",
            "oldpeak           0\n",
            "sex               0\n",
            "cp                0\n",
            "fbs               0\n",
            "restecg           0\n",
            "exang             0\n",
            "slope             0\n",
            "ca                0\n",
            "thal              0\n",
            "chol_not_done     0\n",
            "slope_not_done    0\n",
            "ca_not_done       0\n",
            "thal_not_done     0\n",
            "fbs_not_done      0\n",
            "dtype: int64\n",
            "\n",
            "Shape X_full (TRAIN): (1002, 18)\n",
            "Distrib clases TRAIN (04):\n",
            "label\n",
            "0    477\n",
            "1    276\n",
            "2    108\n",
            "3    107\n",
            "4     34\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [16:17:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========== MODELO GENERAL: XGB BINARIO (0 vs 14) ==========\n",
            "Accuracy binario (val): 0.8855721393034826\n",
            "F1 macro binario (val): 0.8850143017037682\n",
            "Matriz conf binaria (val):\n",
            " [[82 14]\n",
            " [ 9 96]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.85      0.88        96\n",
            "           1       0.87      0.91      0.89       105\n",
            "\n",
            "    accuracy                           0.89       201\n",
            "   macro avg       0.89      0.88      0.89       201\n",
            "weighted avg       0.89      0.89      0.89       201\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [16:17:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========== MODELO ESPEC칈FICO: XGB SEVERIDAD (14) ==========\n",
            "Accuracy severidad (val): 0.44761904761904764\n",
            "F1 macro severidad (val): 0.3749299929992999\n",
            "Matriz conf severidad (val):\n",
            " [[31 12  9  3]\n",
            " [ 6  5  5  6]\n",
            " [ 8  4  8  1]\n",
            " [ 1  2  1  3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.67      0.56      0.61        55\n",
            "           2       0.22      0.23      0.22        22\n",
            "           3       0.35      0.38      0.36        21\n",
            "           4       0.23      0.43      0.30         7\n",
            "\n",
            "    accuracy                           0.45       105\n",
            "   macro avg       0.37      0.40      0.37       105\n",
            "weighted avg       0.48      0.45      0.46       105\n",
            "\n",
            "\n",
            "Distribuci칩n de predicciones finales (04) en test:\n",
            "{np.int64(0): np.int64(87), np.int64(1): np.int64(45), np.int64(2): np.int64(21), np.int64(3): np.int64(25), np.int64(4): np.int64(6)}\n",
            "\n",
            "Columnas de sample_submission:\n",
            "Index(['ID', 'label'], dtype='object')\n",
            "\n",
            "Filas test Kaggle: 184\n",
            "Filas sample_submission: 184\n",
            "\n",
            "九 submission_xgb_bin_xgb_sev.csv generado con la misma estructura que sample_submission.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ============================================================\n",
        "# 1. Definici칩n de columnas (CON chol)\n",
        "# ============================================================\n",
        "\n",
        "# Continuas biom칠tricas\n",
        "cont_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "\n",
        "# Categ칩ricas cl칤nicas\n",
        "cat_cols  = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "# Flags de pruebas NO realizadas\n",
        "not_done_cols = ['chol_not_done', 'slope_not_done', 'ca_not_done', 'thal_not_done', 'fbs_not_done']\n",
        "\n",
        "features_base = cont_cols + cat_cols + not_done_cols\n",
        "target_col = 'label'\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. Funciones de limpieza compartidas (TRAIN + TEST)\n",
        "# ============================================================\n",
        "\n",
        "def add_not_done_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Crea columnas *_not_done a partir de -9/-9.0 en chol/slope/ca/thal/fbs.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    for col in ['chol', 'slope', 'ca', 'thal', 'fbs']:\n",
        "        if col in df.columns:\n",
        "            mask_nd = df[col].astype(str).isin(['-9', '-9.0'])\n",
        "            df[col + '_not_done'] = mask_nd.astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def basic_numeric_clean(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    - \"?\" -> NaN\n",
        "    - -9 en chol/slope/ca/thal -> NaN\n",
        "    - fbs -9 -> 0\n",
        "    - Convierte columnas a num칠ricas\n",
        "    - Marca 0 imposibles como NaN\n",
        "    - En TRAIN, limpia label\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1) \"?\" -> NaN\n",
        "    df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "    # 2) -9 para chol/slope/ca/thal -> NaN (prueba no realizada)\n",
        "    for col in ['chol', 'slope', 'ca', 'thal']:\n",
        "        if col in df.columns:\n",
        "            mask_nd = df[col].astype(str).isin(['-9', '-9.0'])\n",
        "            df.loc[mask_nd, col] = np.nan\n",
        "\n",
        "    # 3) fbs: -9 / -9.0 -> 0 (pero con flag fbs_not_done)\n",
        "    if 'fbs' in df.columns:\n",
        "        df['fbs'] = df['fbs'].replace(['-9', '-9.0'], 0)\n",
        "\n",
        "    # 4) Convertir columnas num칠ricas a float/int\n",
        "    num_cols_all = cont_cols + cat_cols\n",
        "    if is_train and target_col in df.columns:\n",
        "        num_cols_all = num_cols_all + [target_col]\n",
        "\n",
        "    for col in num_cols_all:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # 5) Zeros imposibles -> NaN\n",
        "    if 'trestbps' in df.columns:\n",
        "        df.loc[df['trestbps'] == 0, 'trestbps'] = np.nan\n",
        "    if 'chol' in df.columns:\n",
        "        df.loc[df['chol'] == 0, 'chol'] = np.nan\n",
        "\n",
        "    # 6) En TRAIN: eliminar filas sin label y pasarla a int\n",
        "    if is_train and target_col in df.columns:\n",
        "        df = df.dropna(subset=[target_col])\n",
        "        df[target_col] = df[target_col].astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. Cargar y limpiar TRAIN (train_IA + statlog)\n",
        "# ============================================================\n",
        "\n",
        "print(\"Cargando datasets de TRAIN...\")\n",
        "df_train = pd.read_csv(\"/train_IA_PROJECT.csv\")       # ajusta ruta\n",
        "df_statlog = pd.read_csv(\"/statlog_limpio.csv\")       # ajusta ruta\n",
        "\n",
        "print(f\"Filas train_IA_PROJECT: {len(df_train)}\")\n",
        "print(f\"Filas statlog_limpio   : {len(df_statlog)}\")\n",
        "\n",
        "# Fusionamos ambos\n",
        "df_total = pd.concat([df_train, df_statlog], ignore_index=True)\n",
        "print(f\"Total pacientes combinados (train+statlog): {len(df_total)}\")\n",
        "\n",
        "# 1) Flags not_done en TRAIN\n",
        "df_total = add_not_done_flags(df_total)\n",
        "\n",
        "# 2) Limpieza b치sica num칠rica + label\n",
        "df_train_clean = basic_numeric_clean(df_total, is_train=True)\n",
        "\n",
        "# 3) Imputaci칩n KNN en continuas (solo con TRAIN)\n",
        "knn_imp = KNNImputer(n_neighbors=5)\n",
        "df_train_clean[cont_cols] = knn_imp.fit_transform(df_train_clean[cont_cols])\n",
        "\n",
        "# 4) NaN en categ칩ricas -> moda (solo TRAIN)\n",
        "cat_modes = {}\n",
        "for col in cat_cols:\n",
        "    moda = df_train_clean[col].mode()[0]\n",
        "    cat_modes[col] = moda\n",
        "    df_train_clean[col].fillna(moda, inplace=True)\n",
        "\n",
        "# df_imp definitivo de TRAIN\n",
        "df_imp = df_train_clean.copy()\n",
        "\n",
        "print(\"\\nResumen df_imp (TRAIN limpio+imputado):\")\n",
        "print(df_imp[features_base + [target_col]].isna().sum())\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. Cargar y limpiar TEST de Kaggle\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nCargando TEST de Kaggle...\")\n",
        "df_test_raw = pd.read_csv(\"/test.csv\")   # ajusta ruta\n",
        "\n",
        "# 1) Flags not_done en TEST\n",
        "df_test = add_not_done_flags(df_test_raw)\n",
        "\n",
        "# 2) Limpieza b치sica num칠rica (sin label)\n",
        "df_test = basic_numeric_clean(df_test, is_train=False)\n",
        "\n",
        "# 3) Imputaci칩n KNN en continuas usando MISMO imputador que TRAIN\n",
        "df_test[cont_cols] = knn_imp.transform(df_test[cont_cols])\n",
        "\n",
        "# 4) NaN en categ칩ricas -> usar las modas del TRAIN\n",
        "for col in cat_cols:\n",
        "    df_test[col].fillna(cat_modes[col], inplace=True)\n",
        "\n",
        "print(\"\\nNaNs en TEST despu칠s de limpieza (features_base):\")\n",
        "print(df_test[features_base].isna().sum())\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. Preparar matrices X e y\n",
        "# ============================================================\n",
        "\n",
        "X_full = df_imp[features_base].copy()\n",
        "y_full = df_imp[target_col].astype(int)\n",
        "\n",
        "X_test_kaggle = df_test[features_base].copy()\n",
        "\n",
        "print(\"\\nShape X_full (TRAIN):\", X_full.shape)\n",
        "print(\"Distrib clases TRAIN (04):\")\n",
        "print(y_full.value_counts().sort_index())\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. Modelo general: XGB BINARIO (0 vs 14)\n",
        "# ============================================================\n",
        "\n",
        "# Etiqueta binaria: 0 = sano, 1 = enfermo\n",
        "y_bin = (y_full > 0).astype(int)\n",
        "\n",
        "# Split train/valid\n",
        "Xb_train, Xb_val, yb_train, yb_val = train_test_split(\n",
        "    X_full, y_bin,\n",
        "    test_size=0.2,\n",
        "    stratify=y_bin,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# SMOTENC para balancear el binario\n",
        "features = list(X_full.columns)\n",
        "cat_for_smote = cat_cols + not_done_cols\n",
        "cat_indices = [features.index(c) for c in cat_for_smote if c in features]\n",
        "\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "smote_bin = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',\n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "Xb_train_res, yb_train_res = smote_bin.fit_resample(Xb_train, yb_train)\n",
        "\n",
        "xgb_bin = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=5,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='binary:logistic',\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        ")\n",
        "\n",
        "xgb_bin.fit(Xb_train_res, yb_train_res)\n",
        "\n",
        "yb_val_proba = xgb_bin.predict_proba(Xb_val)[:, 1]\n",
        "yb_val_pred = (yb_val_proba >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\n========== MODELO GENERAL: XGB BINARIO (0 vs 14) ==========\")\n",
        "print(\"Accuracy binario (val):\", accuracy_score(yb_val, yb_val_pred))\n",
        "print(\"F1 macro binario (val):\", f1_score(yb_val, yb_val_pred, average=\"macro\"))\n",
        "print(\"Matriz conf binaria (val):\\n\", confusion_matrix(yb_val, yb_val_pred))\n",
        "print(classification_report(yb_val, yb_val_pred, zero_division=0))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. Modelo espec칤fico: XGB multiclase para severidad 14\n",
        "# ============================================================\n",
        "\n",
        "# Nos quedamos SOLO con enfermos para el modelo de severidad\n",
        "mask_sick = (y_full > 0)\n",
        "X_sick = X_full[mask_sick].copy()\n",
        "y_sick = y_full[mask_sick].copy()   # valores 14\n",
        "\n",
        "# Vamos a relabelar a 03 internamente para XGBoost (opcional pero c칩modo)\n",
        "y_sick_04 = y_sick - 1  # 14 -> 03\n",
        "\n",
        "# Split train/valid en enfermos\n",
        "Xs_train, Xs_val, ys_train, ys_val = train_test_split(\n",
        "    X_sick, y_sick_04,\n",
        "    test_size=0.2,\n",
        "    stratify=y_sick_04,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# SMOTENC para balancear clases 03 (equivalentes a 14)\n",
        "smote_sev = SMOTENC(\n",
        "    categorical_features=cat_indices,\n",
        "    sampling_strategy='not majority',\n",
        "    k_neighbors=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "Xs_train_res, ys_train_res = smote_sev.fit_resample(Xs_train, ys_train)\n",
        "\n",
        "xgb_severity = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=5,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='multi:softprob',\n",
        "    num_class=4,          # clases 0,1,2,3 (que luego mapeamos a 14)\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False,\n",
        ")\n",
        "\n",
        "xgb_severity.fit(Xs_train_res, ys_train_res)\n",
        "\n",
        "ys_val_proba = xgb_severity.predict_proba(Xs_val)\n",
        "ys_val_pred_04 = ys_val_proba.argmax(axis=1)\n",
        "ys_val_pred = ys_val_pred_04 + 1  # volver a 14\n",
        "\n",
        "print(\"\\n========== MODELO ESPEC칈FICO: XGB SEVERIDAD (14) ==========\")\n",
        "print(\"Accuracy severidad (val):\", accuracy_score(ys_val + 1, ys_val_pred))\n",
        "print(\"F1 macro severidad (val):\", f1_score(ys_val + 1, ys_val_pred, average=\"macro\"))\n",
        "print(\"Matriz conf severidad (val):\\n\", confusion_matrix(ys_val + 1, ys_val_pred))\n",
        "print(classification_report(ys_val + 1, ys_val_pred, zero_division=0))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. Predicci칩n en TEST: combinaci칩n jer치rquica\n",
        "# ============================================================\n",
        "\n",
        "# 1) Probabilidad de estar enfermo en test\n",
        "proba_test_bin = xgb_bin.predict_proba(X_test_kaggle)\n",
        "p_sano = proba_test_bin[:, 0]\n",
        "p_enfermo = proba_test_bin[:, 1]\n",
        "\n",
        "# 2) Probabilidades de severidad condicional (14) en test\n",
        "proba_sev_cond_04 = xgb_severity.predict_proba(X_test_kaggle)  # shape (n,4)\n",
        "# Convertimos a 14 solo para claridad si queremos luego, pero ahora usamos 03\n",
        "\n",
        "# 3) Combinamos:\n",
        "#    P(0) = P(sano)\n",
        "#    P(k) = P(enfermo) * P(severidad=k | enfermo), k=1..4\n",
        "n_test = X_test_kaggle.shape[0]\n",
        "proba_final = np.zeros((n_test, 5))\n",
        "\n",
        "# P(clase 0)\n",
        "proba_final[:, 0] = p_sano\n",
        "\n",
        "# P(clases 14)\n",
        "for k in range(4):  # k=0..3 -> clase real = k+1\n",
        "    proba_final[:, k+1] = p_enfermo * proba_sev_cond_04[:, k]\n",
        "\n",
        "# 4) Predicci칩n final = argmax sobre 04\n",
        "y_test_pred_final = proba_final.argmax(axis=1).astype(int)\n",
        "\n",
        "print(\"\\nDistribuci칩n de predicciones finales (04) en test:\")\n",
        "unique, counts = np.unique(y_test_pred_final, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9. Crear submission con la MISMA ESTRUCTURA que sample_submission\n",
        "# ============================================================\n",
        "\n",
        "sub = pd.read_csv(\"/sample_submission.csv\")  # usa tu plantilla real\n",
        "\n",
        "print(\"\\nColumnas de sample_submission:\")\n",
        "print(sub.columns)\n",
        "\n",
        "print(\"\\nFilas test Kaggle:\", len(X_test_kaggle))\n",
        "print(\"Filas sample_submission:\", len(sub))\n",
        "\n",
        "if len(sub) != len(X_test_kaggle):\n",
        "    raise ValueError(\n",
        "        f\"仇 El n칰mero de filas del test ({len(X_test_kaggle)}) \"\n",
        "        f\"no coincide con sample_submission ({len(sub)})\"\n",
        "    )\n",
        "\n",
        "# Detectamos la columna de predicci칩n\n",
        "if \"label\" in sub.columns:\n",
        "    label_col = \"label\"\n",
        "else:\n",
        "    label_col = sub.columns[-1]\n",
        "    print(f\"丘멆잺 No se encontr칩 columna 'label'. \"\n",
        "          f\"Usando '{label_col}' como columna de predicci칩n.\")\n",
        "\n",
        "sub[label_col] = y_test_pred_final\n",
        "\n",
        "sub.to_csv(\"submission_xgb_bin_xgb_sev.csv\", index=False)\n",
        "print(\"\\n九 submission_xgb_bin_xgb_sev.csv generado con la misma estructura que sample_submission.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK3rLTFutB1o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QN0UfZoVAibe",
        "qVo27nGlDUkY",
        "_bXJkTpuH_u0",
        "yL4LXi30LIyr",
        "iA1eEzyyMHOM"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
